[{"authors":["admin"],"categories":null,"content":"Valentina Andrade de la Horra es socióloga de la Universidad de Chile. Apoyo docente de la Facultad de Ciencias Sociales de la Universidad de Chile en cursos de estadística y académica adjunta de la Escuela de Sociología de la Universidad Silva Henríquez.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Valentina Andrade de la Horra es socióloga de la Universidad de Chile. Apoyo docente de la Facultad de Ciencias Sociales de la Universidad de Chile en cursos de estadística y académica adjunta de la Escuela de Sociología de la Universidad Silva Henríquez.","tags":null,"title":"Valentina Andrade","type":"authors"},{"authors":null,"categories":null,"content":"\rÍndice\r\rInstrucciones generales para las prácticas\rReportes de progreso\rNotas sobre trabajo con software R\rTutorial de instalación de R\rTutorial RCloud\r\r\r\rEsta página contiene los materiales de los contenidos de cada sesión (documento de presentación, lecturas, links), y también las guías prácticas.\nTodo el material es accesible desde el menú de la izquierda \u0026lt;–\nInstrucciones generales para las prácticas\r\rLas prácticas se desarrollarán semana a semana en el horario correspondiente a cada sección (Jueves Sección 1, Viernes Sección 2, de 8:30 a 10:00); ver detalles en la planificación del curso.\n\rEstas sesiones acompañarán el desarrollo de las guías prácticas disponibles en este sitio.\n\rLos contenidos de las guías refieren a aplicaciones de análisis de datos de lo visto en clases la semana anterior\n\rEn las prácticas vamos a trabajar con el software R, Versión 4.0. Para su instalación consultar el video-tutorial disponible en la página de la práctica 1 (click aquí)\n\rPara poder tener una asesoría y monitoreo más cercano en el desarrollo de las guías, los estudiantes han sido divididos en grupos asignados a un/a ayudante (ver en UCursos)\n\rEl trabajo con estas guías se organiza en los siguientes momentos:\n\rcada estudiante realiza la guía de manera autónoma durante la semana correspondiente, antes de la sesión de práctica\ren caso de dudas, las realizan en los foros disponibles o se contactan directamente con su ayudante\rdurante las sesiones prácticas, cada ayudante se reunirá con su grupo de estudiantes asignado para revisar la guía paso a paso y resolver dudas\rcada semana se completa un reporte de progreso (detalles abajo) que va a ser implementado en la plataforma de UCursos\r\r\r\rReportes de progreso\rEste curso se caracteriza por el desarrollo secuencial y acumulativo de aprendizajes. En otras palabras, va a ser muy difícil poder lograr los objetivos de aprendizaje posteriores sin haber logrado los objetivos de contenidos previos. Y nuevamente en otras palabras: es muy difícil aprender a multiplicar sin saber sumar. Por lo tanto, como equipo a cargo del curso nos interesa poder monitorear permanentemente el cumplimiento de objetivos de aprendizaje semana a semana para así poder prestar asesoría oportuna.\nEl sistema de monitoreo de cumplimiento de objetivos se llevará a cabo mediante reportes de progreso. Un ejemplo de este reporte se ve así:\nLos reportes consisten en completar una encuesta simple y breve, donde se preguntará por el cumplimiento de los objetivos de las prácticas respectivas. La idea es que los puedan completar durante la semana en que se desarrolla la guía, a más tardar los días viernes.\nActualización (22/05)\n1- El primer reporte (Praćtica 1) se generó en la función Test de UCursos, pero lamentablemente la forma en que se entregan los resultados no nos permitió un análisis desagregado por pregunta, que es importante para poder monitorear distintos objetivos. Por eso, desde la práctica 2 hay disponible una encuesta formato web (Forms), a la que se accede directamente la final de la página de cada práctica.\r2- Como incentivo para completar los reportes de progreso, se entregarán dos décimas adicionales a cada evaluación para quienes tengan sus reportes completados.\n\rNotas sobre trabajo con software R\rPara los análisis estadísticos de este curso usamos el programa R, principalmente porque es gratuito, pero la principal razón es que es de código abierto. Esto quiere decir que cualquier persona puede revisar cómo está hecho y aportar con modificaciones y procedimientos nuevos, como son las librerías que realizan funciones específicas.\nEl carácter de apertura de R posee muchas ventajas, pero también conlleva complicaciones. Se actualiza permanentemente, así como también las librerías, y esto puede generar problemas de compatibilidad y de fallas en ejecución del código de análisis.\nPara minimizar estos posibles problemas en este curso, vamos a:\n\rtrabajar con la misma y última versión de R, que es la 4.0\n\revitar uso de tilde, ñ, espacios y mayusculas tanto en carpetas y archivos, así como también en los nombres de las variable\n\ral momento de hacer consultas sobre problemas en la ejecución del código, adjuntar archivo con:\nCódigo completo hasta que se produce el problema\rIndicar línea del código donde se produce el problema\rAdjuntar el resultado del output de la información de la sesión (sessionInfo())\r\r\rTutorial de instalación de R\r\rPara quienes no trabajan en R constantemente, abajo un primer tutorial sobre instalación de R y RStudio, necesarios para poder desarrollar esta práctica: Actualizado a versión 4.0 \r\r\r\r\rTutorial RCloud\rRCloud permite trabajar con RStudio en línea, sin necesidad de instalar localmente. Puede ser muy útil para quienes tengan problemas de instalación, así como también para trabajo colaborativo.\n\r\r\r\r","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1594088024,"objectID":"108da05078d325a5a1f01a1ff2583053","permalink":"/class/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/","section":"class","summary":"Índice\r\rInstrucciones generales para las prácticas\rReportes de progreso\rNotas sobre trabajo con software R\rTutorial de instalación de R\rTutorial RCloud\r\r\r\rEsta página contiene los materiales de los contenidos de cada sesión (documento de presentación, lecturas, links), y también las guías prácticas.\nTodo el material es accesible desde el menú de la izquierda \u0026lt;–\nInstrucciones generales para las prácticas\r\rLas prácticas se desarrollarán semana a semana en el horario correspondiente a cada sección (Jueves Sección 1, Viernes Sección 2, de 8:30 a 10:00); ver detalles en la planificación del curso.","tags":null,"title":"Material","type":"docs"},{"authors":null,"categories":null,"content":"\rIf I assign readings, you really should read them.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1585568956,"objectID":"40fcd2da3bf2dc718a2fe044c31cdc56","permalink":"/reading/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/","section":"reading","summary":"If I assign readings, you really should read them.","tags":null,"title":"Reading","type":"docs"},{"authors":null,"categories":null,"content":"\rAquí se accede a las distintas guías prácticas desde el menú de la izquierda\r\r","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1585568305,"objectID":"3aa23ffb1eb3dedbe4d8a9c2165e2c58","permalink":"/assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/","section":"assignment","summary":"\rAquí se accede a las distintas guías prácticas desde el menú de la izquierda\r\r","tags":null,"title":"Prácticas","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de la clase\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r","date":1597968000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1598319561,"objectID":"df7a31a1291d87ad849bb7c3fb14d771","permalink":"/class/12-class/","publishdate":"2020-08-21T00:00:00Z","relpermalink":"/class/12-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de la clase\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r","tags":null,"title":"12: Pendientes y complementos","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo\rLibrerías\rDatos\rExplorar datos\r\rMedición y transformación de variables\rCreación de índice\rRecuperar casos perdidos\rIngresos como variable categórica\r\rA tibble: 6 x 2\rEstimación\rDiágnosticos\rCasos influyentes\rLinealidad\r\r\rTest homogeneidad de varianza\rMulticolinealidad\rReferencias\r\rReporte de progreso\rForo práctica 11\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo\rLa siguiente práctica tiene el objetivo de introducir a los estudiantes en los supuestos y robustez del modelo de regresión. Por esta razón, volveremos a algunos de los contenidos previos relacionados con la estimación, análisis de residuos y ajuste. Para ello, utilizaremos la base de datos de la tercera ola del Estudio Longitudinal Social del Chile 2018 con el objetivo de analizar los determinantes de la Participación Ciudadana.\n\rLibrerías\rpacman::p_load(dplyr, summarytools, sjPlot,texreg, corrplot,ggplot2,ggfortify,sandwich,lmtest,sjlabelled)\r\rDatos\rEl Estudio Longitudinal Social del Chile (ENACOES 2014), único en Chile y América Latina, consiste en encuestar a casi 3.000 chilenos, anualmente, a lo largo de una década. ELSOC ha sido diseñado para evaluar la manera cómo piensan, sienten y se comportan los chilenos en torno a un conjunto de temas referidos al conflicto y la cohesión social en Chile. La población objetivo son hombres y mujeres entre 15 y 75 años de edad con un alcance nacional, donde se obtuvo una muestra final de 3748 casos en el año 2018.\nload(\u0026quot;content/assignment/data/elsoc18p11.RData\u0026quot;)\r#Cargamos la base de datos desde internet\rload(url(\u0026quot;https://multivariada.netlify.com/assignment/data/elsoc18p11.RData\u0026quot;))\rExplorar datos\rA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para realizar las transformaciones y análisis posteriores.\nview(dfSummary(elsoc, headings = FALSE, method = \u0026quot;render\u0026quot;))\r\r\rNo\rVariable\rLabel\rStats / Values\rFreqs (% of Valid)\rGraph\rValid\rMissing\r\r\r\r\r1\rsexo\r[numeric]\rSexo entrevistado\rMin : 0\rMean : 0.6\rMax : 1\r0:1446(38.6%)1:2302(61.4%)\r\r3748\r(100%)\r0\r(0%)\r\r\r2\redad\r[numeric]\rEdad entrevistado\rMean (sd) : 47.1 (15.5)\rmin 70 distinct values\r\r3748\r(100%)\r0\r(0%)\r\r\r3\reduc\r[factor]\rNivel educacional\r1. 1\r2. 2\r3. 3\r4. 4\r5. 5\r450(12.0%)370(9.9%)1600(42.8%)598(16.0%)725(19.4%)\r\r3743\r(99.87%)\r5\r(0.13%)\r\r\r4\rpospol\r[factor]\rAutoubicacion escala izquierda-derecha\r1. 1\r2. 2\r3. 3\r4. 4\r807(22.0%)952(26.0%)734(20.0%)1171(32.0%)\r\r3664\r(97.76%)\r84\r(2.24%)\r\r\r5\rpart01\r[numeric]\rFrecuencia: Firma carta o peticion\rapoyando causa\rMean (sd) : 1.5 (0.9)\rmin 1:2717(72.6%)2:476(12.7%)3:411(11.0%)4:117(3.1%)5:21(0.6%)\r\r3742\r(99.84%)\r6\r(0.16%)\r\r\r6\rpart02\r[numeric]\rFrecuencia: Asiste a marcha o\rmanifestacion pacifica\rMean (sd) : 1.2 (0.6)\rmin 1:3289(87.8%)2:195(5.2%)3:191(5.1%)4:51(1.4%)5:19(0.5%)\r\r3745\r(99.92%)\r3\r(0.08%)\r\r\r7\rpart03\r[numeric]\rFrecuencia: Participa en huelga\rMean (sd) : 1.2 (0.5)\rmin 1:3407(91.0%)2:152(4.1%)3:146(3.9%)4:29(0.8%)5:11(0.3%)\r\r3745\r(99.92%)\r3\r(0.08%)\r\r\r8\rpart04\r[numeric]\rFrecuencia: Usa redes sociales para\ropinar en temas publicos\rMean (sd) : 1.6 (1.1)\rmin 1:2598(69.4%)2:310(8.3%)3:514(13.7%)4:223(6.0%)5:98(2.6%)\r\r3743\r(99.87%)\r5\r(0.13%)\r\r\r9\ringhogar\r[numeric]\rIngreso total del hogar\rMean (sd) : 678842.5 (781003.9)\rmin 227 distinct values\r\r3080\r(82.18%)\r668\r(17.82%)\r\r\r10\ringhogar_t\r[numeric]\rIngreso total del hogar (en tramos)\rMean (sd) : 7 (5.4)\rmin 20 distinct values\r\r477\r(12.73%)\r3271\r(87.27%)\r\r\r11\rtamhogar\r[numeric]\rHabitantes del hogar\rMean (sd) : 3.2 (1.6)\rmin 13 distinct values\r\r3741\r(99.81%)\r7\r(0.19%)\r\r\r\rGenerated by summarytools 0.9.6 (R version 4.0.0)2020-08-17\n\rview_df(elsoc,max.len = 50)\r\rData frame: elsoc\r\r\rID\r\rName\r\rLabel\r\rValues\r\rValue Labels\r\r\r\r1\r\rsexo\r\rSexo entrevistado\r\r0\n1\r\rHombre\nMujer\r\r\r\r2\r\redad\r\rEdad entrevistado\r\rrange: 18-90\r\r\r\r3\r\reduc\r\rNivel educacional\r\r1\n2\n3\n4\n5\r\rPrimaria incompleta menos\nPrimaria y secundaria baja\nSecundaria alta\nTerciaria ciclo corto\nTerciaria y Postgrado\r\r\r\r4\r\rpospol\r\rAutoubicacion escala izquierda-derecha\r\r1\n2\n3\n4\r\rDerecha\nCentro\nIzquierda\nIndep./Ninguno\r\r\r\r5\r\rpart01\r\rFrecuencia: Firma carta o peticion apoyando causa\r\r1\n2\n3\n4\n5\r\rNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\r\r\r\r6\r\rpart02\r\rFrecuencia: Asiste a mbackground-color:#eeeeeeha o manifestacion\npacifica\r\r1\n2\n3\n4\n5\r\rNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\r\r\r\r7\r\rpart03\r\rFrecuencia: Participa en huelga\r\r1\n2\n3\n4\n5\r\rNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\r\r\r\r8\r\rpart04\r\rFrecuencia: Usa redes sociales para opinar en\ntemas publicos\r\r1\n2\n3\n4\n5\r\rNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\r\r\r\r9\r\ringhogar\r\rIngreso total del hogar\r\rrange: 30000-17000000\r\r\r\r10\r\ringhogar_t\r\rIngreso total del hogar (en tramos)\r\r1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\r\rMenos de $220.000 mensuales liquidos\nDe $220.001 a $280.000 mensuales liquidos\nDe $280.001 a $330.000 mensuales liquidos\nDe $330.001 a $380.000 mensuales liquidos\nDe $380.001 a $420.000 mensuales liquidos\nDe $420.001 a $470.000 mensuales liquidos\nDe $470.001 a $510.000 mensuales liquidos\nDe $510.001 a $560.000 mensuales liquidos\nDe $560.001 a $610.000 mensuales liquidos\nDe $610.001 a $670.000 mensuales liquidos\nDe $670.001 a $730.000 mensuales liquidos\nDe $730.001 a $800.000 mensuales liquidos\nDe $800.001 a $890.000 mensuales liquidos\nDe $890.001 a $980.000 mensuales liquidos\nDe $980.001 a $1.100.000 mensuales liquidos\nDe $1.100.001 a $1.260.000 mensuales liquidos\nDe $1.260.001 a $1.490.000 mensuales liquidos\nDe $1.490.001 a $1.850.000 mensuales liquidos\nDe $1.850.001 a $2.700.000 mensuales liquidos\nMas de $2.700.000 a mensuales liquidos\r\r\r\r11\r\rtamhogar\r\rHabitantes del hogar\r\rrange: 1-14\r\r\r\r\r\rMedición y transformación de variables\rCreación de índice\rEn ELSOC existen cuatro preguntas referentes a la participación política o ciudadana, donde se le pregunta a las personas por la frecuencia en que han participado de determinados eventos vinculados a su rol como ciudadanos. Para esto, se emplearon escalas likert de 5 categorías para medir dicha participación.\nplot_stackfrq(elsoc[,c(\u0026quot;part01\u0026quot;,\u0026quot;part02\u0026quot;,\u0026quot;part03\u0026quot;,\u0026quot;part04\u0026quot;)]) +theme(legend.position=\u0026quot;bottom\u0026quot;)\rEn la figura anterior, podemos ver que existe un alto porcentaje de personas que declaran no haber participado nunca en alguna de estas expresiones de la participación ciudadana. En este sentido, para la creación de un índice o medida agrupada, nos interesa saber si existe algún grado de relación entre nuestros indicadores. Para esto, lo que tradicionalmente se realiza es realizar un análisis de correlación entre los indicadores.\ncorrplot.mixed(cor(select(elsoc,part01,part02,part03,part04),\ruse = \u0026quot;complete.obs\u0026quot;))\rLa matriz de correlación nos indica que existen correlaciones moderadas entre los indicadores, donde 0.25 es la más baja y 0.44 la más alta. Es muy importante realizar este paso, debido a que si nuestros indicadores no correlacionan en absoluto, es posible que estemos frente a un atributo distinto. Por lo tanto, sería poco adecuado realizar la construcción de un índice que busque representar un fenómeno o constructo “común” a través de indicadores que no poseen ningún grado de correlación. En nuestro caso, hemos decidido elaborar un índice sumatorio a través de la suma de las respuestas de cada individuo. Para ello emplearemos las funciones mutate (para crear una nueva variable) y rowSums() (para sumar los indicadores) de la librería dplyr.\nelsoc \u0026lt;-elsoc %\u0026gt;%mutate(partpol=rowSums(select(., part01,part02,part03,part04)))\rdescr(elsoc$partpol,style = \u0026quot;rmarkdown\u0026quot;,stats = \u0026quot;common\u0026quot;, transpose = T,headings = F)\r\r\r\rMean\rStd.Dev\rMin\rMedian\rMax\rN.Valid\rPct.Valid\r\r\r\rpartpol\r5.47\r2.30\r4.00\r4.00\r20.00\r3740.00\r99.79\r\r\r\rplot_frq(data = elsoc$partpol,type = \u0026quot;hist\u0026quot;,show.mean = T)\rVemos que el índice sumatorio posee valores que van desde 4 hasta 20, con una media de 5,47 y una mediana de 4. Además, vemos algo que ya se había identificado en el gráfico descriptivo de cada indicador por separado, el hecho que existe una proporción importante de personas que respondieron “nunca” en los cuatro indicadores, los cuales son representados por una alta frecuencia de 4 en el histograma. Con esto hemos creado nuestro índice sumatorio de Participación Política.\n\rRecuperar casos perdidos\rEs común que en las encuestas sociales cierta variables posean una alta proporción de datos perdidos. Un ejemplo común es en el reporte de los ingresos de los hogares o individuos. Esto generalmente puede generarse por características de la persona (p.ej. desempleado, estudiante) o por deseabilidad social (personas de altos ingresos desisten de reportar). En el caso de ELSOC, existen dos estrategias para solicitar que las personas reporten sus ingresos. La primera consiste en preguntar directamente por el monto en pesos chilenos de los ingresos totales del hogar. Alternativamente, si la persona no reporta los ingresos, se le presenta la posibilidad de ubicar los ingresos del hogar en tramos (Por ejemplo “De $560.001 a $610.000 mensuales liquidos”). De esta manera, si existen datos perdidos en la primera, se emplea la segunda pregunta para tener un nivel aproximado del ingreso del hogar.\ndescr(elsoc$inghogar,style = \u0026quot;rmarkdown\u0026quot;,stats = \u0026quot;common\u0026quot;, transpose = T,headings = F)\r\r\r\rMean\rStd.Dev\rMin\rMedian\rMax\rN.Valid\rPct.Valid\r\r\r\ringhogar\r678842.52\r781003.92\r30000.00\r5e+05\r1.7e+07\r3080.00\r82.18\r\r\r\rsjmisc::frq(elsoc$inghogar_t,\rout = \u0026quot;txt\u0026quot;,\rshow.na = T) %\u0026gt;%knitr::kable()\r\r\r\r\r\rval\rlabel\rfrq\rraw.prc\rvalid.prc\rcum.prc\r\r\r\r1\rMenos de $220.000 mensuales liquidos\r62\r1.65\r13.00\r13.00\r\r2\rDe $220.001 a $280.000 mensuales liquidos\r46\r1.23\r9.64\r22.64\r\r3\rDe $280.001 a $330.000 mensuales liquidos\r57\r1.52\r11.95\r34.59\r\r4\rDe $330.001 a $380.000 mensuales liquidos\r40\r1.07\r8.39\r42.98\r\r5\rDe $380.001 a $420.000 mensuales liquidos\r38\r1.01\r7.97\r50.94\r\r6\rDe $420.001 a $470.000 mensuales liquidos\r37\r0.99\r7.76\r58.70\r\r7\rDe $470.001 a $510.000 mensuales liquidos\r27\r0.72\r5.66\r64.36\r\r8\rDe $510.001 a $560.000 mensuales liquidos\r15\r0.40\r3.14\r67.51\r\r9\rDe $560.001 a $610.000 mensuales liquidos\r24\r0.64\r5.03\r72.54\r\r10\rDe $610.001 a $670.000 mensuales liquidos\r12\r0.32\r2.52\r75.05\r\r11\rDe $670.001 a $730.000 mensuales liquidos\r15\r0.40\r3.14\r78.20\r\r12\rDe $730.001 a $800.000 mensuales liquidos\r16\r0.43\r3.35\r81.55\r\r13\rDe $800.001 a $890.000 mensuales liquidos\r8\r0.21\r1.68\r83.23\r\r14\rDe $890.001 a $980.000 mensuales liquidos\r14\r0.37\r2.94\r86.16\r\r15\rDe $980.001 a $1.100.000 mensuales liquidos\r14\r0.37\r2.94\r89.10\r\r16\rDe $1.100.001 a $1.260.000 mensuales liquidos\r10\r0.27\r2.10\r91.19\r\r17\rDe $1.260.001 a $1.490.000 mensuales liquidos\r7\r0.19\r1.47\r92.66\r\r18\rDe $1.490.001 a $1.850.000 mensuales liquidos\r11\r0.29\r2.31\r94.97\r\r19\rDe $1.850.001 a $2.700.000 mensuales liquidos\r14\r0.37\r2.94\r97.90\r\r20\rMas de $2.700.000 a mensuales liquidos\r10\r0.27\r2.10\r100.00\r\r\r\r3271\r87.27\r\r\r\r\r\r\r\r\r\rSi observamos la tabla de descriptivos para la variable ingreso del hogar (inghogar), tenemos un porcentaje 17,82% de datos perdidos. Por esta razón, emplearemos los datos disponibles en inghogar_t para recuperar información en los ingresos del hogar.\nLa estrategia posee los siguientes pasos:\nCalcular la media del tramo reportado.\rEn el caso de que la persona no haya reportado el monto de los ingresos del hogar, remplazamos este valor perdido por el valor de la media del tramo, en el caso de estar disponible.\rComparamos la variable original con la nueva variable que posee información recuperada.\r\rPaso 1: Calcular la media por cada tramo\nelsoc$inghogar_t[elsoc$inghogar_t==1] \u0026lt;-( 220000 ) # [1] \u0026quot;Menos de $220.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==2] \u0026lt;-(220001 +280000 )/2 # [2] \u0026quot;De $220.001 a $280.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==3] \u0026lt;-(280001 +330000 )/2 # [3] \u0026quot;De $280.001 a $330.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==4] \u0026lt;-(330001 +380000 )/2 # [4] \u0026quot;De $330.001 a $380.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==5] \u0026lt;-(380001 +420000 )/2 # [5] \u0026quot;De $380.001 a $420.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==6] \u0026lt;-(420001 +470000 )/2 # [6] \u0026quot;De $420.001 a $470.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==7] \u0026lt;-(470001 +510000 )/2 # [7] \u0026quot;De $470.001 a $510.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==8] \u0026lt;-(510001 +560000 )/2 # [8] \u0026quot;De $510.001 a $560.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==9] \u0026lt;-(560001 +610000 )/2 # [9] \u0026quot;De $560.001 a $610.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==10]\u0026lt;-(610001 +670000 )/2 # [10] \u0026quot;De $610.001 a $670.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==11]\u0026lt;-(670001 +730000 )/2 # [11] \u0026quot;De $670.001 a $730.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==12]\u0026lt;-(730001 +800000 )/2 # [12] \u0026quot;De $730.001 a $800.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==13]\u0026lt;-(800001 +890000 )/2 # [13] \u0026quot;De $800.001 a $890.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==14]\u0026lt;-(890001 +980000 )/2 # [14] \u0026quot;De $890.001 a $980.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==15]\u0026lt;-(980001 +1100000)/2 # [15] \u0026quot;De $980.001 a $1.100.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==16]\u0026lt;-(1100001+1260000)/2 # [16] \u0026quot;De $1.100.001 a $1.260.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==17]\u0026lt;-(1260001+1490000)/2 # [17] \u0026quot;De $1.260.001 a $1.490.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==18]\u0026lt;-(1490001+1850000)/2 # [18] \u0026quot;De $1.490.001 a $1.850.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==19]\u0026lt;-(1850001+2700000)/2 # [19] \u0026quot;De $1.850.001 a $2.700.000 mensuales liquidos\u0026quot; \relsoc$inghogar_t[elsoc$inghogar_t==20]\u0026lt;-(2700000) # [20] \u0026quot;Mas de $2.700.000 a mensuales liquidos\u0026quot;\rPaso 2: En el caso de no tener información, remplazar por la media del tramo\nelsoc$inghogar_i \u0026lt;-ifelse(test = (is.na(elsoc$inghogar)), #¿existen NA en ingresos?\ryes = elsoc$inghogar_t, #VERDADERO, remplazar con la media del tramo\rno = elsoc$inghogar) #FALSE, mantener la variable original.\r\relsoc$inghogar_i \u0026lt;-set_label(elsoc$inghogar_i,\u0026quot;Ingreso total del hogar (imputada)\u0026quot;)\rPaso 3: Comparamos la variable original con la nueva\nsjmisc::descr(elsoc[,c(\u0026quot;inghogar\u0026quot;,\u0026quot;inghogar_i\u0026quot;)],\rshow =c(\u0026quot;label\u0026quot;, \u0026quot;n\u0026quot;, \u0026quot;NA.prc\u0026quot;, \u0026quot;mean\u0026quot;, \u0026quot;md\u0026quot;,\u0026quot;sd\u0026quot;)) %\u0026gt;%knitr::kable(digits = 2)\r\r\rvar\rlabel\rn\rNA.prc\rmean\rsd\rmd\r\r\r\ringhogar\rIngreso total del hogar\r3080\r17.82\r678842.5\r781003.9\r500000\r\ringhogar_i\rIngreso total del hogar (imputada)\r3557\r5.10\r668539.5\r752608.2\r480000\r\r\r\rVemos que pasamos de tener 17,82% de datos perdidos a un 5,1%, es decir recuperamos un 12,72% de los casos que antes tenían datos perdidos en la variable ingreso. Con estos datos podemos calcular el ingreso per capita del hogar, empleando la variable habitantes del hogar (tamhogar).\nelsoc$ing_pcap \u0026lt;-elsoc$inghogar_i/elsoc$tamhogar\relsoc$ing_pcap \u0026lt;-set_label(elsoc$ing_pcap,\u0026quot;Ingreso per cápita del hogar\u0026quot;)\rsjmisc::descr(elsoc[,c(\u0026quot;inghogar\u0026quot;,\u0026quot;inghogar_i\u0026quot;,\u0026quot;tamhogar\u0026quot;,\u0026quot;ing_pcap\u0026quot;)],\rshow =c(\u0026quot;label\u0026quot;, \u0026quot;n\u0026quot;, \u0026quot;NA.prc\u0026quot;, \u0026quot;mean\u0026quot;, \u0026quot;md\u0026quot;,\u0026quot;sd\u0026quot;)) %\u0026gt;%knitr::kable(digits = 2)\r\r\rvar\rlab\rel\rn NA\r.prc\rmean\rsd\rmd\r\r\r\r1\ringhogar\rIngreso total del hogar\r3080\r17.82\r678842.52\r781003.92\r500000.0\r\r2\ringhogar_i\rIngreso total del hogar (imputada)\r3557\r5.10\r668539.54\r752608.16\r480000.0\r\r4\rtamhogar\rHabitantes del hogar\r3741\r0.19\r3.16\r1.57\r3.0\r\r3\ring_pcap\rIngreso per cápita del hogar\r3552\r5.23\r263057.71\r350338.36\r166666.7\r\r\r\rVemos que la variable tamhogar posee un 0,19% de datos perdidos, por lo cual, al calcular el ingreso per cápita, vemos que el porcentaje de casos sin información en la nueva variable aumenta levemente a un 5,23%.\n\rIngresos como variable categórica\rTeniendo el ingreso per cápita del hogar, podemos calcular categorías de ingresos tales como los quintiles (o deciles). Por lo tanto, podemos clasificar a los individuos según sus ingresos en una variable categórica.\nEl procedimiento es el siguiente:\nelsoc$quintile\u0026lt;-dplyr::ntile(x = elsoc$ing_pcap,\rn = 5) # n de categorias, para quintiles usamos 5 \relsoc$quintile \u0026lt;-factor(elsoc$quintile,c(1,2,3,4,5), c(\u0026quot;Quintil 1\u0026quot;,\u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;)) \relsoc %\u0026gt;%\rgroup_by(quintile) %\u0026gt;%\rsummarise(n=n(),\rMedia=mean(ing_pcap,na.rm = T),\rMediana=median(ing_pcap,na.rm = T)) %\u0026gt;%\rknitr::kable()\r\r\rquintile\rn\rMedia\rMediana\r\r\r\rQuintil 1\r711\r62859.09\r66666.67\r\rQuintil 2\r711\r112218.97\r111250.12\r\rQuintil 3\r710\r167748.23\r166666.67\r\rQuintil 4\r710\r262710.27\r250000.50\r\rQuintil 5\r710\r710246.41\r500000.00\r\r\r196\r\r\r\r\r\rEn la tabla podemos observar que la variable quintile posee 5 grupos de tamaño equivalente. Además, agregamos la media y la mediana de los ingresos para cada categoría para ilustrar que podemos tratar esta variable como categórica y ordinal.\nExiste una última estrategia que podemos utilizar para recuperar ese 5,23% (n=196) de casos perdidos. Para esto, generamos una categoría adicional para los datos perdidos, es decir, recodificamos los NA para que se incluyan como una nueva categoría.\nEl procedimiento es el siguiente:\nelsoc$quintilemiss \u0026lt;-factor(elsoc$quintile,ordered = T)\relsoc$quintilemiss \u0026lt;-ifelse(is.na(elsoc$quintilemiss),yes = 6,no = elsoc$quintilemiss)\relsoc$quintilemiss \u0026lt;-factor(elsoc$quintilemiss ,levels = c(1,2,3,4,5,6),labels = c(\u0026quot;Quintil 1\u0026quot;,\u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;,\u0026quot;Missing\u0026quot;)) \relsoc %\u0026gt;%group_by(quintilemiss) %\u0026gt;%summarise(n=n())\r\r\rA tibble: 6 x 2\rquintilemiss n\r \r1 Quintil 1 711\r2 Quintil 2 711\r3 Quintil 3 710\r4 Quintil 4 710\r5 Quintil 5 710\r6 Missing 196\nTeniendo una nueva categoría de ingresos, podemos recuperar estos casos para los posteriores análisis. A continuación, se llevaran a cabo una serie de análisis que nos permitirán comprar los resultados según distintas especificaciones y empleando distintas maneras de operacionalizar la variable ingresos.\n\rEstimación\rfit01\u0026lt;-lm(partpol~sexo+edad+ing_pcap+pospol,data=elsoc)\rfit02\u0026lt;-lm(partpol~sexo+edad+quintile+pospol,data=elsoc)\rfit03\u0026lt;-lm(partpol~sexo+edad+quintilemiss+pospol,data=elsoc)\rlabs01 \u0026lt;-c(\u0026quot;Intercepto\u0026quot;,\u0026quot;Sexo (mujer=1)\u0026quot;,\u0026quot;Edad\u0026quot;,\u0026quot;Ingreso per/cap\u0026quot;,\u0026quot;Centro (ref. derecha)\u0026quot;,\u0026quot;Izquierda\u0026quot;,\u0026quot;Idep./Ninguno\u0026quot;,\r\u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;,\r\u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;,\u0026quot;Quintil perdido\u0026quot;)\rhtmlreg(list(fit01,fit02,fit03),doctype = FALSE, \rcustom.model.names = c(\u0026quot;Modelo 1\u0026quot;,\u0026quot;Modelo 2\u0026quot;,\u0026quot;Modelo 3\u0026quot;),\rcustom.coef.names = labs01)\rStatistical models\r\r\r\r\rModelo 1\r\rModelo 2\r\rModelo 3\r\r\r\rIntercepto\r\r8.27***\r\r7.94***\r\r7.97***\r\r\r\r\r(0.14)\r\r(0.16)\r\r(0.16)\r\r\r\rSexo (mujer=1)\r\r0.05\r\r0.13\r\r0.12\r\r\r\r\r(0.07)\r\r(0.08)\r\r(0.07)\r\r\r\rEdad\r\r-0.04***\r\r-0.04***\r\r-0.04***\r\r\r\r\r(0.00)\r\r(0.00)\r\r(0.00)\r\r\r\rIngreso per/cap\r\r0.00***\r\r\r\r\r\r\r(0.00)\r\r\r\r\r\rCentro (ref. derecha)\r\r-1.02***\r\r-1.04***\r\r-1.04***\r\r\r\r\r(0.10)\r\r(0.10)\r\r(0.10)\r\r\r\rIzquierda\r\r-1.10***\r\r-1.12***\r\r-1.13***\r\r\r\r\r(0.11)\r\r(0.11)\r\r(0.11)\r\r\r\rIdep./Ninguno\r\r-1.59***\r\r-1.58***\r\r-1.60***\r\r\r\r\r(0.10)\r\r(0.10)\r\r(0.10)\r\r\r\rQuintil 2\r\r\r0.22\r\r0.21\r\r\r\r\r\r(0.11)\r\r(0.11)\r\r\r\rQuintil 3\r\r\r0.51***\r\r0.51***\r\r\r\r\r\r(0.11)\r\r(0.11)\r\r\r\rQuintil 4\r\r\r0.51***\r\r0.50***\r\r\r\r\r\r(0.11)\r\r(0.11)\r\r\r\rQuintil 5\r\r\r0.89***\r\r0.88***\r\r\r\r\r\r(0.12)\r\r(0.12)\r\r\r\rQuintil perdido\r\r\r\r0.59***\r\r\r\r\r\r\r(0.18)\r\r\r\rR2\r\r0.17\r\r0.17\r\r0.17\r\r\r\rAdj. R2\r\r0.16\r\r0.17\r\r0.17\r\r\r\rNum. obs.\r\r3475\r\r3475\r\r3656\r\r\r\rRMSE\r\r2.10\r\r2.09\r\r2.10\r\r\r\rp \u0026lt; 0.001, p \u0026lt; 0.01, p \u0026lt; 0.05\r\r\r\rDiágnosticos\rCasos influyentes\rPara determinar si un outlier es un caso influyente, es decir que su presencia/ausencia genera un cambio importante en la estimación de los coeficientes de regresión, calculamos la Distancia de Cook..\nPosteriormente, se establece un punto de corte de \\(4/(n-k-1)\\):\nn\u0026lt;-nobs(fit03) #n de observaciones\rk\u0026lt;-length(coef(fit03)) # n de parametros\rdcook\u0026lt;-4/(n-k-1) #punt de corte\rSi lo graficamos se ve de la siguiente manera:\nfinal \u0026lt;-broom::augment_columns(fit03,data = elsoc)\rfinal$id \u0026lt;-as.numeric(row.names(final))\r# identify obs with Cook\u0026#39;s D above cutoff\rggplot(final, aes(id, .cooksd))+\rgeom_bar(stat=\u0026quot;identity\u0026quot;, position=\u0026quot;identity\u0026quot;)+\rxlab(\u0026quot;Obs. Number\u0026quot;)+ylab(\u0026quot;Cook\u0026#39;s distance\u0026quot;)+\rgeom_hline(yintercept=dcook)+\rgeom_text(aes(label=ifelse((.cooksd\u0026gt;dcook),id,\u0026quot;\u0026quot;)),\rvjust=-0.2, hjust=0.5)\rIdentificamos los casos influyentes y filtramos la base de datos:\nident\u0026lt;-final %\u0026gt;%filter(.cooksd\u0026gt;dcook)\relsoc02 \u0026lt;-final %\u0026gt;%filter(!(id %in%ident$id))\rEstimación sin casos influyentes:\nfit04\u0026lt;-lm(partpol~sexo+edad+quintilemiss+pospol,data=elsoc02)\rlabs02 \u0026lt;-c(\u0026quot;Intercepto\u0026quot;,\u0026quot;Sexo (mujer=1)\u0026quot;,\u0026quot;Edad\u0026quot;,\r\u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;,\u0026quot;Quintil perdido\u0026quot;,\r\u0026quot;Izquierda (ref. derecha)\u0026quot;,\u0026quot;Centro\u0026quot;,\u0026quot;Idep./Ninguno\u0026quot;)\r\rhtmlreg(list(fit03,fit04), \rdoctype = FALSE,\rcustom.model.names = c(\u0026quot;Modelo 3\u0026quot;, \u0026quot;Modelo 4\u0026quot;),\rcustom.coef.names = labs02)\rStatistical models\r\r\r\r\rModelo 3\r\rModelo 4\r\r\r\rIntercepto\r\r7.97***\r\r7.05***\r\r\r\r\r(0.16)\r\r(0.11)\r\r\r\rSexo (mujer=1)\r\r0.12\r\r0.07\r\r\r\r\r(0.07)\r\r(0.05)\r\r\r\rEdad\r\r-0.04***\r\r-0.03***\r\r\r\r\r(0.00)\r\r(0.00)\r\r\r\rQuintil 2\r\r0.21\r\r0.11\r\r\r\r\r(0.11)\r\r(0.08)\r\r\r\rQuintil 3\r\r0.51***\r\r0.34***\r\r\r\r\r(0.11)\r\r(0.08)\r\r\r\rQuintil 4\r\r0.50***\r\r0.32***\r\r\r\r\r(0.11)\r\r(0.08)\r\r\r\rQuintil 5\r\r0.88***\r\r0.57***\r\r\r\r\r(0.12)\r\r(0.08)\r\r\r\rQuintil perdido\r\r0.59***\r\r0.31*\r\r\r\r\r(0.18)\r\r(0.13)\r\r\r\rIzquierda (ref. derecha)\r\r-1.04***\r\r-0.65***\r\r\r\r\r(0.10)\r\r(0.07)\r\r\r\rCentro\r\r-1.13***\r\r-0.71***\r\r\r\r\r(0.11)\r\r(0.08)\r\r\r\rIdep./Ninguno\r\r-1.60***\r\r-1.14***\r\r\r\r\r(0.10)\r\r(0.07)\r\r\r\rR2\r\r0.17\r\r0.18\r\r\r\rAdj. R2\r\r0.17\r\r0.18\r\r\r\rNum. obs.\r\r3656\r\r3460\r\r\r\rRMSE\r\r2.10\r\r1.48\r\r\r\rp \u0026lt; 0.001, p \u0026lt; 0.01, p \u0026lt; 0.05\r\r\r\rEn términos generales, el sentido y significación estadística de los coeficientes del Modelo 4 se mantiene respecto al Modelo 3. Adicionalmente, si observamos que el modelo sin casos influyentes presenta una mejora en ajuste. Por lo tanto, los análisis posteriores se realizaran en base a este modelo.\n\rLinealidad\rPara analizar la linealidad respecto de un modelo de regresión, debemos analizar la distribución de los residuos con respecto a la recta de regresión.\n\rLos residuos deben ser independientes de los valores predichos (fitted values).\rCualquier correlación entre residuo y valores predichos violarían este supuesto.\rLa presencia de un patrón no lineal, es señal de que el modelo está especificado incorrectamente.\r\rggplot(fit04, aes(.fitted, .resid)) +\rgeom_point() +\rgeom_hline(yintercept = 0) +\rgeom_smooth(se = TRUE)\r\rFigure 1: Relación entre residuos y valores predichos\r\rEl gráfico nos indica que existe un patrón en la distribución de los residuos. Para intentar mejorar la estimación podemos realizar una transformación de variables. A continuación presentaremos un ejemplo para la Edad y para los Ingresos.\n\rPolinomio: \\(\\text{Edad}^2\\)\r\relsoc02$edad2 \u0026lt;-elsoc02$edad^2\rfit05\u0026lt;-lm(partpol~sexo+edad+edad2+quintilemiss+pospol,data=elsoc02)\redad\u0026lt;-fit05$model$edad\rfit\u0026lt;-fit05$fitted.values\rdata01 \u0026lt;-as.data.frame(cbind(edad,fit))\r\rggplot(data01, aes(x = edad, y = fit)) +\rtheme_bw() +\rgeom_point()+\rgeom_smooth()\r\rFigure 2: Efecto cuadrático de la edad (Modelo 5)\r\r\rLogaritmo: \\(\\log(\\text{ingreso})\\)\r\relsoc02$lningreso \u0026lt;-log(elsoc02$ing_pcap)\relsoc02$lningreso \u0026lt;-set_label(elsoc02$lningreso,\u0026quot;log(ingreso per cap)\u0026quot;)\rfit06 \u0026lt;-lm(partpol~sexo+edad+edad2+lningreso+pospol,data=elsoc02)\rplot_frq(elsoc02$ing_pcap,type = \u0026quot;hist\u0026quot;,normal.curve = T, show.mean = T)\rplot_frq(elsoc02$lningreso,type = \u0026quot;hist\u0026quot;, normal.curve = T,show.mean = T)\rlabs03 \u0026lt;-c(\u0026quot;Intercepto\u0026quot;,\u0026quot;Sexo (mujer=1)\u0026quot;,\u0026quot;Edad\u0026quot;,\r\u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;,\u0026quot;Quintil perdido\u0026quot;,\r\u0026quot;Izquierda (ref. derecha)\u0026quot;,\u0026quot;Centro\u0026quot;,\u0026quot;Idep./Ninguno\u0026quot;, \u0026quot;Edad²\u0026quot;,\u0026quot;Ingreso per cap (log)\u0026quot;)\r\rhtmlreg(list(fit04, fit05, fit06), doctype = FALSE,\rcustom.model.names = c(\u0026quot;Modelo 4\u0026quot;, \u0026quot;Modelo 5\u0026quot;, \u0026quot;Modelo 6\u0026quot;), \rcustom.coef.names = labs03)\rStatistical models\r\r\r\r\rModelo 4\r\rModelo 5\r\rModelo 6\r\r\r\rIntercepto\r\r7.05***\r\r7.62***\r\r4.98***\r\r\r\r\r(0.11)\r\r(0.24)\r\r(0.46)\r\r\r\rSexo (mujer=1)\r\r0.07\r\r0.08\r\r0.09\r\r\r\r\r(0.05)\r\r(0.05)\r\r(0.05)\r\r\r\rEdad\r\r-0.03***\r\r-0.06***\r\r-0.06***\r\r\r\r\r(0.00)\r\r(0.01)\r\r(0.01)\r\r\r\rQuintil 2\r\r0.11\r\r0.11\r\r\r\r\r\r(0.08)\r\r(0.08)\r\r\r\r\rQuintil 3\r\r0.34***\r\r0.34***\r\r\r\r\r\r(0.08)\r\r(0.08)\r\r\r\r\rQuintil 4\r\r0.32***\r\r0.32***\r\r\r\r\r\r(0.08)\r\r(0.08)\r\r\r\r\rQuintil 5\r\r0.57***\r\r0.57***\r\r\r\r\r\r(0.08)\r\r(0.08)\r\r\r\r\rQuintil perdido\r\r0.31*\r\r0.31*\r\r\r\r\r\r(0.13)\r\r(0.13)\r\r\r\r\rIzquierda (ref. derecha)\r\r-0.65***\r\r-0.65***\r\r-0.63***\r\r\r\r\r(0.07)\r\r(0.07)\r\r(0.08)\r\r\r\rCentro\r\r-0.71***\r\r-0.70***\r\r-0.70***\r\r\r\r\r(0.08)\r\r(0.08)\r\r(0.08)\r\r\r\rIdep./Ninguno\r\r-1.14***\r\r-1.13***\r\r-1.12***\r\r\r\r\r(0.07)\r\r(0.07)\r\r(0.07)\r\r\r\rEdad²\r\r\r0.00**\r\r0.00**\r\r\r\r\r\r(0.00)\r\r(0.00)\r\r\r\rIngreso per cap (log)\r\r\r\r0.24***\r\r\r\r\r\r\r(0.03)\r\r\r\rR2\r\r0.18\r\r0.19\r\r0.19\r\r\r\rAdj. R2\r\r0.18\r\r0.18\r\r0.18\r\r\r\rNum. obs.\r\r3460\r\r3460\r\r3305\r\r\r\rRMSE\r\r1.48\r\r1.47\r\r1.48\r\r\r\rp \u0026lt; 0.001, p \u0026lt; 0.01, p \u0026lt; 0.05\r\r\r\rInterpretación: Vemos que el coeficiente de lningreso es de 0.24, sin embargo, debido a que la unidad de medida es logarítmica decimos que por una unidad de porcentaje (1%) de incremento en los ingresos per cápita del hogar, el promedio del índice de participación política aumenta en 0.24/100 = 0.0024, manteniendo todas las demás variables constantes. El coeficiente es estadísticamente significativo a uno 99.9% de confianza. En este caso particular, no es muy informativo, pero corresponde a una manera de especificar un modelo con los ingresos como una variable logaritmizada para hacernos cargo de posible problemas de linealidad.\nDebemos tener cautela al interpretar el ajuste del Modelo 5 y 6 debido a que las observaciones empleadas no son las mismas (3462 comparado con 3304) debido a que en el Modelo 5 se incluye la variable ingresos en quintiles con la categoría adicional para los casos perdidos. En este caso, realizamos la especificación a modo de ejemplo. Por lo tanto, seguiremos trabajando con el Modelo 5 para realizar los análisis posteriores.\n\r\r\rTest homogeneidad de varianza\rcar::ncvTest(fit05)\r## Non-constant Variance Score Test ## Variance formula: ~ fitted.values ## Chisquare = 521.5278, Df = 1, p = \u0026lt; 2.22e-16\rlmtest::bptest(fit05)\r## ## studentized Breusch-Pagan test\r## ## data: fit05\r## BP = 385.59, df = 11, p-value \u0026lt; 2.2e-16\rTanto el test Breush-Pagan como el de Cook-Weisberg nos indican que existen problemas con respecto a homogeneidad en la distribución de los residuos del modelo debido a que \\(p\u0026gt;0.05\\) en ambos casos. Es decir, se rechaza \\(H_0\\) donde se asume que la varianza del error es constante, lo cual nos indica que tenemos problemas de heterocedasticidad en los residuos.\nPara hacer frente a este problema, debemos calcular los errores estándar robustos para nuestra última estimación para corregir problemas de heterocedasticidad y así estimar el último modelo nuevamente:\nmodel_robust\u0026lt;-coeftest(fit05, vcov=vcovHC)\rComparemos los resultados:\nlabs04 \u0026lt;-c(\u0026quot;Intercepto\u0026quot;,\u0026quot;Sexo (mujer=1)\u0026quot;,\u0026quot;Edad\u0026quot;,\r\u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;,\u0026quot;Quintil perdido\u0026quot;,\r\u0026quot;Izquierda (ref. derecha)\u0026quot;,\u0026quot;Centro\u0026quot;,\u0026quot;Idep./Ninguno\u0026quot;, \u0026quot;Edad²\u0026quot;)\r\rhtmlreg(list(fit04, fit05, model_robust), doctype = FALSE,\rcustom.model.names = c(\u0026quot;Modelo 4\u0026quot;,\u0026quot;Modelo 5\u0026quot;, \u0026quot;M5 Robust\u0026quot;), custom.coef.names = labs04)\rStatistical models\r\r\r\r\rModelo 4\r\rModelo 5\r\rM5 Robust\r\r\r\rIntercepto\r\r7.05***\r\r7.62***\r\r7.62***\r\r\r\r\r(0.11)\r\r(0.24)\r\r(0.27)\r\r\r\rSexo (mujer=1)\r\r0.07\r\r0.08\r\r0.08\r\r\r\r\r(0.05)\r\r(0.05)\r\r(0.05)\r\r\r\rEdad\r\r-0.03***\r\r-0.06***\r\r-0.06***\r\r\r\r\r(0.00)\r\r(0.01)\r\r(0.01)\r\r\r\rQuintil 2\r\r0.11\r\r0.11\r\r0.11\r\r\r\r\r(0.08)\r\r(0.08)\r\r(0.07)\r\r\r\rQuintil 3\r\r0.34***\r\r0.34***\r\r0.34***\r\r\r\r\r(0.08)\r\r(0.08)\r\r(0.08)\r\r\r\rQuintil 4\r\r0.32***\r\r0.32***\r\r0.32***\r\r\r\r\r(0.08)\r\r(0.08)\r\r(0.08)\r\r\r\rQuintil 5\r\r0.57***\r\r0.57***\r\r0.57***\r\r\r\r\r(0.08)\r\r(0.08)\r\r(0.09)\r\r\r\rQuintil perdido\r\r0.31*\r\r0.31*\r\r0.31**\r\r\r\r\r(0.13)\r\r(0.13)\r\r(0.12)\r\r\r\rIzquierda (ref. derecha)\r\r-0.65***\r\r-0.65***\r\r-0.65***\r\r\r\r\r(0.07)\r\r(0.07)\r\r(0.09)\r\r\r\rCentro\r\r-0.71***\r\r-0.70***\r\r-0.70***\r\r\r\r\r(0.08)\r\r(0.08)\r\r(0.09)\r\r\r\rIdep./Ninguno\r\r-1.14***\r\r-1.13***\r\r-1.13***\r\r\r\r\r(0.07)\r\r(0.07)\r\r(0.08)\r\r\r\rEdad²\r\r\r0.00**\r\r0.00**\r\r\r\r\r\r(0.00)\r\r(0.00)\r\r\r\rR2\r\r0.18\r\r0.19\r\r\r\r\rAdj. R2\r\r0.18\r\r0.18\r\r\r\r\rNum. obs.\r\r3460\r\r3460\r\r\r\r\rRMSE\r\r1.48\r\r1.47\r\r\r\r\rp \u0026lt; 0.001, p \u0026lt; 0.01, p \u0026lt; 0.05\r\r\r\rLos resultados del modelo con errores estándar robustos, nos indica que nuestras estimaciones son robustas a la presencia de heterocedasticidad en los residuos debido a que la significancia de los coeficientes se mantiene si lo comparamos con Modelo 4.\n\rMulticolinealidad\rcar::vif(fit04)\rcar::vif(fit05)\r## GVIF Df GVIF^(1/(2*Df))\r## sexo 1.057775 1 1.028482\r## edad 1.012463 1 1.006212\r## quintilemiss 1.085365 5 1.008225\r## pospol 1.041316 3 1.006770\r## GVIF Df GVIF^(1/(2*Df))\r## sexo 1.058907 1 1.029032\r## edad 38.308809 1 6.189411\r## edad2 38.275011 1 6.186680\r## quintilemiss 1.087725 5 1.008444\r## pospol 1.042085 3 1.006894\rEntonces, asumiendo que valores del VIF mayores a 2.5, vemos que en el modelo que no incorpora el término cuadrático de edad no tendríamos problemas de multicolinealidad. Sin embargo, al incorporar el término cuadrático, nos muestra un VIF de 6.2 en la variable edad y edad2.\nReferencias\rDarlington \u0026amp; Hayes 2016 Cap16 Detecting and Managing Irregularities\nDarlington \u0026amp; Hayes 2016 Cap12 Nonlinear relationships\n\r\rReporte de progreso\rContestar aquí.\n\rForo práctica 11\r\r","date":1597968000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1597721378,"objectID":"5594772ee389e3a8f923e29a8eccc9c3","permalink":"/assignment/11-code/","publishdate":"2020-08-21T00:00:00Z","relpermalink":"/assignment/11-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 11: Transformación de variables y supuestos de regresión","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de la clase\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r","date":1597363200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1597449087,"objectID":"187acf4fd964c835bff8f91f793da537","permalink":"/class/11-class/","publishdate":"2020-08-14T00:00:00Z","relpermalink":"/class/11-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de la clase\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r","tags":null,"title":"11: Supuestos","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo\rLibrerías\rDatos\rExplorar datos\r\rEstimación\rPresentación de resultados\rTabla de regresión\rRegresión logística sin predictores\rRegresión logistica con variable binaria como predictor\rRegresión logística con variable continua como predictor\rRegresión logística con múltiples predictores\r\r\rMedidas de Ajuste\rTest de Devianza\rPseudo-R2 de McFadden\rPresentación de resultados\rReferencias\r\rReporte de progreso\rForo práctica 10\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo\rLa siguiente práctica tiene el objetivo de introducir a los estudiantes en los modelos de regresión logística multivariada. Al igual que en la práctica anterior emplearemos una variable dependiente dicotómica, de modo tal que veremos de qué una serie de variables independientes nos permiten predecir la ocurrencia de un determinado evento. Para ello, utilizaremos la base de datos de la Encuesta sobre Conflicto y Cohesion Social en Chile 2014 para analizar los determinantes de la participación en las elecciones del año 2013.\n\rLibrerías\rpacman::p_load(dplyr, summarytools, ggmosaic, sjPlot, texreg)\r\rDatos\rLa Encuesta sobre Conflicto y Cohesión Social en Chile (ENACOES 2014) es el primer estudio de este tipo que busca mapear los conflictos y la cohesión en el país. Su objetivo fundamental es aportar a la comprensión de las creencias, actitudes y percepciones de los chilenos hacia las distintas dimensiones de la convivencia y el conflicto. La población objetivo son hombre y mujeres entre 15 y 75 años de edad con un alcance nacional, donde se obtuvo una muestra final de 2025 casos. Para el caso de este ejercicio, se trabajara con una submuestra de 1974 individuos que estuvieron habilitados para votar en el año 2013.\n#Cargamos la base de datos desde internet\rload(url(\u0026quot;https://multivariada.netlify.com/assignment/data/enacoes.RData\u0026quot;))\rExplorar datos\rA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(enacoes, headings = FALSE, method = \u0026quot;render\u0026quot;))\r\r\rNo\rVariable\rLabel\rStats / Values\rFreqs (% of Valid)\rGraph\rValid\rMissing\r\r\r\r\r1\rvoto\r[factor]\rVot\u0026#0243; en \u0026#0250;ltima elecci\u0026#0243;n\r1. 0\r2. 1\r649(32.9%)1325(67.1%)\r\r1974\r(100%)\r0\r(0%)\r\r\r2\rsexo\r[factor]\rSexo entrevistado\r1. 0\r2. 1\r803(40.7%)1171(59.3%)\r\r1974\r(100%)\r0\r(0%)\r\r\r3\redad\r[numeric]\rEdad entrevistado\rMean (sd) : 45.1 (16)\rmin 58 distinct values\r\r1974\r(100%)\r0\r(0%)\r\r\r4\reduc\r[factor]\rNivel Educacional\r1. 1\r2. 2\r3. 3\r4. 4\r5. 5\r179(9.1%)167(8.5%)878(44.5%)513(26.0%)237(12.0%)\r\r1974\r(100%)\r0\r(0%)\r\r\r\rGenerated by summarytools 0.9.6 (R version 4.0.0)2020-08-10\n\rLo primero que debemos observar es la distribución de la participación electoral, donde 0 son quienes nos votaron en la última elección y 1 los que sí lo hicieron. En este caso, vemos que un 67,1% (1325) señaló haber participado en la última elección, en contraste de un 32,9% que no lo hizo. En este sentido, vemos que existen aproximadamente 2/3 de los individuos de la muestra que sí acudieron a votar, por tanto ahora vamos a revisar cómo se distribuyen estas respuestas según el sexo y el nivel educacional de el entrevistado.\nEn primera instancia nos centraremos en las variables sexo y voto. Como podemos notar la categoría de respuesta de estas variables son 0 y 1, es decir, estamos ante variables dicotómicas.\nEn segunda instancia, observaremos la distribución de participación electoral según el Nivel educacional (educ), la cual en este caso hemos recodificado en cinco niveles educacionales.\nCon la función tab_xtab del paquete sjPlot podemos realizar una tabla de contingencia donde se señala la proporción de la participación electoral según sexo.\ntab_xtab(var.row = enacoes$voto,enacoes$sexo,show.cell.prc = T,show.summary = F)\r\rVotó en última\nelección\r\rSexo entrevistado\r\rTotal\r\r\r\rHombre\r\rMujer\r\r\r\rNo votó\r\r254\n12.9 %\r\r395\n20 %\r\r649\n32.9 %\r\r\r\rVotó\r\r549\n27.8 %\r\r776\n39.3 %\r\r1325\n67.1 %\r\r\r\rTotal\r\r803\n40.7 %\r\r1171\n59.3 %\r\r1974\n100 %\r\r\r\rTeniendo en cuenta que existen 2/3 (67,1%) de las personas en Chile que han declarado haber votado en la última elección, la tabla anterior nos muestra que del total de personas que votan, las participación electoral es mayor en las mujeres, lo cual equivale a un 39,3% del total en desmedro del 27,8% que representado por los hombres.\ntab_xtab(var.row = enacoes$voto,enacoes$educ,\rshow.cell.prc = T,show.summary = F, encoding = \u0026quot; \u0026quot;)\r\rVotó en última\nelección\r\rNivel Educacional\r\rTotal\r\r\r\rPrimaria incompleta\no menos\r\rPrimaria\r\rSecundaria\r\rTécnica Superior\r\rUniversitaria o\npostgrado\r\r\r\rNo votó\r\r55\n2.8 %\r\r47\n2.4 %\r\r320\n16.2 %\r\r182\n9.2 %\r\r45\n2.3 %\r\r649\n32.9 %\r\r\r\rVotó\r\r124\n6.3 %\r\r120\n6.1 %\r\r558\n28.3 %\r\r331\n16.8 %\r\r192\n9.7 %\r\r1325\n67.2 %\r\r\r\rTotal\r\r179\n9.1 %\r\r167\n8.5 %\r\r878\n44.5 %\r\r513\n26 %\r\r237\n12 %\r\r1974\n100 %\r\r\r\rAdicionalmente, la tabla anterior nos muestra la distribución de la participación electoral según cinco categorías de nivel educacional. Como podemos observar, la participación electoral se concentra en los niveles educacionales secundario con un 28,3% y superior técnica y universitaria, con un 16,8% y 9,7% respectivamente. Por otro lado, podemos observar una baja participación electoral de los grupos con nivel educacional más bajo, donde las personas con Primaria incompleta o menos representan un 6,3% y aquellas con Primaria completa son el 6,1%.\nAl igual que la práctica anterior, podemos representar gráficamente estas distribuciones a través del paquete ggmosaic que con su función geom_mosaic. A continuación se presentan dos gráficos para la participación electoral según sexo y nivel educacional.\nggplot(enacoes) +\rgeom_mosaic(aes(x=product(voto, sexo), fill=sexo)) +\rgeom_label(data = layer_data(last_plot(), 1),\raes(x = (xmin +xmax)/2,\ry = (ymin +ymax)/2,\rlabel = paste0(round((.wt/sum(.wt))*100,1),\u0026quot;%\u0026quot;))) +\rlabs(y = \u0026quot;Voto última elección\u0026quot;,\rx = \u0026quot;Sexo\u0026quot;) +\rscale_fill_discrete(name = \u0026quot;\u0026quot;,\rlabels = c(\u0026quot;Hombre\u0026quot;,\u0026quot;Mujer\u0026quot;))+\rscale_y_continuous(breaks = c(0,1),\rlabels = c(\u0026quot;No votó\u0026quot;,\u0026quot;Votó\u0026quot;)) +\rtheme(legend.position=\u0026quot;bottom\u0026quot;)\r\r\rggplot(enacoes) +\rgeom_mosaic(aes(x=product(voto, educ), fill=educ)) +\rgeom_label(data = layer_data(last_plot(), 1),\raes(x = (xmin + xmax)/2,\ry = (ymin + ymax)/2,\rlabel = paste0(round((.wt/sum(.wt))*100,1),\u0026quot;%\u0026quot;))) +\rlabs(y = \u0026quot;Voto última elección\u0026quot;,\rx = \u0026quot;Nivel Educacional\u0026quot;) +\rscale_fill_discrete(name = \u0026quot;\u0026quot;,\rlabels = c(\u0026quot;Primaria incompleta o menos\u0026quot;,\r\u0026quot;Primaria\u0026quot;,\r\u0026quot;Secundaria\u0026quot;, \u0026quot;Técnica o Superior\u0026quot;,\r\u0026quot;Universitaria o postgrado\u0026quot;))+\rscale_y_continuous(breaks = c(0,1),labels = c(\u0026quot;No votó\u0026quot;,\u0026quot;Votó\u0026quot;)) +\rtheme(legend.position=\u0026quot;bottom\u0026quot;)\r\rFigure 1: Participación electoral en 2013 según Sexo y Nivel Educacional\r\r\r\rEstimación\rLa función pincipal para la estimación de modelos de regresión logística es glm(), especificando el argumento family=\"binomial\", lo cual le indica a la función que estamos prediciendo una variable binaria. Al igual que con lm(), debemos especificar los predictores y la base de datos a emplear. A continuación, estimaremos una serie de modelos de regresión logística que nos permitan determinar de qué manera el sexo, la edad y el nivel educacional de las personas pueden predecir la participación electoral.\nAqui ecuacion del logit(p) = --\rm00 \u0026lt;-glm(voto~1,data = enacoes,family = \u0026quot;binomial\u0026quot;)\rm01 \u0026lt;-glm(voto~sexo,data = enacoes,family = \u0026quot;binomial\u0026quot;)\rm02 \u0026lt;-glm(voto~edad,data = enacoes,family = \u0026quot;binomial\u0026quot;)\rm03 \u0026lt;-glm(voto~sexo+edad+educ,data = enacoes,family = \u0026quot;binomial\u0026quot;)\rPresentación de resultados\rPara construir una tabla de regresión podemos usar la librería texreg:\nEsto se puede hacer si se utiliza RMarkdown (no es requisito en este curso, para los interesad_s pueden revisar material del curso ciencia social abierta )\nInstalar librería texreg. Si bien existe una versión en CRAN, no nos permite usar el argumento custom.gof.rows para agregar estadísticos de ajuste adicionales, así que para instalar:remotes::install_github(\"leifeld/texreg\")\n\rExisten tres variaciones para crear tablas:\n\rscreenreg(): nos muestra la tabla en la consola de R\rhtmlreg(): produce una tabla en formato html (como las que vemos en este documento)\rtexreg(): produce una tabla en formato \\(\\LaTeX\\) para documentos en pdf.\r\rPara que el resultado pueda ser renderizado desde un documento RMarkdown a pdf o html, debe estar en un chunk con las siguientes especificaciones:\n\r\r```{r results=\u0026#39;asis\u0026#39;, echo=FALSE}\rhtmlreg(list(m01,m02,m03))\r```\rPara personalizar nuestra tabla podemos ir agregando más información, tales como los nombres de los coeficientes o el nombre de los modelos:\r\r```{r results=\u0026#39;asis\u0026#39;, echo=FALSE}\rhtmlreg(l = list(m00,m01,m02,m03),\rcustom.coef.names=c(\u0026quot;Intercepto\u0026quot;,\u0026quot;Sexo (Mujer=1)\u0026quot;,\u0026quot;Edad\u0026quot;,\u0026quot;Primaria\u0026quot;,\u0026quot;Secundaria\u0026quot;, \u0026quot;Técnica o Superior\u0026quot;,\u0026quot;Universitaria o postgrado\u0026quot;),\rcustom.model.names = c(\u0026quot;Modelo 0\u0026quot;,\u0026quot;Modelo 1\u0026quot;,\u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;))\r```\r\r\rTabla de regresión\r\r\r\rModelo 0\r\rModelo 1\r\rModelo 2\r\rModelo 3\r\r\r\rIntercepto\r\r0.71***\r\r0.77***\r\r-1.07***\r\r-2.04***\r\r\r\r\r(0.05)\r\r(0.08)\r\r(0.15)\r\r(0.29)\r\r\r\rSexo (Mujer=1)\r\r\r-0.10\r\r\r-0.02\r\r\r\r\r\r(0.10)\r\r\r(0.10)\r\r\r\rEdad\r\r\r\r0.04***\r\r0.05***\r\r\r\r\r\r\r(0.00)\r\r(0.00)\r\r\r\rPrimaria\r\r\r\r\r0.34\r\r\r\r\r\r\r\r(0.25)\r\r\r\rSecundaria\r\r\r\r\r0.47*\r\r\r\r\r\r\r\r(0.19)\r\r\r\rTécnica o Superior\r\r\r\r\r0.88***\r\r\r\r\r\r\r\r(0.22)\r\r\r\rUniversitaria o postgrado\r\r\r\r\r1.53***\r\r\r\r\r\r\r\r(0.25)\r\r\r\rAIC\r\r2502.30\r\r2503.34\r\r2334.32\r\r2290.54\r\r\r\rLog Likelihood\r\r-1250.15\r\r-1249.67\r\r-1165.16\r\r-1138.27\r\r\r\rDeviance\r\r2500.30\r\r2499.34\r\r2330.32\r\r2276.54\r\r\r\rNum. obs.\r\r1974\r\r1974\r\r1974\r\r1974\r\r\r\r\\(^{***}\\) p \u0026lt; 0.001; \\(^{**}\\) p \u0026lt; 0.01; \\(^{*}\\) p \u0026lt; 0.05 Errores estándar entre paréntesis\r\r\r\rEn la tabla anterior podemos observar cuatro modelos distintos:\n\r\rModelo\rPredictores\r\r\r\rModelo 0\rmodelo nulo (sin predictores)\r\rModelo 1\rIncluye sexo\r\rModelo 2\rIncluye edad\r\rModelo 3\rIncluye sexo, edad y nivel educacional\r\r\r\rRegresión logística sin predictores\r\\[logit(p) = \\beta_{0}\\]\nEl modelo sin predictores nos permite conocer la probabilidad de votar. En este caso, vemos que se obtiene un intercepto de 0.71 correspondiente a \\(log(p/1-p)\\). En este caso \\(p\\) es la probabilidad de que una persona participe en las elecciones como votante (voto = 1). Miremos nuevamente la distribución de la participación electoral:\n\r\r\r\r\rval\rlabel\rfrq\rraw.prc\rvalid.prc\rcum.prc\r\r\r\r0\rNo votó\r649\r32.88\r32.88\r32.88\r\r1\rVotó\r1325\r67.12\r67.12\r100.00\r\r\r\r\r\r\r\rEntonces, tenemos que \\(p =1325/1974 = .67\\). Por tanto, la odds calculadas corresponden a 0.67/(1-0.67) =2.03, lo cual en unidades de log(odds) corresponde al valore del intercepto que es 0.71. En otras palabras el intercepto del modelo sin predictores nos entrega la log-odds de votar en las elecciones. Adicionalmente, podemos transformar nuevamente a unidades de probabilidad de la siguiente manera: p = exp(0.71)/(1 + exp(0.71))= 0.67.\n\rRegresión logistica con variable binaria como predictor\r\\[logit(p) = \\beta_0 + \\beta_{mujer}\\]\nEl modelo con un predictor binario como sexo nos permite estimar la probabilidad de votar para las mujeres (sexo = 1), respecto a los hombres (sexo = 0). En este caso, los resultados muestran el valor del intercepto (0.77) y para sexo (-0.10). Antes de interpretar, demos una mirada a la distribución de la participación electoral según sexo:\n## sexo Hombre Mujer\r## voto ## No votó 254 395\r## Votó 549 776\rEn nuestros datos, ¿cuáles son las chances (odds) de votar para los hombres y para las mujeres? Con la información de la tabla de contingencia podemos realizar los cálculos manualmente: para los hombres (sexo = 0), las odds de votar son (549/803)/(254/803) = 0.683 /0.316 = 2.16. A su vez, para las mujeres, las odds de votar son (776/1171)/(395/1171) = 0.662/0.337 = 1.96. Entonces, las odds ratio para las mujeres respecto de los hombres es (776/395)/(549/254) = (776x254)/(549x395) = 0.907, por lo tanto podemos decir que las odds de votar en las elecciones son son 9,5% (exp(-0.10)-1 = 0.908-1) más bajas para las mujeres respecto a los hombres.\nAhora, si observamos los resultados de la tabla de regresión vemos que el intercepto es 0.77, el cual representa las log-odds para los hombres en tanto corresponde a la categoría de referencia (sexo = 0). Usando las odds de votar para los hombres calculada en el apartado anterior, podemos confirmarlo: log(2.16) = 0.77. A su vez, el log-odds para las mujeres corresponde al log del odds-ratio de las odds de las mujeres y de los hombres calculado anteriormente: log(0.907) = -0.10. El output tradicional de R cuando usamos glm() nos entrega los coeficientes en unidades de log-odds, por tanto es necesario realizar la exponenciación de dichos coeficientes para realizar la interpretación en unidades de odds-ratio.\n\rRegresión logística con variable continua como predictor\r\\[logit(p) = \\beta_0 + \\beta_{edad}\\]\nAhora, estimaremos un modelo empleando la edad como predictor continuo. En este caso, el intercepto corresponde a los log-odds de una persona con “edad 0”. En otras palabras, las odds de votar cuando se tiene edad 0 es exp(-1.07) = 0.343. Lo importante es que si observamos la distribución de la variable edad, vemos que el valor mínimo es 18 años, por tanto, sabemos que este coeficiente no posee una interpretación sustantiva directamente. Lo más relevante es que el intercepto en ese modelo corresponde a los log-odds de votar en el hipotético caso de tener edad cero.\nEntonces, ¿cómo interpretamos el coeficiente de edad?. Para esto, lo ideal es tener en cuenta todos los valores de la ecuación:\n\\[logit(p) = -1.07 + 0.04 \\times edad\\]\nUna manera de hacerlo es fijar edad en algún valor, por ejemplo un sujeto de con 54 años. Entonces, el valor del log-odds para una persona con 54 años es:\n\\(logit(p_{edad54}) = -1.07 + 0.04 \\times 54 = 1.09\\)\nAhora, el valor de los log-odds para una persona con 55 años es:\n\\(logit(p_{edad55}) = -1.07 + 0.04 \\times 55 = 1.13\\)\nEntonces, podemos decir que el coeficiente para edad es la diferencia en el log-odds. En otras palabras, por una unidad de incremento en edad (1 año), el cambio esperado en los log-odds es de 0.04.\nAhora, ¿cómo traducimos este cambio en odds?. Tenemos que:\n\\(\\exp(logit(p_{edad55})-logit(p_{edad54}) = \\frac{\\exp(logit(p_{edad55}))}{\\exp(logit(p_{edad55}))}= \\frac{\\exp(1.13)}{\\exp(1.09)}=\\frac{3.09}{2.97} = 1.04\\)\nFinalmente, podemos decir que por el incremento de una unidad en edad (1 año), se espera ver un incremento aproximado de un 4% en las odds de ir a votar. Este porcentaje no depende de los valores en los cuales se mantenga edad.\n\rRegresión logística con múltiples predictores\r\\[logit(p) = \\beta_0 + \\beta_{\\text{mujer}}+ \\beta_{\\text{edad}}+ \\beta_{\\text{prim}}+ \\beta_{\\text{secu}}+ \\beta_{\\text{técn}}+ \\beta_{\\text{univ}}\\]\nEste ejemplo representa el modelo multivariado para participación electoral. Cada coeficiente prepresenta el cambio predicho en el log-odds de votar por un incremento/cambio en la variable, manteniendo todas las demás variables constantes. Cada coeficiente exponenciado (exp), representa el ratio de dos odds (por ejemplo, mujer respecto a hombre), o el cambio en las odds por el incremento de una unidad de la variable independiente (por ejemplo, un año de edad), manteniendo las demás variables constantes.\nEntonces, si observamos el coeficiente de sexo en el Modelo 3, vemos que el odds-ratio de las mujeres sobre los hombres es de exp(-0.02)= 0.98, es decir que las odds de votar en las elecciones son son 1,9% (exp(-0.02)-1 = 0.98-1) más bajas para las mujeres respecto a los hombres, manteniendo edad y el nivel educacional constante.\nLa variable nivel educacional posee 5 niveles, donde “Primaria incompleta o menos” es la categoría de referencia, por tanto, los coeficientes se deben interpretar respecto dicha categoría. Por ejemplo, tenemos que el odds-ratio para Primaria es de exp(0.34) = 1.40, por lo tanto las odds de votar en las elecciones son 40% (exp(-0.02)-1 = 1.40-1) más altas para las personas que completaron la educación primaria respecto a quienes tienen educación primaria incompleta o menos, manteniendo sexo y edad en valores constantes.\nAhora, observando el log-odds para las personas son educación Universitaria o postgrado podemos calcular que el odds-ratio para esta categoría es de exp(1.53) = 4.61, lo cual nos indica que las odds de votar son 361% exp(1.53)-1 = 4.61-1 más altas para las personas con educación universitaria o postgrado respecto a quienes tienen educación primaria incompleta o menos, manteniendo sexo y edad en valores constantes.\nOtra alternativa de interpretación es a través del cálculo de las probabilidades predichas. Por ejemplo ¿cuál es la probabilidad de votar según los distintos niveles educacionales manteniendo constante sexo y edad?. En este caso usaremos una persona hipotética que es mujer (sexo=1) de 55 años.\nTenemos nuestros coeficientes para el Modelo 3:\nm03$coefficients\r## (Intercept) sexo1 edad educ2 educ3 educ4 ## -2.03578412 -0.02351809 0.04911213 0.33653007 0.46911435 0.88442909 ## educ5 ## 1.52605507\rCalculamos las log-odds para cada caso:\n# Intercept sexo*1 edad*55 educ2 educ3 educ4 educ5\red01\u0026lt;--2.03578412+(-0.0235*1)+(0.0491*55)+(0.3365*0)+(0.4691*0)+(0.8844*0)+(1.5260*0) # mujer 55 anios Primaria incompleta\red02\u0026lt;--2.03578412+(-0.0235*1)+(0.0491*55)+(0.3365*1)+(0.4691*0)+(0.8844*0)+(1.5260*0) # mujer 55 anios Primaria\red03\u0026lt;--2.03578412+(-0.0235*1)+(0.0491*55)+(0.3365*0)+(0.4691*1)+(0.8844*0)+(1.5260*0) # mujer 55 anios Secundaria\red04\u0026lt;--2.03578412+(-0.0235*1)+(0.0491*55)+(0.3365*0)+(0.4691*0)+(0.8844*1)+(1.5260*0) # mujer 55 anios Tecnica\red05\u0026lt;--2.03578412+(-0.0235*1)+(0.0491*55)+(0.3365*0)+(0.4691*0)+(0.8844*0)+(1.5260*1) # mujer 55 anios Universitaria\rCalculamos las probabilidades predichas de la siguiente manera:\n\\[\\text{Probabilidad}= \\frac{\\exp(\\beta_0+\\beta_jX_j)}{1+\\exp(\\beta_0+\\beta_jX_j)} = \\frac{\\text{Odds}}{1+\\text{Odds}}\\]\npr.ed01\u0026lt;-exp(ed01)/(1+exp(ed01))\rpr.ed02\u0026lt;-exp(ed02)/(1+exp(ed02))\rpr.ed03\u0026lt;-exp(ed03)/(1+exp(ed03))\rpr.ed04\u0026lt;-exp(ed04)/(1+exp(ed04))\rpr.ed05\u0026lt;-exp(ed05)/(1+exp(ed05))\rFinalmente, se presenta la tabla resumen a continuación:\n\r\rNivel educacional\rlog-odds\rexp(log-odds)\rexp(odds)/(1-exp(odds)\r\r\r\rPrimaria incompleta o menos\r0.641\r1.899\r0.655\r\rPrimaria\r0.978\r2.658\r0.727\r\rSecundaria\r1.110\r3.035\r0.752\r\rTécnica\r1.526\r4.598\r0.821\r\rUnivsersitaria\r2.167\r8.734\r0.897\r\r\r\rLa librería sjPlot posee la función plot_model() la cual, dentro de otras cosas, nos permite visualizar las probabilidades predichas para un modelo de regresión logística.\nplot_model(m03,type = \u0026quot;pred\u0026quot;,\rterms = \u0026quot;educ\u0026quot;,\rtitle = \u0026quot;Probabilidades predichas para Voto según nivel educacional\u0026quot;) +geom_line()\rEn conjunto, podemos observar que en la medida que aumenta el nivel educacional de las personas, la probabilidad de que participen en las elecciones tiende a ser mayor, manteniendo edad y sexo constante.\n\r\r\rMedidas de Ajuste\rEl ajuste de los modelos de regresión logística puede ser evaluado de distintas maneras. Generalmente se realiza a través del contraste con otros modelos con más o menos predictores, lo cual nos permite elegir entre las mejores especificaciones. Adicionalmente, presentaremos la manera de incorporar estas medidas de ajuste a la tabla de regresión del apartado anterior.\nEn este ejercicio emplearemos (1) Test de Devianza y (2) Pseudo-R2 de McFadden.\nTest de Devianza\rEste test nos permite comparar las verosimilitudes del modelo con predictores, respecto a un modelo con menos predictores. En este caso, emplearemos la función anova() el cual realiza un test basado en la distribución chi-cuadrado donde se contrasta el modelo en cuestión respecto a un modelo sin predictores (modelo “nulo”).\nEn nuestro caso, comparamos nuestro modelo sin predictores con los posteriores modelos para sexo, edad y nivel educacional.\ntest01\u0026lt;-anova(m00,m01,test = \u0026quot;Chisq\u0026quot;)\rtest02\u0026lt;-anova(m00,m02,test = \u0026quot;Chisq\u0026quot;)\rtest03\u0026lt;-anova(m00,m03,test = \u0026quot;Chisq\u0026quot;)\rlrt01\u0026lt;-rbind(test01,test02,test03) %\u0026gt;%unique()\rrow.names(lrt01) \u0026lt;-c(\u0026quot;Modelo nulo\u0026quot;,\r\u0026quot;Modelo 1\u0026quot;,\r\u0026quot;Modelo 2\u0026quot;,\r\u0026quot;Modelo 3\u0026quot;)\rknitr::kable(lrt01,digits = 3, caption = \u0026quot;Test de devianza entre modelos\u0026quot;)\r\rTable 1: Test de devianza entre modelos\r\r\rResid. Df\rResid. Dev\rDf\rDeviance\rPr(\u0026gt;Chi)\r\r\r\rModelo nulo\r1973\r2500.296\r\r\r\r\rModelo 1\r1972\r2499.342\r1\r0.954\r0.329\r\rModelo 2\r1972\r2330.325\r1\r169.971\r0.000\r\rModelo 3\r1967\r2276.545\r6\r223.751\r0.000\r\r\r\rModelo nulo vs. Modelo 1: La diferencia entre los modelos no es estadísticamente significativa con una probabilidad \\(p\\) \u0026gt; 0.05. Por lo tanto el modelo que incluye sexo como predictor no ofrece un mejor ajuste a los datos que un modelo sin predictores.\n\rModelo nulo vs. Modelo 2: La diferencia entre los modelos es estadísticamente significativa con una probabilidad \\(p\\) \u0026lt; 0.001. Por lo tanto el modelo que incluye la edad como predictor ofrece un mejor ajuste a los datos que un modelo sin predictores.\n\rModelo nulo vs. Modelo 3: La diferencia entre los modelos es estadísticamente significativa con una probabilidad \\(p\\) \u0026lt; 0.001. Por lo tanto el modelo que incluye el sexo, edad y nivel educacional como predictores ofrece un mejor ajuste a los datos que un modelo sin predictores.\n\r\rPodemos guardar los valores \\(p\\) de cada modelo para luego incorporarlos en la tabla de regresión:\ntest.pvalues1\u0026lt;-test01$`Pr(\u0026gt;Chi)`[2]\rtest.pvalues2\u0026lt;-test02$`Pr(\u0026gt;Chi)`[2]\rtest.pvalues3\u0026lt;-test03$`Pr(\u0026gt;Chi)`[2]\r\rPseudo-R2 de McFadden\rEsta medida de ajuste nos entrega una magnitud comparativa entre el modelo con predictores y el modelo nulo (sin predictores). Este se basda en los valores del loglikelihood de cada modelo.\n\\(1-\\frac{LL(LM)}{LL(L0)}\\)\n\rLL es el log likelihood del modelo\rLM es el modelo posterior (con predictores)\rL0 es el modelo nulo\r\rPodemos calcularlos manualmente de la siguiente manera:\n1-(logLik(m01)[1]/logLik(m00)[1]) # modelo 1 vs modelo nulo\r1-(logLik(m02)[1]/logLik(m00)[1]) # modelo 2 vs modelo nulo\r1-(logLik(m03)[1]/logLik(m00)[1]) # modelo 3 vs modelo nulo\r## [1] 0.0003817169\r## [1] 0.06798047\r## [1] 0.08948998\rTambién, podemos utilizar la función PseudoR2() de la librería DescTools. A continuación los calculamos y guardamos para incluirlos en la tabla de regresión.\nmfr2.00 \u0026lt;-DescTools::PseudoR2(m00)\rmfr2.01 \u0026lt;-DescTools::PseudoR2(m01)\rmfr2.02 \u0026lt;-DescTools::PseudoR2(m02)\rmfr2.03 \u0026lt;-DescTools::PseudoR2(m03)\rr2\u0026lt;-as.data.frame(cbind(c(mfr2.00,mfr2.01,mfr2.02,mfr2.03)))\rrownames(r2) \u0026lt;-c(\u0026quot;Modelo nulo\u0026quot;,\r\u0026quot;Modelo 1\u0026quot;,\r\u0026quot;Modelo 2\u0026quot;,\r\u0026quot;Modelo 3\u0026quot;)\rknitr::kable(r2,digits = 3, col.names = c(\u0026quot;McFadden R2\u0026quot;))\r\r\rMc\rFadden R2\r\r\r\rModelo nulo\r0.000\r\rModelo 1\r0.000\r\rModelo 2\r0.068\r\rModelo 3\r0.089\r\r\r\rDe esta manera, podemos observar que el cálculo del Pseudo R2 nos indica que el Modelo 1 no aporta mayor a la predicción, en contraste con el Modelo 2 y 3.\n\rPresentación de resultados\rExisten distintas librerías para presentar modelos de regresión, tales como las funciones tab_modeñ() o stargazer() que ya hemos revisado anteriormente. En este caso vamos a usar htmlreg() de la librería texreg. Por defecto, la función nos entrega la siguiente salida:\nhtmlreg(l = list(m03,m03))\r\u0026lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN” “http://www.w3.org/TR/html4/loose.dtd”\u0026gt;\rStatistical models\r\r\r\r\rModel 1\r\rModel 2\r\r\r\r(Intercept)\r\r-2.04***\r\r-2.04***\r\r\r\r\r(0.29)\r\r(0.29)\r\r\r\rsexo1\r\r-0.02\r\r-0.02\r\r\r\r\r(0.10)\r\r(0.10)\r\r\r\redad\r\r0.05***\r\r0.05***\r\r\r\r\r(0.00)\r\r(0.00)\r\r\r\reduc2\r\r0.34\r\r0.34\r\r\r\r\r(0.25)\r\r(0.25)\r\r\r\reduc3\r\r0.47*\r\r0.47*\r\r\r\r\r(0.19)\r\r(0.19)\r\r\r\reduc4\r\r0.88***\r\r0.88***\r\r\r\r\r(0.22)\r\r(0.22)\r\r\r\reduc5\r\r1.53***\r\r1.53***\r\r\r\r\r(0.25)\r\r(0.25)\r\r\r\rAIC\r\r2290.54\r\r2290.54\r\r\r\rBIC\r\r2329.66\r\r2329.66\r\r\r\rLog Likelihood\r\r-1138.27\r\r-1138.27\r\r\r\rDeviance\r\r2276.54\r\r2276.54\r\r\r\rNum. obs.\r\r1974\r\r1974\r\r\r\rp \u0026lt; 0.001, p \u0026lt; 0.01, p \u0026lt; 0.05\r\r\r\rDentro de la misma función, existen más opciones para personalizar el reporte, incluyendo el argumento custom.gof.rows señalado en el apartado anterior, el cual emplearemos para incluirlos resultados delTest de Devianza y el Pseudo R2. En este caso, incluiremos una versión con coeficientes en log-odds del Modelo 3 y su posterior transformación a odds-ratio (OR), además de remplazar los errores estándar por intervalos de confianza.\nPara transformar los coeficientes de log-odds a odds-ratio realizamos lo siguiente:\nor \u0026lt;-texreg::extract(m03)\ror@coef \u0026lt;-exp(or@coef)\rhtmlreg(l = list(m03,or), doctype = F,caption = \u0026quot;\u0026quot;,caption.above = T,\rcustom.model.names = c(\u0026quot;Modelo 3\u0026quot;, \u0026quot;Modelo 3 (OR)\u0026quot;),\rcustom.coef.names = coef.labs,\rci.force = c(TRUE,TRUE),\roverride.coef = list(coef(m03),or@coef),\rcustom.gof.rows=list(\u0026quot;Deviance Test ($p$)\u0026quot; =c(test.pvalues3,\rtest.pvalues3),\r\u0026quot;Pseudo R2\u0026quot; =c(mfr2.03,mfr2.03)),\rcustom.note = \u0026quot;$^{***}$ p \u0026lt; 0.001; $^{**}$ p \u0026lt; 0.01; $^{*}$ p \u0026lt; 0.05 \u0026lt;br\u0026gt; Errores estándar entre paréntesis. \u0026lt;br\u0026gt; **Nota**: La significancia estadística de los coeficientes en unidades de Odds ratio está calculada en base a los valores $t$, \u0026lt;br\u0026gt; los cuales a su vez se calculan en base a $log(Odds)/SE$\u0026quot;)\r\r\r\rModelo 3\r\rModelo 3 (OR)\r\r\r\rIntercepto\r\r-2.04*\r\r0.13\r\r\r\r\r[-2.60; -1.47]\r\r[-0.43; 0.70]\r\r\r\rSexo (Mujer=1)\r\r-0.02\r\r0.98*\r\r\r\r\r[-0.23; 0.18]\r\r[0.77; 1.18]\r\r\r\rEdad\r\r0.05*\r\r1.05*\r\r\r\r\r[0.04; 0.06]\r\r[1.04; 1.06]\r\r\r\rPrimaria\r\r0.34\r\r1.40*\r\r\r\r\r[-0.15; 0.82]\r\r[0.91; 1.89]\r\r\r\rSecundaria\r\r0.47*\r\r1.60*\r\r\r\r\r[0.09; 0.85]\r\r[1.22; 1.98]\r\r\r\rTécnica o Superior\r\r0.88*\r\r2.42*\r\r\r\r\r[0.46; 1.31]\r\r[2.00; 2.84]\r\r\r\rUniversitaria o postgrado\r\r1.53*\r\r4.60*\r\r\r\r\r[1.03; 2.02]\r\r[4.11; 5.09]\r\r\r\rAIC\r\r2290.54\r\r2290.54\r\r\r\rBIC\r\r2329.66\r\r2329.66\r\r\r\rLog Likelihood\r\r-1138.27\r\r-1138.27\r\r\r\rDeviance\r\r2276.54\r\r2276.54\r\r\r\rNum. obs.\r\r1974\r\r1974\r\r\r\r\\(^{***}\\) p \u0026lt; 0.001; \\(^{**}\\) p \u0026lt; 0.01; \\(^{*}\\) p \u0026lt; 0.05 Errores estándar entre paréntesis. Nota: La significancia estadística de los coeficientes en unidades de Odds ratio está calculada en base a los valores \\(t\\), los cuales a su vez se calculan en base a \\(log(Odds)/SE\\)\r\r\r\rUna alternativa a las tablas de regresión son los coefplots. Como hemos visto en prácticas anteriores, este tipo de gráficos muestran el valor de coeficiente acompañados de sus intervalos de confianza. En este caso, vemos que la función plot_model nos entrega por defecto los coeficientes en unidades de odds-ratio, por tanto el valor 1 representa el límite para la significancia estadística, a diferencia del 0 cuando se encuentra en unidades de log-odds. En este caso, conforme a lo presentado en la tabla de regresión, el coeficiente de Edad y Educación Secundaria, Técnica superior y Universitaria poseen intervalos de confianza que no contienen el valor 1, por tanto son estadísticamente signficativos.\nplot02\u0026lt;-plot_model(m03,vline.color = \u0026quot;grey\u0026quot;)\rplot01\u0026lt;-plot_model(m03,vline.color = \u0026quot;grey\u0026quot;,transform = NULL)\rplot_grid(list(plot02,plot01),tags = c(\u0026quot; \u0026quot;,\u0026quot; \u0026quot;),\rmargin = c(0,0,0,0))\r\rFigure 2: Modelo de regresión con y sin exponenciar (exp)\r\r\rReferencias\rCamarero et al (2017) Regresión logística: Fundamentos y aplicación a la investigación sociológica (p.30-52)\nCerda, Vera y Rada (2017) Odds ratio: aspectos teóricos y prácticos.\n\r\rReporte de progreso\rContestar aquí.\n\rForo práctica 10\r\r","date":1597363200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1597114659,"objectID":"8ec314482bb68fedf05e4758dbbdc14d","permalink":"/assignment/10-code/","publishdate":"2020-08-14T00:00:00Z","relpermalink":"/assignment/10-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 10: Regresión Logística 2","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de la clase - no disponible … falla de zoom :(\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase - no disponible … falla de zoom :(\r\r","date":1596758400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1597153340,"objectID":"3fea5612523ac7da2f3ba696739f7198","permalink":"/class/10-class/","publishdate":"2020-08-07T00:00:00Z","relpermalink":"/class/10-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de la clase - no disponible … falla de zoom :(\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase - no disponible … falla de zoom :(\r\r","tags":null,"title":"10: Regresión logística (2)","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo\rLibrerías\rDatos\rExplorar datos\r\rConceptos centrales\rProbabilidades\rOdds\rOdds Ratio (OR)\rReferencias\r\rReporte de progreso\rForo práctica 9\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo\rLa siguiente práctica tiene el objetivo de introducir a los estudiantes en los modelos de regresión logística, que es una técnica de análisis que nos permite tener una variable dependiente como dicotómica. Para ello, utilizaremos la base de datos del Titanic.\n\rLibrerías\rpacman::p_load(dplyr, summarytools, ggmosaic, finalfit)\r\rDatos\r¿Qué es el titanic? El RMS Titanic fue un transatlántico británico, el mayor barco del mundo al finalizar su construcción, que se hundió en la madrugada del 15 de abril de 1912 durante su viaje inaugural desde Southampton a Nueva York. En el hundimiento del Titanic murieron 619 personas de las 1046 que iban a bordo, lo que convierte a esta tragedia en uno de los mayores naufragios de la historia ocurridos en tiempo de paz.\n#Cargamos la base de datos desde internet\rload(url(\u0026quot;https://multivariada.netlify.com/assignment/data/titanic.RData\u0026quot;))\rExplorar datos\rA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(tt, headings = FALSE, method = \u0026quot;render\u0026quot;))\r\r\rNo\rVariable\rStats / Values\rFreqs (% of Valid)\rGraph\rValid\rMissing\r\r\r\r\r1\rpclass\r[factor]\r1. Clase Alta\r2. Clase Intermedia\r3. Clase Baja\r284(27.2%)261(24.9%)501(47.9%)\r\r1046\r(100%)\r0\r(0%)\r\r\r2\rsurvived\r[factor]\r1. No sobrevive\r2. Sobrevive\r619(59.2%)427(40.8%)\r\r1046\r(100%)\r0\r(0%)\r\r\r3\rsex\r[factor]\r1. Hombre\r2. Mujer\r658(62.9%)388(37.1%)\r\r1046\r(100%)\r0\r(0%)\r\r\r4\rage\r[numeric]\rMean (sd) : 29.9 (14.4)\rmin 98 distinct values\r\r1046\r(100%)\r0\r(0%)\r\r\r5\rsibsp\r[numeric]\rMean (sd) : 0.5 (0.9)\rmin 0:685(65.5%)1:280(26.8%)2:36(3.4%)3:16(1.5%)4:22(2.1%)5:6(0.6%)8:1(0.1%)\r\r1046\r(100%)\r0\r(0%)\r\r\r6\rparch\r[numeric]\rMean (sd) : 0.4 (0.8)\rmin 0:768(73.4%)1:160(15.3%)2:97(9.3%)3:8(0.8%)4:5(0.5%)5:6(0.6%)6:2(0.2%)\r\r1046\r(100%)\r0\r(0%)\r\r\r\rGenerated by summarytools 0.9.6 (R version 4.0.0)2020-08-05\n\rPara esta práctica nos centraremos en las variables sex y survived. Como podemos notar la categoría de respuesta de estas variables son 0 y 1, es decir, estamos ante variables dicotómicas.\nCon la función ctable del paquete summarytools podemos realizar una tabla de contingencia donde se señala la proporción de sobrevivientes según sexo\nCross-Tabulation, Row Proportions\rsurvived * sex\rData Frame: tt\r\r\r\r\rsex\r\r\r\rsurvived\r\rHombre\rMujer\rTotal\r\r\r\r\r\rNo sobrevive\r\r523\r(\r84.5%\r)\r96\r(\r15.5%\r)\r619\r(\r100.0%\r)\r\r\r\rSobrevive\r\r135\r(\r31.6%\r)\r292\r(\r68.4%\r)\r427\r(\r100.0%\r)\r\r\r\rTotal\r\r658\r(\r62.9%\r)\r388\r(\r37.1%\r)\r1046\r(\r100.0%\r)\r\r\r\rGenerated by summarytools 0.9.6 (R version 4.0.0)2020-08-05\n\rctable(tt$survived, tt$sex)\rLa tabla muestra que la mayoría de los tripulantes no sobrevivió (619 no sobreviven, mientras que 427 si sobreviven). A su vez, la mayoría de los no sobrevivientes corresponden a hombres (84.5%), mientras que solo un 15.5% de las mujeres no sobrevive. En relación a sobrevivientes, la mayoría de los sobrevivientes corresponden a mujeres (68,4%), en desmedro de hombres (31.6%).\nUna forma gráfica de verlo es por medio del paquete ggmosaic que con su función geom_mosaic permite construir visualizaciones para datos categóricos. El mosaico general corresponde al total de tripulantes del titanic. Como podrán notar, hay más hombres tripulantes que mujeres, por lo que las barras para hombres son mas anchas. Luego, gracias al comando fill del geom_mosaic podemos distinguir en hombres y mujeres la proporción de cuantos sobrevivieron y cuantos no sobrevivieron.\nggplot(data = tt) +\rgeom_mosaic(aes(product(survived, sex), fill= survived)) +labs(y = \u0026quot;Sobreviviente\u0026quot;, x = \u0026quot;Sexo\u0026quot;)\r\r\rConceptos centrales\rLos dos conceptos centrales en regresión logística son las “chances” (o en inglés, odds) y la razón (o en inglés, ratio).\nProbabilidades\rUna probabilidad es la posibilidad de ocurrencia de un evento de interés, usando como referencia todos los eventos. Por ejemplo, la probabilidad de “ser sobreviviente en el titanic” se calcula en relación a todos los tripulantes del titanic.\nEn primera instancia, podríamos decir que del total de pasajeros, un 40.8% de ellos sobrevive, es decir, la probabilidad de sobrevivir es de 0.408\n\\[Probabilidades_{sobrevivientes} = \\frac{427}{1046} = 0.408\\]\rMientras que un 59.2% de los tripulantes no sobrevive, es decir, la probabilidad de no sobrevivir es de 0.592\n\\[Probabilidades_{sobrevivientes} = \\frac{619}{1046} = 0.592\\]\nEn R se realiza a través de la función prop.table\nprop.table(table(tt$survived))\r## ## No sobrevive Sobrevive ## 0.5917782 0.4082218\r\rOdds\rUna forma alternativa de representar una probabilidad es un odds que se definen como la división entre el número de ocurrencias (\\(\\pi\\)) y el numero de “no ocurrencias” (\\(1-\\pi\\)).\n\\[Odd = \\frac{\\pi}{1-\\pi}\\]\nSi seguimos el ejemplo del Titanic\n\\[Odds = \\frac{Sobrevivientes}{No{Sobrevivientes}}\\]\nLa función addmargins nos entrega las frecuencias marginales y absolutas para columnas (sexo) y filas (sobrevivencia)\naddmargins(table(tt$survived,tt$sex))\r## ## Hombre Mujer Sum\r## No sobrevive 523 96 619\r## Sobrevive 135 292 427\r## Sum 658 388 1046\rSi hacemos el cálculo de los odds obtenemos 0.68 (427/619), es decir, hay 0.68 sobrevivientes por cada no sobreviviente. Aunque parezca poco “lógico” hablar de 0.68 sobrevivientes, esto indica que la relación entre sobrevivientes y no sobrevivientes no es 1:1 y de hecho existen más chances de morir que de sobrevivir.\nOtra forma de leer este dato es decir que por cada 100 no sobrevivientes, hay 68 sobrevivientes.\nPodríamos también calcular el odds de sobrevivencia de hombres y mujeres\n\\[Odds{hombres} = \\frac{135}{523} = 0.258\\]\r\\[Odds{mujeres} = \\frac{292}{96} = 3.04\\]\nPara los hombres, hay más chances de no sobrevivir que de sobrevivir (odds \u0026lt; 1), mientras que para mujeres hay más chances de sobrevivir que de no sobrevivir (odds \u0026gt; 1)\nPropiedades de Odds\n\rOdds menores que 1, indican una chance negativa\rOdds mayores que 1, indican una chance positiva\r\rEn R esto podemos realizar este calculo directamente a través de las probabilidades marginales para cada sexo que entrega prop.table.El número 2 indica que las proporciones están calculadas por columna, es decir, las probabilidades indicadas se calculan considerando como total cada sexo.\nprop.table(table(tt$survived,tt$sex),2)\r## ## Hombre Mujer\r## No sobrevive 0.7948328 0.2474227\r## Sobrevive 0.2051672 0.7525773\r\rOdds Ratio (OR)\rAhora bien, con los datos hasta ahí podriamos llegar a la conclusión de que las mujeres tienen más chances de sobrevivir que los hombres. Pero, ¿cuánto más sobreviven las mujeres que los hombres?\nEsta pregunta implica la asociación entre sobrevivencia y sexo y ya no solo hablar de las chances de sobrevivencia de cada sexo por separado. Para hacer esa relación se requiere calcular los odds ratio o razón de chances.\n\\[Odds Ratio = \\frac{Odds_{mujeres}}{Odds_{hombres}} = \\frac{3.04}{0.258} = 11.78\\]\nEl resultado que obtenemos se lee de la siguiente manera: las chances de sobrevivir de las mujeres es 11.78 veces más grande que la de los hombres.\nEn consecuencia, la comparación de los Odds de dos grupos es conocido como Odds Ratio (OR). Formalmente:\n\\[Odds_{ratio}=\\frac{odds_{1}}{odds_{2}}=\\frac{\\pi_{1}/(1-\\pi_{1})}{\\pi_{2}/(1-\\pi_{2})}\\]\nPropiedades de Odds Ratio:\n\rCuando X e Y son independientes \\(Odds_{ratio}\\) ya que \\(odds_{1}=odds_{2}\\)\n\rEl rango de posibles valores es: \\(0\u0026lt;Odds_{ratio}\u0026lt;\\infty\\)\n\rCuando los valores van de 0 a 1, \\(Odds_{ratio}\\) indica que \\(odds_{1}\u0026lt;odds_{2}\\)\n\rCuando los valores van de 1 a \\(\\infty\\), \\(Odds_{ratio}\\) indica que \\(odds_{1}\u0026gt;odds_{2}\\)\n\r\rEs una medida de magnitud de asociación simétrica: un \\(Odds_{ratio}=4\\) es una asociación positiva proporcional a la asociación negativa \\(Odds_{ratio}=1/4=0.25\\)\n\r\rLos \\(Odds_{ratio}\\) se pueden graficar por medio de la funcion or_plor de finalfit. Para ello solo de debe indicar cuál es la variable predictora (o explanatory en inglés) y la variable dependiente.\nexplanatory =\u0026quot;sex\u0026quot;\rdependent =\u0026quot;survived\u0026quot;\r\rtt %\u0026gt;%or_plot(dependent, explanatory)\rComo se puede ver, en el gráfico no solo se indican los \\(Odds_{ratio}\\) de sobrevivencia de las mujeres por sobre los hombres (11.78), sino que estos se grafican en relacióna qué tan cerca están del 0 (y por tanto, cuánto se aleja del rango de asociación negativa).\n\rReferencias\rCamarero et al (2017) Regresión logística: Fundamentos y aplicación a la investigación sociológica (p.1-29)\nCerda, Vera y Rada (2017) Odds ratio: aspectos teóricos y prácticos.\n\r\rReporte de progreso\rContestar aquí.\n\rForo práctica 9\r\r","date":1596326400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1596661700,"objectID":"d1d31d6e8d02dd2e2bca57b081533945","permalink":"/assignment/09-code/","publishdate":"2020-08-02T00:00:00Z","relpermalink":"/assignment/09-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 9. Regresión Logística 1","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de la clase\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r","date":1596153600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1597153340,"objectID":"6fce0ded8aa03d77081bcdf32570ef18","permalink":"/class/09-class/","publishdate":"2020-07-31T00:00:00Z","relpermalink":"/class/09-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de la clase\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r","tags":null,"title":"9: Regresión logística (1)","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rLibrerías\rDatos\rAjustes y descriptivos\rModelos de regresión\rLógica de presentación de modelos\rEstimación\rInterpretación\rAjuste global del modelo\r\rReferencias\rForo práctica 8\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rEn el siguiente documento se presenta un ejemplo de análisis e interpretación de una tabla de regresión múltiple, para que sea considerado como referencia en la entrega de los informes 2 y 3. El ejemplo está adaptado de https://stats.idre.ucla.edu/stata/output/regression-analysis/\nLibrerías\rpacman::p_load(dplyr,readxl, summarytools, stargazer, equatiomatic)\r\rDatos\rLos datos a utilizar corresponden a resultados de pruebas de conocimiento en distintas areas de 200 estudiantes de educación secundaria.\ndata \u0026lt;-read_excel(\u0026quot;https://multivariada.netlify.app/assignment/data/hsb2.xls\u0026quot;)\r\rAjustes y descriptivos\rPrimero seleccionamos las variables que vamos a usar en el ejemplo y cambiamos las etiquetas de las variables a español.\nnames(data)\r## [1] \u0026quot;id\u0026quot; \u0026quot;female\u0026quot; \u0026quot;race\u0026quot; \u0026quot;ses\u0026quot; \u0026quot;schtyp\u0026quot; \u0026quot;prog\u0026quot; \u0026quot;read\u0026quot; ## [8] \u0026quot;write\u0026quot; \u0026quot;math\u0026quot; \u0026quot;science\u0026quot; \u0026quot;socst\u0026quot;\rdata \u0026lt;-data %\u0026gt;%select (science,math,female, socst, read)\rdata \u0026lt;-data %\u0026gt;%rename(ciencia=science, matematicas =math, mujer=female, status=socst, lectura=read)\rprint(dfSummary(data, headings = FALSE), method = \u0026quot;render\u0026quot;)\r\r\rNo\rVariable\rStats / Values\rFreqs (% of Valid)\rGraph\rValid\rMissing\r\r\r\r\r1\rciencia\r[numeric]\rMean (sd) : 51.9 (9.9)\rmin 34 distinct values\r\r200\r(100%)\r0\r(0%)\r\r\r2\rmatematicas\r[numeric]\rMean (sd) : 52.6 (9.4)\rmin 40 distinct values\r\r200\r(100%)\r0\r(0%)\r\r\r3\rmujer\r[numeric]\rMin : 0\rMean : 0.5\rMax : 1\r0:91(45.5%)1:109(54.5%)\r\r200\r(100%)\r0\r(0%)\r\r\r4\rstatus\r[numeric]\rMean (sd) : 52.4 (10.7)\rmin 22 distinct values\r\r200\r(100%)\r0\r(0%)\r\r\r5\rlectura\r[numeric]\rMean (sd) : 52.2 (10.3)\rmin 30 distinct values\r\r200\r(100%)\r0\r(0%)\r\r\r\rGenerated by summarytools 0.9.6 (R version 4.0.0)2020-07-15\n\r\rModelos de regresión\rLógica de presentación de modelos\rLa forma en que se presentan los modelos en regresión múltiple depende de las hipótesis que se estan contrastando, y de la definición del/a investigador/a sobre cuáles son los predictores principales y cuáles son las variables de control. Pensemos en este caso que nuestra hipótesis principal es que el puntaje de ciencias se puede predecir con los puntajes de matemáticas y lectura, pero queremos controlar estas asociaciones por sexo y estatus. En este caso, podríamos presentar dos modelos, uno solamente con los predictores principales, y luego un segundo modelo con los controles para ver si los efectos se mantienen. También podríamos pensar en tres modelos: uno con matemáticas, otro con ciencias, y otro con ambos y además controles. La decisión de cómo presentar los modelos depende principalmente de las hipótesis que se están contrastando, y también de que los resultados permitan hacer la mejor discusión posible.\n\rEstimación\rVamos a estimar un primer modelo con las variables asociadas a la hipótesis principal, y luego un segundo con las variables control:\n\\[\r\\text{ciencia} = \\alpha + \\beta_{1}(\\text{matematicas}) + \\beta_{2}(\\text{lectura}) + \\epsilon\r\\]\\[\r\\text{ciencia} = \\alpha + \\beta_{1}(\\text{matematicas}) + \\beta_{2}(\\text{lectura}) + \\beta_{3}(\\text{mujer}) + \\beta_{4}(\\text{status}) + \\epsilon\r\\]\nPara estimar estos modelos en R:\nreg1 \u0026lt;-lm(ciencia ~matematicas +lectura, data=data)\rreg2 \u0026lt;-lm(ciencia ~matematicas +lectura +mujer +status, data=data)\rPara presentar los resultados de regresión existen diferentes librerías en R, como\rstargazer, texreg, sjPlot. En este caso vamos a utilizar la función tab_model de sjPlot:\nsjPlot::tab_model(list(reg1,reg2))\r\r\rciencia\r\rciencia\r\r\r\rPredictors\r\rEstimates\r\rCI\r\rp\r\rEstimates\r\rCI\r\rp\r\r\r\r(Intercept)\r\r11.62\r\r5.59 – 17.64\r\r\u0026lt;0.001\r\r12.33\r\r6.03 – 18.62\r\r\u0026lt;0.001\r\r\r\rmatematicas\r\r0.40\r\r0.26 – 0.54\r\r\u0026lt;0.001\r\r0.39\r\r0.24 – 0.54\r\r\u0026lt;0.001\r\r\r\rlectura\r\r0.37\r\r0.23 – 0.50\r\r\u0026lt;0.001\r\r0.34\r\r0.19 – 0.48\r\r\u0026lt;0.001\r\r\r\rmujer\r\r\r\r\r-2.01\r\r-4.03 – 0.01\r\r0.051\r\r\r\rstatus\r\r\r\r\r0.05\r\r-0.07 – 0.17\r\r0.424\r\r\r\rObservations\r\r200\r\r200\r\r\r\rR2 / R2 adjusted\r\r0.478 / 0.473\r\r0.489 / 0.479\r\r\r\rEsta tabla tiene las opciones por defecto. En general, para cada predictor hay dos piezas de información importante: la estimación del coeficiente de regresión \\(\\beta\\) (estimates), y una estimación referida a inferencia/significación estadística (en este caso CI, intervalo de confianza). Esta segunda información es en general el error estándar, pero también puede ser t (que es el coeficiente dividido por el error estándar), o el intervalo de confianza, dado usualmente por el \\(\\beta\\) +/- 1.96 SE para un 95% de confianza (como aparece en esta tabla). Según el output, la información de inferencia puede aparecer abajo del coeficiente, o al lado como en esta tabla.\nAbajo vamos a hacer algunos ajustes en la tabla, presentando el error estándar en lugar del intervalo, y reemplazando la columna del nivel de probabilidad de error (p) por asteriscos que indican el nivel de significación de cada coeficiente, lo cual hace más rápida la interpretación. También cambiamos algunas etiquetas de la tabla para que sea más fácil de leer:\nsjPlot::tab_model(list(reg1,reg2),\rshow.se=TRUE,\rshow.ci=FALSE,\rdigits=3,\rp.style = \u0026quot;asterisk\u0026quot;,\rdv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;),\rstring.pred = \u0026quot;Predictores\u0026quot;,\rstring.est = \u0026quot;β\u0026quot;)\r\r\rModelo 1\r\rModelo 2\r\r\r\rPredictores\r\rβ\r\rstd. Error\r\rβ\r\rstd. Error\r\r\r\r(Intercept)\r\r11.616 ***\r\r3.054\r\r12.325 ***\r\r3.194\r\r\r\rmatematicas\r\r0.402 ***\r\r0.073\r\r0.389 ***\r\r0.074\r\r\r\rlectura\r\r0.365 ***\r\r0.066\r\r0.335 ***\r\r0.073\r\r\r\rmujer\r\r\r\r-2.010 \r\r1.023\r\r\r\rstatus\r\r\r\r0.050 \r\r0.062\r\r\r\rObservations\r\r200\r\r200\r\r\r\rR2 / R2 adjusted\r\r0.478 / 0.473\r\r0.489 / 0.479\r\r\r\r\rp\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001\r\r\r\r\rY para presentar en forma de ecuaciones, quedaría de la siguiente manera:\n\\[\r\\text{ciencia} = 11.62 + 0.4(\\text{matematicas}) + 0.37(\\text{lectura}) + \\epsilon\r\\]\\[\r\\text{ciencia} = 12.33 + 0.39(\\text{matematicas}) + 0.34(\\text{lectura}) - 2.01(\\text{mujer}) + 0.05(\\text{status}) + \\epsilon\r\\]\nPara transformar automáticamente las estimaciones de regresión en R a ecuaciones:\nEsto se puede hacer si se utiliza RMarkdown (no es requisito en este curso, para los interesad_s pueden revisar material del curso ciencia social abierta )\nInstalar librería equatiomatic. No está en CRAN, así que para instalar:remotes::install_github(\"datalorax/equatiomatic\")\n\rLa función para extraer la ecuación es extract_eq, por ejemplo: extract_eq(reg1)\n\rPara que el resultado pueda ser renderizado desde un documento RMarkdown a pdf o html, debe estar en un chunk con las siguientes especificaciones:\n\r\r```{r results=\u0026#39;asis\u0026#39;, echo=FALSE}\rextract_eq(reg1)\rextract_eq(reg2)\r```\rPara presentar las ecuaciones con los coeficientes ya estimados, extract_eq(reg1, use_coefs = TRUE)\r\r\r\rInterpretación\rLos coeficientes nos hablan de la relación entre las variables independientes y la variable dependiente. Nos muestran la magnitud del cambio predicho en el puntaje de ciencia por cada 1 unidad en que aumenta el predictor.\nPara matematica el coeficiente es de 0.402 en el modelo 1 y baja a 0.389 en el modelo 2. Entonces, por cada punto adicional en la prueba de matemáticas en el modelo 2 se presenta un incremento de 0.389 en el puntaje de ciencia, manteniendo todas las demás variables constantes. Respecto a la inferencia, existen distintas maneras de dar cuenta de la significación estadística. Por ejemplo, se puede decir que este valor es estadísticamente significativo con un 99,9% de confianza, o con una probabilidad de error p\u0026lt;0.001.\nPara reportar estos resultados de manera más resumida siguiendo las indicaciones de reporte de APA (American Psychological Association): El puntaje en matemáticas predice significativamente el puntaje de ciencias (modelo 1), b = -.40, SE = .07, p \u0026lt; .001, controlando por el puntaje en lectura. Al agregar los controles de sexo y estatus (modelo 2), el puntaje en matemáticas disminuye levemente pero mantiene su nivel de significación, b = -.39, SE = .07, p \u0026lt; .001.\n\rCon respecto a lectura, en el modelo 2 es posible observar un coeficiente de 0.335. Esto implica que por cada unidad que aumenta el puntaje de lectura se predice un incremento de 0.335 puntos en ciencia, manteniendo todas las demás variables contantes. El coeficiente es estadísticamente significativo con una probabilidad de error p\u0026lt;0.001.\nPara la variable mujer podemos observar que el coeficiente tiene un valor de -2.010 en el modelo 2. Al ser mujer una variable dicotómica donde 1 es mujer y 0 es hombre, la estimación nos indica que para las mujeres el puntaje predicho promedio en ciencias es -2.010 puntos más bajo con respecto al promedio de los hombres, manteniendo todas las demás variables constantes. En términos exclusivamente estadísticos, la variable mujer no es significativamente distinta de 0 cuando empleamos un nivel de confianza del 95%, debido a que el valor \\(p\\) es mayor a 0.05.\nSi observamos el coeficiente de status tenemos un valor de 0.050. Entonces, por cada unidad en que incrementa el estatus se predice un incremento de 0.050 puntos en ciencia, manteniendo todas las demás variables constantes. Sin embargo, no es estadísticamente significativo a un 95% de confianza.\nStd Error: Esta columna corresponde a los errores estándar de los coeficientes de regresión (Estimate). Estos errores estándar son empleados para testear en qué medida los coeficientes son distintos de 0. El procedimiento es dividir el coeficiente por su error estándar para obstener el valor \\(t\\), los que luego se contrastan con la tabla de valores críticos t para obtener la probabilidad de error (que ya aparece automáticamente en la tabla) . Además, los errores estándar pueden ser utilizados para calcular los intervalos de confianza.\nUna manera de presentar los resultados de un modelo de regresión es a través de la visualización de los coeficientes de regresión con sus respectivos intervalos de confianza. La ventaja de este tipo de gráficos es que podemos observar la magnitud del coeficiente y las “barras de error” que representan el intervalo de confianza inferior y superior. Utilizando un intervalo de confianza de 95% de confianza:\nsjPlot::plot_model(reg2,ci.lvl = c(0.95), title = \u0026quot;\u0026quot;,vline.color = \u0026quot;grey\u0026quot;,line.size = 1)\r\rFigure 1: Modelo 2\r\rLo que nos muestra este gráfico es el valor del coeficiente en el punto, y en las líneas que salen del punto se extienden según su intervalo de confianza. De acuerdo a las reglas de inferencia en regresión, lo que estamos contrastando es que el valor de este coeficiente es distinto de 0 en la población, con un cierto valor de probabilidad. Por lo tanto, si agregamos un intervalo de confianza (valores probables) asociado a una probabilidad de error, entonces podemos decir que este coeficiente es estadísticamente distinto de 0 en la población. Y en el gráfico, esto sucede cuando los intervalos no tocan el 0.\n\rAjuste global del modelo\rR2: El R2 (R-cuadrado) es la proporción de la varianza de la variable dependiente (ciencias) la cual puede ser predicha por las variables independientes (matemáticas, mujer, estatus, lectura). En la Tabla 1 tenemos que para el Modelo (1), este valor nos indica que un 47,7% de la varianza en el puntaje de ciencias se asocia a matemáticas. Luego, en el Modelo (2), el R-cuadrado nos indica que el 48,9% de la varianza de ciencias puede ser predicha conjuntamente por las variables independientes matemáticas, lectura, mujer y status. Como vemos, la incorporación de controles aporta levemente al R2, lo cual se relaciona con que estos predictores no son estadísticamente significativos.\nAdjusted R2: En la medida que se incorporan predictores al modelo, cada uno va contribuyendo a explicar la varianza de la variable dependiente. Así, se podría continuar agregando predictores al modelo, incrementando la capacidad explicativa pero también de cierto modo debido a la variabilidad adicional en una muestra particular con la que estemos trabajando. Por esta razón, el R-cuadrado ajustado busca demostrar un valor estimado más realista del R-cuadrado para la población bajo análisis, penalizando por la inclusión de predictores adicionales. En el caso del Modelo (2) de la Tabla 1, el valor del R-cuadrado es de 0.489, mientras que el R-cuadrado ajustado es de 0.479, el cual es calculado a través de la fórmula \\(1 – ((1 – R^2)((N – 1) /( N – k – 1))\\).\nEntonces, si el número de observaciones (\\(N\\)) es pequeño y el número de predictores (\\(k\\))es grande, tendremos una mayor discrepancia entre el R-cuadrado y el R-cuadrado ajustado. Por otro lado, cuando el número de observaciones es grande en contraste con el número de predictores tendremos que el valor del R-cuadrado y el R-cuadrado ajustado serán mucho más similares debido.\nPor lo tanto, al momento de realizar la intepretación corresponde basarse en los coeficientes del R2 ajustado.\n\r\rReferencias\rBruin, J. 2006. newtest: command to compute new test. UCLA:\rStatistical Consulting Group. https://stats.idre.ucla.edu/stata/ado/analysis/.\n\rRegression analysis annotated output\n\r\r\rForo práctica 8\r\r","date":1594598400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1594831796,"objectID":"e65d602e49caf322a4b3b2cc0350e50c","permalink":"/assignment/08-code/","publishdate":"2020-07-13T00:00:00Z","relpermalink":"/assignment/08-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 8. Tabla de regresión múltiple","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de la clase\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r","date":1594339200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1594685672,"objectID":"a696c93d764e2bfb447300660fcf2be7","permalink":"/class/08-class/","publishdate":"2020-07-10T00:00:00Z","relpermalink":"/class/08-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de la clase\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r","tags":null,"title":"8: Inferencia en regresión (2)","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de la clase\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\r","date":1593734400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1594087749,"objectID":"026700f4d4068083b37f98f89edf4682","permalink":"/class/07-class/","publishdate":"2020-07-03T00:00:00Z","relpermalink":"/class/07-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de la clase\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\r","tags":null,"title":"7: Categóricos / inferencia (1)","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo de la práctica\rPredictores categóricos\rPredictores dicotómicos\rLibrerías\rDatos\rExplorar base de datos\rRelacion entre variables\rPredictores con más de una categoría\rInterpretación\rVariables dummy\r\r\rInferencia\rResumen Práctica 7\rReporte de progreso\rForo práctica 7\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo de la práctica\rEs esta práctica vamos a abordar dos temas:\nPredictores categóricos en regresión\n\rInferencia estadística\n\r\rAmbos temas corresponden a dos ámbitos independientes en el estudio de la regresión. Sin embargo, la inclusión de predictores categóricos de dos niveles (o variables dicotómicas) nos permitirá una aproximación a inferencia estadística que es directamente vinculable a los conocimientos sobre diferencia de promedios mediante la prueba t.\nPredictores categóricos\rHasta ahora hemos trabajado solamente con predictores a los que asumimos un nivel de medición contínua (es decir, al menos intervalar). ¿Qué sucede con predictores donde se asume un distinto nivel de medición, como nominal u ordinal? En general este tipo de predictores requiere una interpretación y tratamiento distinto que los predictores continuos.\n\rPredictores dicotómicos\rLas variables dicotómicas son aquellas variables nominales u ordinales que poseen solo dos categorías de respuesta, por ejemplo hombre/mujer, sano/enfermo, deportista/sedentario. La inclusión de estas variables en un modelo de regresión no requiere un tratamiento especial, solo hay que considerar que su interpretación tiene un sentido distinto. A continuación, veremos un ejemplo respecto a cómo predictores categóricos (de dos o más niveles) permiten modelar el Estatus Social Subjetivo\n\rLibrerías\rpacman::p_load(dplyr, #manipulacion de datos\rsjPlot, #tablas\rsummarytools, #estadisticos descriptivos\rfastDummies, # Crear variable dummy\rsjlabelled, #etiquetas variables\rggplot2, #graficos\rcoefplot # graficos de coeficientes\r)\r\rDatos\rPrimero, se cargará la base de datos\nload(url(\u0026quot;https://multivariada.netlify.app/assignment/data/proc/ELSOC_ess.RData\u0026quot;)) # Cargar base de datos\rLos datos a utilizar corresponden a la base de datos ELSOC 2018 que incluye una muestra de 3784 mujeres y hombres adultos entre 18 y 75 años.\nVariables\n\r[ess]: “Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena” (0 = el nivel mas bajo; 10 = el nivel mas alto)\n\r[edcine]: ¿Cuál es su nivel educacional? Indique el tipo de estudio actual (si estudia actualmente) o el último tipo aprobado (si no estudia actualmente) - CINE 2011 (UNESCO).\n\r\r[edad]: ¿Cuáles su edad? (años cumplidos).\n\r\rview_df(elsoc_18,encoding = \u0026quot;\u0026quot;)\r\rData frame: elsoc_18\r\r\rID\r\rName\r\rLabel\r\rValues\r\rValue Labels\r\r\r\r1\r\ress\r\rEstatus Social Subjetivo\r\r0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\r\r0 El nivel mas bajo\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10 El nivel mas alto\r\r\r\r2\r\rsexo\r\rSexo (1=Mujer)\r\r0\n1\r\rHombre\nMujer\r\r\r\r3\r\redad\r\rEdad\r\rrange: 18-90\r\r\r\r4\r\redcine\r\rEducación\r\r1\n2\n3\n4\n5\r\rPrimaria incompleta menos\nPrimaria y secundaria baja\nSecundaria alta\nTerciaria ciclo corto\nTerciaria y Postgrado\r\r\r\r\rExplorar base de datos\rA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(elsoc_18, headings = FALSE, method = \u0026quot;render\u0026quot;))\r\r\rNo\rVariable\rLabel\rStats / Values\rFreqs (% of Valid)\rGraph\rValid\rMissing\r\r\r\r\r1\ress\r[numeric]\rEstatus Social Subjetivo\rMean (sd) : 4.4 (1.6)\rmin 11 distinct values\r\r3703\r(100%)\r0\r(0%)\r\r\r2\rsexo\r[numeric]\rSexo (1=Mujer)\rMin : 0\rMean : 0.4\rMax : 1\r0:2277(61.5%)1:1426(38.5%)\r\r3703\r(100%)\r0\r(0%)\r\r\r3\redad\r[numeric]\rEdad\rMean (sd) : 47 (15.5)\rmin 70 distinct values\r\r3703\r(100%)\r0\r(0%)\r\r\r4\redcine\r[numeric]\rEducaci\u0026#0243;n\rMean (sd) : 3.2 (1.2)\rmin 1:442(11.9%)2:365(9.9%)3:1589(42.9%)4:592(16.0%)5:715(19.3%)\r\r3703\r(100%)\r0\r(0%)\r\r\r\rGenerated by summarytools 0.9.6 (R version 4.0.0)2020-07-08\n\r\rRelacion entre variables\rVisualizar la asociación entre variables puede ser informativo. Sin embargo, en ocasiones es necesario prestar mayor atención al tipo de gráfico que utilizamos para esto. Por ejemplo, veamos un scatter de Estatus social Subjetivo \\(Y_\\text{estatus}\\) con sexo como independiente \\(X_\\text{sexo}\\) para comparar sus distribuciones y sus pendientes\nplot_scatter(data = elsoc_18,x = sexo,y = ess,fit.grps = \u0026quot;lm\u0026quot;)\rEl scatterplot no es muy informativo debido a que nuestra variable independiente solamente posee dos niveles, de modo tal que la distribución de Estatus Social Subjetivo se separa en dos grandes grupos. Por esta razón, una alternativa para visualizar la distirbución es elaborar un gráfico de cajas para ambas categorías:\nplot_grpfrq(var.cnt = elsoc_18$ess,var.grp = elsoc_18$sexo,type = \u0026quot;box\u0026quot;)\rEn este sentido, al tener solamente dos niveles en los valores de la variable X: 0 (Hombre) y 1 (Mujer). Obtenemos solamente dos medias condicionales.\nEntonces, si calculamos el promedio simple para Estatus Social Subjetivo por sexo tenemos:\nelsoc_18 %\u0026gt;%\rgroup_by(sexo) %\u0026gt;%\rsummarise(mean_ess=mean(ess,na.rm = T))\r## # A tibble: 2 x 2\r## sexo mean_ess\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 0 4.34\r## 2 1 4.47\rSegun esto el promedio para las mujeres es de 4.47 puntos en la escala de Estatus Social Subjetivo, mientras para los hombres es de 4.34.\nRealizando ahora la regresión:\nreg1\u0026lt;-lm(ess ~sexo, data=elsoc_18)\rsjPlot::tab_model(list(reg1), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3,\rdv.labels = c(\u0026quot;Modelo 1\u0026quot;))\r\r\rModelo 1\r\r\r\rPredictores\r\rβ\r\r\r\r(Intercept)\r\r4.339 ***\r\r\r\rSexo(1=Mujer)\r\r0.133 *\r\r\r\rObservations\r\r3703\r\r\r\rR2 / R2 adjusted\r\r0.002 / 0.001\r\r\r\r\rp\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001\r\r\r\r\rEntonces:\n\\[\\widehat{Y}_\\text{estatus} = 4.339 + \\beta_1 \\times \\text{Sexo} + \\epsilon \\]\rTenemos que las mujeres (Sexo = 1) tienen un promedio 0.133 puntos más alto que los hombres (Sexo = 0) en la escala de estatus social subjetivo. En este caso, el grupo de los hombres corresponde a la categoría de referencia.\nPor lo tanto, ¿cuál es la predicción de estatus social subjetivo para la variable sexo?\nPara el caso de los hombres tenemos:\n\\[\\widehat{Y}_\\text{estatus} = 4.339 + 0.133 \\times 0 = 4.339\\]\rEn cambio, para las mujeres tenemos:\n\\[\\widehat{Y}_\\text{estatus} = 4.339 + 0.133 \\times 1 = 4.472\\]\nEntonces cuando calculamos el promedio de Estatus social Subjetivo \\(Y_\\text{estatus}\\) para hombre (\\(X_\\text{sexo=0}\\)) mujer (\\(X_\\text{sexo=1}\\)), podemos observar que son los mismos valores que nos entrega la estimación de la regresión simple empleando Sexo como predictor de Estatus Social Subjetivo. Es decir:\n\rAl ingresar un regresor dicotómico en regresión simple lo que se obtiene es una estimación de la diferencia de promedios de ambas categorías en relación a la variable dependiente -en regresión múltiple esta diferencia se ajusta o controla por la presencia de otras variables, por ejemplo:\r\rreg2\u0026lt;-lm(ess ~sexo+edad, data=elsoc_18)\rsjPlot::tab_model(list(reg1,reg2), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3,\rdv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;))\r\r\rModelo 1\r\rModelo 2\r\r\r\rPredictores\r\rβ\r\rβ\r\r\r\r(Intercept)\r\r4.339 ***\r\r4.602 ***\r\r\r\rSexo(1=Mujer)\r\r0.133 *\r\r0.126 *\r\r\r\rEdad\r\r\r-0.006 ***\r\r\r\rObservations\r\r3703\r\r3703\r\r\r\rR2 / R2 adjusted\r\r0.002 / 0.001\r\r0.005 / 0.004\r\r\r\r\rp\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001\r\r\r\r\r\\[\\widehat{Y}_\\text{estatus} = 4.602 + 0.126 \\times \\text{Sexo} + -0.006 \\times \\text{Edad} + \\epsilon \\]\rAl controlar por la Edad de las personas, las mujeres tienen un promedio 0.126 más alto que el de los hombres en la escala de Estatus Social Subjetivo. Vemos que, en comparación con el Modelo 1, la diferencia en el promedio de estatus subjetivo de mujeres respecto de hombres se ajusta al incorporar la Edad. En este sentido, ¿por qué la diferencia en el promedio de estatus subjetivo entre mujeres y hombres puede verse afectada por la Edad?. Revisemos el promedio de Edad para hombres y mujeres:\nelsoc_18 %\u0026gt;%\rgroup_by(sexo) %\u0026gt;%\rsummarise(mean_ess=mean(edad,na.rm = T))\r## # A tibble: 2 x 2\r## sexo mean_ess\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 0 47.5\r## 2 1 46.3\rEsta información nos permite observar que los hombres tienen un promedio de edad de 1.2 años mayor que el de las mujeres. En este sentido, lo que vemos es que la diferencia promedio de estatus subjetivo entre hombres y mujeres disminuye de 0.136 a 0.126, es decir, se ajusta al considerar (controlar por) la edad de las personas.\n\rPredictores con más de una categoría\rUna de las características de estatus más importante es el nivel educacional de las personas. En este sentido, el nivel educacional puede considerarse como una variable contínua (p.ej: años de educación) o categórica (nivel/grado educacional), lo cual depende no solo de la distribución empírica de la variable sino que también del criterio de quien investiga.\nPara este ejercicio consideraremos la variable educación en base a las categorías de la Clasificación Internacional Normalizada de la Educación (UNESCO). La cual posee 5 niveles:\nsjmisc::frq(x = elsoc_18$edcine,show.na = F)\r## ## Educación (x) \u0026lt;numeric\u0026gt;\r## # total N=3703 valid N=2988 mean=3.21 sd=1.21\r## ## Value | Label | N | Raw % | Valid % | Cum. %\r## --------------------------------------------------------------------\r## 1 | Primaria incompleta menos | 442 | 11.94 | 11.94 | 11.94\r## 2 | Primaria y secundaria baja | 365 | 9.86 | 9.86 | 21.79\r## 3 | Secundaria alta | 1589 | 42.91 | 42.91 | 64.70\r## 4 | Terciaria ciclo corto | 592 | 15.99 | 15.99 | 80.69\r## 5 | Terciaria y Postgrado | 715 | 19.31 | 19.31 | 100.00\rY se distribuye de esta manera:\nplot_frq(data = elsoc_18$edcine)\rPara poder incluir esta variable en la regresión como categórica en R la manera más simple es definirla como un factor. Primero necesitamos conocer la estructura de la variable, ya que puede venir previamente definida como factor:\nclass(elsoc_18$edcine)\r## [1] \u0026quot;numeric\u0026quot;\rstr(elsoc_18$edcine)\r## num [1:3703] 2 3 3 4 3 3 3 4 5 2 ...\r## - attr(*, \u0026quot;labels\u0026quot;)= Named num [1:5] 1 2 3 4 5\r## ..- attr(*, \u0026quot;names\u0026quot;)= chr [1:5] \u0026quot;Primaria incompleta menos\u0026quot; \u0026quot;Primaria y secundaria baja\u0026quot; \u0026quot;Secundaria alta\u0026quot; \u0026quot;Terciaria ciclo corto\u0026quot; ...\r## - attr(*, \u0026quot;label\u0026quot;)= chr \u0026quot;Educación\u0026quot;\rVemos que al emplear class, R nos indica que edcine es una variable numérica con 5 valores distintos. Además, al correr str se nos indica que dichos valores numéricos poseen atributos en forma de etiquetas (labels). Entonces, si estimamos la regresión con la variable tal cual como está, obtenemos lo siguiente:\nreg3\u0026lt;-lm(ess~edcine,data = elsoc_18)\rsjPlot::tab_model(list(reg3), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3,\rdv.labels = c(\u0026quot;Modelo 3\u0026quot;))\r\r\rModelo 3\r\r\r\rPredictores\r\rβ\r\r\r\r(Intercept)\r\r3.329 ***\r\r\r\rEducación\r\r0.331 ***\r\r\r\rObservations\r\r3703\r\r\r\rR2 / R2 adjusted\r\r0.064 / 0.064\r\r\r\r\rp\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001\r\r\r\r\rEl coeficiente de regresión nos indica que por cada nivel adicional de educación, hay un aumento de 0.331 puntos en la escala de estatus social subjetivo. Sin embargo, dada la naturaleza de nuestra variable, decir “por cada nivel educacional” es poco informativo, por lo tanto la manera más adecuada de utilizar nuestra variable en la estimación de una regresión es transformarla en un factor empleando la función as_factor() De la librería sjlabelled .\nelsoc_18$edcine\u0026lt;-as_factor(elsoc_18$edcine)\rNota: en R existe la función as.factor(), sin embargo, en esa ocasión usamos as_factor() debido a que es compatible los vectores numéricos etiquetados y nos permite matener todos los atributos de las variables, tales como las etiquetas de variable y valores.\n\rTeniendo nuestra variable transformada a factor, estimamos nuevamente la regresión:\nreg4 \u0026lt;-lm(ess~edcine,data = elsoc_18)\rsjPlot::tab_model(list(reg3,reg4), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3,\rdv.labels = c(\u0026quot;Modelo 3\u0026quot;,\u0026quot;Modelo 4\u0026quot;))\r\r\rModelo 3\r\rModelo 4\r\r\r\rPredictores\r\rβ\r\rβ\r\r\r\r(Intercept)\r\r3.329 ***\r\r3.794 ***\r\r\r\rEducación\r\r0.331 ***\r\r\r\r\rEducación: Primaria y\nsecundaria baja\r\r\r0.151 \r\r\r\rEducación: Secundaria\nalta\r\r\r0.476 ***\r\r\r\rEducación: Terciaria\nciclo corto\r\r\r0.811 ***\r\r\r\rEducación: Terciaria y\nPostgrado\r\r\r1.279 ***\r\r\r\rObservations\r\r3703\r\r3703\r\r\r\rR2 / R2 adjusted\r\r0.064 / 0.064\r\r0.066 / 0.065\r\r\r\r\rp\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001\r\r\r\r\rInterpretación\rAl igual que en el modelo empleando Educación como variable continua, el modelo con Educación categórica muestra que a medida que aumenta el nivel educacional, el promedio de estatus subjetivo tiende a ser más alto. Por otro lado, en este caso la categoría de referenca es Primaria Incompleta o menos. Entonces:\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Primaria y Secundaria baja es 0.151 puntos más alto con respecto a las personas con educación Primaria Incompleta o menos.\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Secundaria Alta es 0.476 más alto con respecto a las personas con educación Primaria Incompleta o menos.\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Terciaria ciclo corto es 0.811 más alto con respecto a las personas con educación Primaria Incompleta o menos.\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Terciaria y Postgrado es de 1.279 más alto con respecto a las personas con educación Primaria Incompleta o menos.\n\rAlternativamente es posible cambiar la categoría de referencia. Por ejemplo, si quisieramos que la referencia fuera el nivel educativo más alto “Terciaria y Postgrado” (5) debemos usar relevel(edcine, ref =5):\r\rreg4.1 \u0026lt;-lm(ess~relevel(edcine,ref=5),data = elsoc_18)\rsummary(reg4.1)\r## ## Call:\r## lm(formula = ess ~ relevel(edcine, ref = 5), data = elsoc_18)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -5.0727 -0.7941 0.0548 0.7300 6.2059 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 5.07273 0.05710 88.833 \u0026lt; 2e-16 ***\r## relevel(edcine, ref = 5)1 -1.27861 0.09239 -13.839 \u0026lt; 2e-16 ***\r## relevel(edcine, ref = 5)2 -1.12752 0.09823 -11.479 \u0026lt; 2e-16 ***\r## relevel(edcine, ref = 5)3 -0.80275 0.06876 -11.674 \u0026lt; 2e-16 ***\r## relevel(edcine, ref = 5)4 -0.46800 0.08485 -5.516 3.71e-08 ***\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 1.527 on 3698 degrees of freedom\r## Multiple R-squared: 0.06634, Adjusted R-squared: 0.06533 ## F-statistic: 65.69 on 4 and 3698 DF, p-value: \u0026lt; 2.2e-16\r\rVariables dummy\rLa manera tradicional de incluir predictores categóricos de más de dos niveles (variable politómica) es a través de las denominadas variables dummy. Tal como vimos en el ejemplo anterior, se incluyen n-1 categorías en el modelo dado que siempre se mantiene una como categoría de referencia.\nPara explorar nuestra base de datos, usaremos la función head() que nos mostrará las primeras 6 filas de nuestra base de datos para observar la variable Educación.\nhead(elsoc_18)\r## ess sexo edad edcine\r## 1 9 0 66 2\r## 2 5 0 62 3\r## 3 5 0 28 3\r## 4 5 1 53 4\r## 5 5 1 63 3\r## 6 5 0 56 3\rPara la construcción de las variables dummy, usaremos la función dummy_cols() de la librería fastDummies. En el argumento select_columns, le indicamos cuál es la variable que usaremos para construir las variables dummy:\nlibrary(fastDummies)\relsoc_18 \u0026lt;-dummy_cols(elsoc_18,select_columns = \u0026quot;edcine\u0026quot;)\rRevisamos nuestra base de datos:\nhead(elsoc_18)\r## ess sexo edad edcine edcine_1 edcine_2 edcine_3 edcine_4 edcine_5\r## 1 9 0 66 2 0 1 0 0 0\r## 2 5 0 62 3 0 0 1 0 0\r## 3 5 0 28 3 0 0 1 0 0\r## 4 5 1 53 4 0 0 0 1 0\r## 5 5 1 63 3 0 0 1 0 0\r## 6 5 0 56 3 0 0 1 0 0\rTal como se estimó en el modelo anterior, ahora lo que haremos es seleccionar cada dummy para las categorías 2, 3, 4 y 5 de la variable edcine. Esto implica que el nivel 1 (Primaria incompleta o menos) será la categoría de referencia.\nreg5 \u0026lt;-lm(ess~edcine_2+edcine_3+edcine_4+edcine_5,data = elsoc_18)\rsjPlot::tab_model(list(reg4, reg5), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3,\rdv.labels = c(\u0026quot;Modelo 4\u0026quot;,\u0026quot;Modelo 5\u0026quot;))\r\r\rModelo 4\r\rModelo 5\r\r\r\rPredictores\r\rβ\r\rβ\r\r\r\r(Intercept)\r\r3.794 ***\r\r3.794 ***\r\r\r\rEducación: Primaria y\nsecundaria baja\r\r0.151 \r\r\r\r\rEducación: Secundaria\nalta\r\r0.476 ***\r\r\r\r\rEducación: Terciaria\nciclo corto\r\r0.811 ***\r\r\r\r\rEducación: Terciaria y\nPostgrado\r\r1.279 ***\r\r\r\r\redcine 2\r\r\r0.151 \r\r\r\redcine 3\r\r\r0.476 ***\r\r\r\redcine 4\r\r\r0.811 ***\r\r\r\redcine 5\r\r\r1.279 ***\r\r\r\rObservations\r\r3703\r\r3703\r\r\r\rR2 / R2 adjusted\r\r0.066 / 0.065\r\r0.066 / 0.065\r\r\r\r\rp\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001\r\r\r\r\rSi observamos la tabla de arriba, vemos que las estimaciones para el modelo 4 y 5 son idénticas. La única diferencia es que en el Modelo 5 empleamos dummies para cada categoría en vez de utilizar la variable como un factor.\n\r\r\rInferencia\rUna de las ideas fundamentales de la inferencia es determinar si nuestros análisis estadísticos pueden ser extrapolados a la población que estamos estudiando. En el contexto de regresión, queremos conocer la significación estadística del coeficiente \\(\\beta\\).\nQueremos saber :\n¿Es significativo el coeficiente del modelo de regresión?.\n\rPara ello, buscamos determinar la probabilidad de que \\(\\beta \\neq 0\\)\n\rEl concepto fundamental es el Error.\n\r\rConceptos clave:\nDispersión\rCurva normal\rError estándar\r\rEjemplo\nSupongamos que nuestra muestra de 3703 casos corresponde a la Población, de modo tal que vamos a extraer una serie de muestras aleatorias de esta “Población” a modo de ilustrar cambios en la dispersión de los datos en la medida que aumenta el tamaño muestral.\n\rRecordemos que la fórmula del Error Estándar para una muestra es : \\(\\frac{s}{\\sqrt{N}}\\) donde \\(s\\) es la desviación estándar y \\(N\\) es el tamaño de la muestra.\n\rBajo el supuesto de que el promedio calculado para la muestra \\(\\bar{x}\\) posee una distribución normal con una \\(s = \\text{Error Estándar (SE)}\\), es posible calcular la probabilidad de error siguiendo dicha distribución. Donde \\(\\bar{x} \\pm 2\\text{ SE}\\) abarca el 95% de la distribución.\n\r\rset.seed(123)\relsoc_n30 \u0026lt;-sample_n(tbl = elsoc_18,size = 30 ) %\u0026gt;%mutate(dataset=30 ,mean_ess=mean(ess,na.rm = T))\relsoc_n50 \u0026lt;-sample_n(tbl = elsoc_18,size = 50 ) %\u0026gt;%mutate(dataset=50 ,mean_ess=mean(ess,na.rm = T))\relsoc_n75 \u0026lt;-sample_n(tbl = elsoc_18,size = 75 ) %\u0026gt;%mutate(dataset=75 ,mean_ess=mean(ess,na.rm = T))\relsoc_n100 \u0026lt;-sample_n(tbl = elsoc_18,size = 100) %\u0026gt;%mutate(dataset=100,mean_ess=mean(ess,na.rm = T))\relsoc_n200 \u0026lt;-sample_n(tbl = elsoc_18,size = 200) %\u0026gt;%mutate(dataset=200,mean_ess=mean(ess,na.rm = T))\relsoc_n300 \u0026lt;-sample_n(tbl = elsoc_18,size = 300) %\u0026gt;%mutate(dataset=300 ,mean_ess=mean(ess,na.rm = T))\relsoc_n400 \u0026lt;-sample_n(tbl = elsoc_18,size = 400) %\u0026gt;%mutate(dataset=400,mean_ess=mean(ess,na.rm = T))\relsoc_n700 \u0026lt;-sample_n(tbl = elsoc_18,size = 700) %\u0026gt;%mutate(dataset=700,mean_ess=mean(ess,na.rm = T))\relsoc_n800 \u0026lt;-sample_n(tbl = elsoc_18,size = 800) %\u0026gt;%mutate(dataset=800,mean_ess=mean(ess,na.rm = T))\relsoc_n900 \u0026lt;-sample_n(tbl = elsoc_18,size = 900) %\u0026gt;%mutate(dataset=900,mean_ess=mean(ess,na.rm = T))\relsoc_n1000\u0026lt;-sample_n(tbl = elsoc_18,size = 1000) %\u0026gt;%mutate(dataset=1000,mean_ess=mean(ess,na.rm = T))\relsoc_n1500\u0026lt;-sample_n(tbl = elsoc_18,size = 1500) %\u0026gt;%mutate(dataset=1500,mean_ess=mean(ess,na.rm = T))\relsoc_n2000\u0026lt;-sample_n(tbl = elsoc_18,size = 2000) %\u0026gt;%mutate(dataset=2000,mean_ess=mean(ess,na.rm = T))\relsoc_n2500\u0026lt;-sample_n(tbl = elsoc_18,size = 2500) %\u0026gt;%mutate(dataset=2500,mean_ess=mean(ess,na.rm = T))\r# elsoc \u0026lt;- elsoc_18 %\u0026gt;% mutate(dataset=3703,mean_ess=mean(ess,na.rm = T))\r\rfullmat\u0026lt;-bind_rows(elsoc_n30 ,elsoc_n50 ,elsoc_n75 ,elsoc_n100,elsoc_n200,elsoc_n300,elsoc_n400,elsoc_n700,elsoc_n800,elsoc_n900,elsoc_n1000,elsoc_n1500,elsoc_n2000,elsoc_n2500)\rfullmat \u0026lt;-fullmat %\u0026gt;%mutate(mean_ssta=mean(elsoc_18$ess,na.rm = T))\rLuego de obtener las muestras, calculamos la media, desviación estándar y Error estándar:\ntab_full\u0026lt;-fullmat %\u0026gt;%group_by(dataset) %\u0026gt;%summarise(mean=mean(ess,na.rm = T), sd=sd(ess,na.rm = T),SE=sd/sqrt(n()))\rtab_full\r## # A tibble: 14 x 4\r## dataset mean sd SE\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 30 4.07 1.41 0.258 ## 2 50 4.58 1.59 0.225 ## 3 75 4.39 1.60 0.185 ## 4 100 4.4 1.49 0.149 ## 5 200 4.46 1.47 0.104 ## 6 300 4.3 1.55 0.0893\r## 7 400 4.36 1.58 0.0789\r## 8 700 4.35 1.62 0.0611\r## 9 800 4.38 1.54 0.0544\r## 10 900 4.36 1.58 0.0525\r## 11 1000 4.40 1.57 0.0498\r## 12 1500 4.39 1.56 0.0403\r## 13 2000 4.42 1.56 0.0349\r## 14 2500 4.38 1.58 0.0317\r\rEs posible observar que tanto la media como la desviación estándar van cambiando en la medida que aumenta el tamaño de la muestra, pero si observamos el Error Estándar, este va sistemáticamente disminuyendo en la medida que aumenta el tamaño muestral.\r\rPara ilustrar cómo va cambiando la dispersión y la media “muestral” (rojo) con respecto a la “poblacional” (verde), se puede observar el siguiente gráfico:\n\rEste ejemplo sirve para ilustrar de qué manera el Error Estándar de la media \\(\\bar{x}\\) nos permite determinar la significancia estadística de un coeficiente de regresión \\(\\beta\\).\n\rEn regresión nos interesa saber si las diferencias en Y con respecto a los distintos niveles o valores de X son significativas, es decir estadisticamente distintas de 0.\n\r\rVolviendo nuestro ejemplo inicial: Estatus Social subjetivo según Sexo.\n\rEstimamos una regresión para cuatro de las muestras de distinto tamaño usando Sexo como predictor de Estatus subjetivo.\r\rreg100 \u0026lt;-lm(ess~sexo,data=elsoc_n100)\rreg1500\u0026lt;-lm(ess~sexo,data=elsoc_n1500)\rreg2000\u0026lt;-lm(ess~sexo,data=elsoc_n2000)\rreg2500\u0026lt;-lm(ess~sexo,data=elsoc_n2500)\r\rNos interesa saber si el promedio de Mujeres respecto de Hombres es distinto de 0.\n\rLa estimación de la regresión realiza este procedimiento a través del cálculo de la significación estadística. Los modelos entregan el resultado ya calculado en base al Error Estándar del \\(\\beta\\).\n\rPara determinar esto, se realiza una prueba de hipótesis nula. En regresión la hipótesis nula es:\n\r\r\\[ H_0: \\beta =0\\]\rEn relación a la hipótesis alternativa:\n\\[ H_1: \\beta \\neq 0\\]\n\rEste contraste se basa en el cálculo de un invervalo de confianza para el coeficiente, asumiendo +/- 2 SE (o al 95% de confianza). Entonces, si este intervalo no pasa por cero, entonces rechazamos \\(H_0\\).\n\rEntonces, ¿es estadísticamente significativa la diferencia del promedio de Estatus Subjetivo entre hombres y mujeres?. Revisemos para nuestras muestras de distinto tamaño:\n\r\rrbind(broom::tidy(reg100)[2,1:3], # n=100\rbroom::tidy(reg1500)[2,1:3], # n=1500\rbroom::tidy(reg2000)[2,1:3], # n=2000\rbroom::tidy(reg2500)[2,1:3]) # n=2500\r## # A tibble: 4 x 3\r## term estimate std.error\r## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 sexo 0.0440 0.314 ## 2 sexo 0.0489 0.0829\r## 3 sexo 0.145 0.0715\r## 4 sexo 0.196 0.0649\r\rAl igual que en ejemplo anterior, el error estándar va sistematicamente disminuyendo en la medida que empleamos una muestra más grande. Ahora, ¿son estas diferencias en el promedio entre mujeres respecto de hombres estadísticamente signifciativas al 95% de confianza?. Calculemos los intervalos de confianza:\n\rPara el caso de la muestra de 100 casos tenemos:\n\r\r#Beta +/- 2*SE = IC\r0.0440 -2*0.314 #intervalo confianza inferior\r0.0440 +2*0.314 #intervalo confianza superior\r## [1] -0.584\r## [1] 0.672\r\rPara el caso de la muestra de 1500 casos tenemos:\r\r0.0489 -2*0.0829 #intervalo confianza inferior\r0.0489 +2*0.0829 #intervalo confianza superior\r## [1] -0.1169\r## [1] 0.2147\r\rPara el caso de la muestra de 2000 casos tenemos:\r\r0.145 -2*0.0715 #intervalo confianza inferior\r0.145 +2*0.0715 #intervalo confianza superior\r## [1] 0.002\r## [1] 0.288\r\rPara el caso de la muestra de 2500 casos tenemos:\r\r0.196 -2*0.0649 #intervalo confianza inferior\r0.196 +2*0.0649 #intervalo confianza superior\r## [1] 0.0662\r## [1] 0.3258\r\rVemos que para las muestras de 100 y 1500, el intervalo inferior cruza el valor 0, por tanto no rechazamos \\(H_0\\). Lo cual implica que no hay diferencias estadísticamente significativas en el promedio de estatus social subjetivo de mujeres respecto de hombres.\n\rPor otro lado, en muestras de 2000 y 2500, el intervalo inferior no cruza el valor 0, por tanto rechazamos \\(H_0\\). Lo cual implica que la diferencia en el promedio de estatus social subjetivo de mujeres respecto de hombres es estadísticamente signficativa a un 95% de confianza.\n\r\rVisualmente lo podemos ver en el siguiente gráfico usando la librería coefplot.\n\rCada punto representa el coeficiente de Sexo (Mujer=1) para cada modelo.\rLas líneas horizontales representan los intervalos de confianza.\r\rcoefplot::multiplot(reg2500,reg2000,reg1500,reg100,\rshorten = T,\rintercept = F,\rxlab = \u0026quot;\u0026quot;,title = \u0026quot;Modelos según tamaño de muestra\u0026quot;,\rzeroColor = \u0026quot;black\u0026quot;,\rlinetype = 1) +\rscale_y_discrete(\u0026quot;\u0026quot;,labels = c(\u0026quot;Sexo (mujer=1)\u0026quot;)) +\rtheme_bw()\rDe manera resumida en una tabla podemos verlo así:\nsjPlot::tab_model(list(reg100,reg1500,reg2000,reg2500),\rdv.labels = c(\u0026quot;n=100\u0026quot;,\u0026quot;n=1500\u0026quot;,\u0026quot;n=2000\u0026quot;,\u0026quot;n=2500\u0026quot;),\rshow.se = T,digits = 3,\rstring.est = \u0026quot;β\u0026quot;,show.intercept = F,\rstring.ci = \u0026quot;CI 95%\u0026quot;,string.se = \u0026quot;SE\u0026quot;,\rshow.p = F)\r\r\rn=100\r\rn=1500\r\rn=2000\r\rn=2500\r\r\r\rPredictors\r\rβ\r\rSE\r\rCI 95%\r\rβ\r\rSE\r\rCI 95%\r\rβ\r\rSE\r\rCI 95%\r\rβ\r\rSE\r\rCI 95%\r\r\r\rSexo(1=Mujer)\r\r0.044\r\r0.314\r\r-0.579 – 0.667\r\r0.049\r\r0.083\r\r-0.114 – 0.212\r\r0.145\r\r0.072\r\r0.004 – 0.285\r\r0.196\r\r0.065\r\r0.069 – 0.323\r\r\r\rObservations\r\r100\r\r1500\r\r2000\r\r2500\r\r\r\rR2 / R2 adjusted\r\r0.000 / -0.010\r\r0.000 / -0.000\r\r0.002 / 0.002\r\r0.004 / 0.003\r\r\r\r\rResumen Práctica 7\rEn esta práctica revisamos los siguientes contenidos:\n\rPredictores categóricos\rVariables dummy\rInferencia estadística\rInferencia en Regresión\r\r\rReporte de progreso\rCompletar el reporte de progreso correspondiente a esta práctica [https://forms.gle/ACUm93yHPQQpLco4A]\n\rForo práctica 7\r\r","date":1593734400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1594262039,"objectID":"48f42589bcb94587b7dfcb568ba66719","permalink":"/assignment/07-code/","publishdate":"2020-07-03T00:00:00Z","relpermalink":"/assignment/07-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 7. Inferencia y predictores categóricos","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de la clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\rLecturas\rMoore: Residuos (144-154)\n\r","date":1593129600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1593230635,"objectID":"119022d4a0cb3ad45bc292e062e9e05a","permalink":"/class/06-class/","publishdate":"2020-06-26T00:00:00Z","relpermalink":"/class/06-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de la clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\rLecturas\rMoore: Residuos (144-154)\n\r","tags":null,"title":"Regresión múltiple 2","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo de la práctica\rLibrerías\rDatos\rExplorar base de datos\rModelo de regresión simple\rRelacion entre variables\rModelo de regresión multiple\rInterpretación\rIntercepto\rCoeficientes de regresion\r\rComparando el modelo de regresión simple con múltiple\r¿Por qué utilizar R^2 ajustado?\r\rResumen Práctica 5:\rReporte de progreso\rForo práctica 5\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo de la práctica\rEn esta práctica nos enfocaremos en el concepto de regresión múltiple, a partir de la incorporación de dos o más predictores en el modelo. Para ello utilizaremos el ejemplo 3.1 de Wooldridge (2010) cap. 3 (Análisis de regresion múltiple) (p.68-80) sobre las determinantes del promedio en la universidad.\nLibrerías\rpacman::p_load(ggpubr, #graficos\rdplyr, #manipulacion de datos\rsjPlot, #tablas\rgridExtra, #unir graficos\rtexreg, #mostrar regresion multiple\rsummarytools, #estadisticos descriptivos\rwooldridge) #paquete con los ejemplos del libro\r\rDatos\rLos datos a utilizar corresponden a la base de datos gpa1 que incluye una muestra de 141 estudiantes de una universidad. La base contiene vaiables\r- [\\(colGPA\\)]: promedio general de calificaciones de la universidad, en escala de 0 a 4 puntos.\r- [\\(hsGPA\\)]: promedio general de calificaciones en la enseñanza media, en escala de 0 a 4 puntos\r- [\\(ACT\\)]: puntaje en el examen de admisión a la universidad, que va de 16 a 33 puntos\rPrimero, se cargará la base de datos que contiene la librería wooldridge y se seleccionarán las variables señaladas\ndata(\u0026#39;gpa1\u0026#39;) # Cargar base de datos\rgpa1 \u0026lt;-dplyr::select(gpa1, colGPA, hsGPA, ACT) #Seleccion de variables\r\rExplorar base de datos\rA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(gpa1, headings = FALSE, method = \u0026#39;render\u0026#39;))\r## Warning in png(png_loc \u0026lt;- tempfile(fileext = \u0026quot;.png\u0026quot;), width = 150 *\r## graph.magnif, : X cannot set locale modifiers\r## Warning in png(png_loc \u0026lt;- tempfile(fileext = \u0026quot;.png\u0026quot;), width = 150 *\r## graph.magnif, : X cannot set locale modifiers\r## Warning in png(png_loc \u0026lt;- tempfile(fileext = \u0026quot;.png\u0026quot;), width = 150 *\r## graph.magnif, : X cannot set locale modifiers\r\rModelo de regresión simple\rSi solo nos centramos en el análisis de regresión simple, intuitivamente partiremos por predecir las calificaciones de la universidad a partir del puntaje obtenido en la prueba de admisión a esta. Formalmente\n\\[\\widehat{colGPA} = b_{0} +b_{1}ACT \\]\ncol_actmodel\u0026lt;-lm(colGPA ~ACT, data=gpa1) #Crear regresion simple\rsummary(col_actmodel)\r## ## Call:\r## lm(formula = colGPA ~ ACT, data = gpa1)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -0.85251 -0.25251 -0.04426 0.26400 0.89336 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 2.40298 0.26420 9.095 8.8e-16 ***\r## ACT 0.02706 0.01086 2.491 0.0139 * ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 0.3656 on 139 degrees of freedom\r## Multiple R-squared: 0.04275, Adjusted R-squared: 0.03586 ## F-statistic: 6.207 on 1 and 139 DF, p-value: 0.0139\rEn formato publicable:\nsjPlot::tab_model(col_actmodel, show.ci=FALSE) #Tabla resumen de resultados\r\r\rcol GPA\r\r\r\rPredictors\r\rEstimates\r\rp\r\r\r\r(Intercept)\r\r2.40\r\r\u0026lt;0.001\r\r\r\rACT\r\r0.03\r\r0.014\r\r\r\rObservations\r\r141\r\r\r\rR2 / R2 adjusted\r\r0.043 / 0.036\r\r\r\rEn consecuencia, nuestro modelo que relaciona el promedio de calificaciones en la universidad solo con el puntaje obtenido en el examen de admisión señala que por cada punto adicional que se obtiene en la prueba de admisión, el promedio de la universidad aumenta en 0.027 (aproximado en la tabla de sjPlot a 0.03) puntos promedio.\n\\[\\widehat{colGPA} = 2.40 +0.0271ACT \\]\nAhora bien, si miramos nuestro \\(R^2\\) notaremos que \\(ACT\\) solo explica en un 4.3% la varianza de \\(colGPA\\). Por ello, incluiremos el promedio de las calificaciones de la enseñanza media (\\(hsGPA\\)) para intentar predecir mejor el promedio general de las calificaciones en la universidad.\n\rRelacion entre variables\rSe grafican las variables que determinarían \\(colGPA\\) para comparar sus distribuciones y sus pendientes (\\(b\\)) de sus respectivas regresiones simples.\n#Grafico x1 = ACT\rgact \u0026lt;-ggscatter(gpa1, x = \u0026quot;ACT\u0026quot;, y = \u0026quot;colGPA\u0026quot;,\rshape = 21, size = 3, # Forma y tamaño de puntos\radd = \u0026quot;reg.line\u0026quot;, #Agregar recta de regresion\rcor.coef = TRUE)# Agregar coeficiente correlacion\r#Grafico x2 = hsGPA\rghsGPA \u0026lt;-ggscatter(gpa1, x = \u0026quot;hsGPA\u0026quot;, y = \u0026quot;colGPA\u0026quot;,\rshape = 21, size = 3,\radd = \u0026quot;reg.line\u0026quot;,\rcor.coef = TRUE)\r\rgrid.arrange(gact, ghsGPA, nrow = 1) # Unir graficos\rCon el gráfico anterior podemos notar que si bien ambas variables tienen una asociación positiva con \\(colGPA\\), el tamaño efecto de esta relación es distinta. Incluso, \\(hsGPA\\) que no había sido considerada en nuestro modelo inicial, tiene una asociación más grande con nuestra variable dependiente.\rAhora bien, ¿cómo incide \\(ACT\\) y \\(hsGPA\\) en conjunto sobre \\(colGPA\\)?\n\rModelo de regresión multiple\rPara estimar el modelo de regresión multiple se debe realizar el mismo procedimiento de la regresión simple, solo que ahora deben señalar un (+) y el segundo predictor\nGrabar / exportar tablas :Exportar tablas \rmodelo \u0026lt;- lm(y ~ x1 + x2 , data = data)\n\rcol_actmodel\u0026lt;-lm(colGPA ~ACT, data=gpa1)\rcol_hsmodel\u0026lt;-lm(colGPA ~hsGPA, data=gpa1)\rcol_model \u0026lt;-lm(colGPA ~ACT +hsGPA, data = gpa1)\rsjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;),string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)\r\r\rModelo 1\r\rModelo 2\r\rModelo 3\r\r\r\rPredictores\r\rβ\r\rβ\r\rβ\r\r\r\r(Intercept)\r\r2.40 ***\r\r1.42 ***\r\r1.29 ***\r\r\r\rACT\r\r0.03 *\r\r\r0.01 \r\r\r\rhsGPA\r\r\r0.48 ***\r\r0.45 ***\r\r\r\rObservations\r\r141\r\r141\r\r141\r\r\r\rR2 / R2 adjusted\r\r0.043 / 0.036\r\r0.172 / 0.166\r\r0.176 / 0.164\r\r\r\r\rp\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001\r\r\r\r\r\\[\\widehat{colGPA} = 1.29 +0.0094 \\dot\\ ACT + 0.453\\dot\\ hsGPA \\]\n\rInterpretación\r¿Cómo se interpreta esta ecuación general de \\(colGPA\\) con dos predictores?\nIntercepto\r\rEl intercepto 1.20 indica la predicción del promedio general de calificaciones en la universidad (\\(colGPA\\)) si \\(hsGPA\\) y \\(ACT\\) son ambos cero. Este intercepto no tiene mucho significado debido a que eso implica un individuo ficticio que no haya ni asistido a la universidad ni haya asistido a la enseñanza media, por lo cual no es parte de nuestra pregunta por las determinantes del promedio en la universidad.\r\r\rCoeficientes de regresion\r\rFijémonos en los coeficientes de regresión de \\(hsGPA\\). Como era de esperar en función de los gráficos que habíamos presentado, existe una relación positiva entre \\(hsGPA\\) y \\(colGPA\\): con \\(ACT\\) constante, cada punto más en \\(hsGPA\\) se relaciona con un aumento en 0.453 puntos adicionales en \\(colGPA\\), es decir, casi medio punto.\r\rEn otras palabras, si se eligen dos estudiantes, A y B, y estos tienen la misma puntación en el exámen de admisión (\\(ACT\\)), pero el promedio en la enseñanza media de A es mayor al de B (\\(hsGPA\\)), entonces se predice que en la universidad el estudiante A tendrá un promedio general de 0.453 puntos más altos que el estudiante B.\n\rFijémonos ahora en el coeficiente de regresión de \\(ACT\\): si \\(hsGPA\\) permanece constante, un aumento en un punto de \\(ACT\\) solo produce un aumento en 0.0094 puntos en \\(colGPA\\), es decir, un cambio muy pequeño.\r\rDe hecho, un cambio de 10 puntos en el examen de admisión \\(ACT\\) tendrá un efecto sobre \\(colGPA\\) de menos de una décima de punto, es decir, menor al cambio que tiene \\(hsGPA\\). Además, la posibilidad de tener un cambio de 10 puntos en \\(ACT\\) es muy grande pues como mostramos en los estadísticos descriptivos de nuestras variables el promedio de puntaje en \\(colGPA\\) es 24 puntos con una desviación estándar de 2.8, lo que hace poco posible ese cambio en la realidad.\nCon esto podemos decir que el puntaje en el examen de admisión \\(ACT\\) no es un fuerte predictor del promedio de calificaciones en la universidad \\(colGPA\\).\n\r\rComparando el modelo de regresión simple con múltiple\rIniciamos este práctico mostrando un análisis de regresión simple con un predictor para el promedio de calificaciones en la universidad: el promedio en el examen de admisión (\\(ACT\\)).\nObtuvimos que por cada punto de aumento de \\(ACT\\), \\(colGPA\\) aumentaba en 0.0271 puntos sus calificaciones, es decir, casi el triple de lo que fue estimado en el modelo de regresión múltiple (tal como se señala en Modelo 1)\n¿Cuál de los dos modelos es más certero?\nEsto lo podemos definir a partir de la bondad de ajuste de nuestros modelos. Por un lado, el \\(R^2\\) del modelo 1 es de 4.3% mientras que en el modelo 3 el \\(R^2ajustado\\) es de 16%, es decir, las variables que se contienen en el modelo explican más la varianza de nuestra variable dependiente.\n\r¿Por qué utilizar R^2 ajustado?\rHasta ahora habíamos utilizado \\(R^2\\) que nos señalaba qué porcentaje de la variación de la variable dependiente es explicada por la variable independiente.\nAhora bien, es esperable que a medida que añadimos más variables a una regresión, el \\(R^2\\) tiende a aumentar a pesar de que la contribución de cada una de las variables nuevas no tenga relevancia estadística.\nPor ello, el \\(R^2\\) ajustado se utiliza en la regresión múltiple para analizar en conjunto la intensidad que tienen las variables independientes en explicar la variable dependiente. Es decir, el \\(R^2\\) ajustado nos dice qué porcentaje de variación de la variable dependiente es explicado colectivamente por todas las variables independientes.\nEn consecuencia, \\(R^2\\) ajustado nos permite determinar mejor si añadir una nueva variable al modelo permite explicar una mayor parte de la variación de la variable dependientE.\nEn el ejercicio anterior bien podemos hacer este análisis comparando los \\(R^2\\) de nuestros modelos 1 y 2 para luego mirar el resultado de nuestro \\(R^2\\) ajustado en nuestro modelo 3. Como podremos notar el \\(R^2\\) del modelo 2 es de 17%, mientras que el \\(R^2\\) es de 18% y el \\(R^2\\) ajustado de 16%.\nEn palabras más simples, si solo miramos el \\(R^2\\) llegaremos a la conclusión de que aunque por mínimo que sea, nuestro modelo 3 ajusta mejor que el modelo 2 pues la variable \\(ACT\\) permitiría predecir mejor \\(colGPA\\) en conjunto a \\(hsGPA\\). Sin embargo, \\(R^2 ajustado\\) del modelo 3 (16%) es menor que la del modelo 2 (17%) por lo que la incorporación de \\(ACT\\) al modelo múltiple no tiene un aporte significativo.\nDe hecho, un punto no menor es que \\(ACT\\) pierde significancia estadística en el modelo 3, mientras que \\(hsGPA\\) sigue siendo significativa con un 99% confianza (la significancia estadística lo revisaremos más adelante).\n\r\rResumen Práctica 5:\rEn esta práctica revisamos los siguientes contenidos\n\rRepaso de regresión lineal simple\rEstimación de regresión lineal múltiple\rInterpretar regresión lineal múltiple\rComparar regresión múltiple y simple\rDiferencia entre \\(R^2\\) ajustado y \\(R^2\\)\r\r\rReporte de progreso\rCompletar el reporte de progreso correspondiente a esta práctica aquí.\n\rForo práctica 5\r\r","date":1592784000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1592791125,"objectID":"e933840b45d355c28b7bb0057d254a85","permalink":"/assignment/05-code/","publishdate":"2020-06-22T00:00:00Z","relpermalink":"/assignment/05-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 5. Regresión múltiple 1 ","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo de la práctica\rLibrerías\rDatos\rExplorar base de datos\rRelacion entre variables\rModelo de regresión multiple\rInterpretación\r¿Porqué se alteran los coeficientes de regresión?\r\rParcialización\rParcializar \\(ACT\\) de \\(hsGPA\\)\r\rControl estadístico\r¿Qué significa mantener todos los demás factores constantes?\r\rResumen Práctica 6:\rReporte de progreso\rForo práctica 6\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo de la práctica\rEn esta práctica nos enfocaremos en el significado de las parcializaciones en la regresión múltiple. Para ello utilizaremos el ejemplo 3.1 de Wooldrige (2010) cap. 3 (Análisis de regresion múltiple) (p.68-80) sobre las determinantes del promedio en la universidad.\nLibrerías\rpacman::p_load(ggpubr, #graficos\rdplyr, #manipulacion de datos\rsjPlot, #tablas\rgridExtra, #unir graficos\rtexreg, #mostrar regresion multiple\rsummarytools, #estadisticos descriptivos\rwooldridge) #paquete con los ejemplos del libro\rlibrary(wooldridge)\r\rDatos\rLos datos a utilizar corresponden a la base de datos gpa1 que incluye una muestra de 141 estudiantes de una universidad. La base contiene variables:\n\r\\(colGPA\\): promedio general de calificaciones de la universidad, en escala de 0 a 4 puntos.\n\r\\(hsGPA\\) : promedio general de calificaciones en la enseñanza media, en escala de 0 a 4 puntos\n\r\\(ACT\\) : puntaje en el examen de admisión a la universidad, que va de 16 a 33 puntos\n\r\rPrimero, se cargará la base de datos que contiene la librería wooldrige y se seleccionarán las variables señaladas\ndata(\u0026#39;gpa1\u0026#39;) # Cargar base de datos\rgpa1 \u0026lt;-dplyr::select(gpa1, colGPA, hsGPA, ACT) #Seleccion de variables\r\rExplorar base de datos\rA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(gpa1, headings = FALSE, method = \u0026quot;render\u0026quot;))\r## Warning in png(png_loc \u0026lt;- tempfile(fileext = \u0026quot;.png\u0026quot;), width = 150 *\r## graph.magnif, : X cannot set locale modifiers\r## Warning in png(png_loc \u0026lt;- tempfile(fileext = \u0026quot;.png\u0026quot;), width = 150 *\r## graph.magnif, : X cannot set locale modifiers\r## Warning in png(png_loc \u0026lt;- tempfile(fileext = \u0026quot;.png\u0026quot;), width = 150 *\r## graph.magnif, : X cannot set locale modifiers\r\r\rNo\rVariable\rStats / Values\rFreqs (% of Valid)\rGraph\rValid\rMissing\r\r\r\r\r1\rcolGPA\r[numeric]\rMean (sd) : 3.1 (0.4)\rmin 19 distinct values\r\r141\r(100%)\r0\r(0%)\r\r\r2\rhsGPA\r[numeric]\rMean (sd) : 3.4 (0.3)\rmin 16 distinct values\r\r141\r(100%)\r0\r(0%)\r\r\r3\rACT\r[integer]\rMean (sd) : 24.2 (2.8)\rmin 15 distinct values\r\r141\r(100%)\r0\r(0%)\r\r\r\rGenerated by summarytools 0.9.6 (R version 4.0.0)2020-08-20\n\r\rRelacion entre variables\rSe grafican la relación entre las variables que determinarían \\(colGPA\\) para comparar sus distribuciones y sus pendientes (\\(b\\)) de sus regresiones simples. A su vez, se grafica un tercer gráfico que muestra la correlación entre las variables independientes.\n#Grafico x1 = ACT y= colGPA\rgact \u0026lt;-ggscatter(gpa1, x = \u0026quot;ACT\u0026quot;, y = \u0026quot;colGPA\u0026quot;,\rshape = 21, size = 3, # Forma y tamaño de puntos\radd = \u0026quot;reg.line\u0026quot;, #Agregar recta de regresion\rcor.coef = TRUE)# Agregar coeficiente correlacion\r#Grafico x2 = hsGPA y= colGPA\rghsGPA \u0026lt;-ggscatter(gpa1, x = \u0026quot;hsGPA\u0026quot;, y = \u0026quot;colGPA\u0026quot;,\rshape = 21, size = 3,\radd = \u0026quot;reg.line\u0026quot;,\rcor.coef = TRUE)\r\r#Grafico x2 = hsGPA x1 = ACT\rgact_hs \u0026lt;-ggscatter(gpa1, x = \u0026quot;hsGPA\u0026quot;, y = \u0026quot;ACT\u0026quot;,\rshape = 21, size = 3,\radd = \u0026quot;reg.line\u0026quot;,\rcor.coef = TRUE)\r\rgrid.arrange(gact, ghsGPA, gact_hs, nrow = 1) # Unir graficos\rCon el gráfico anterior podemos notar dos puntos relevantes:\n\rSi bien ambas variables tienen una asociación positiva con \\(colGPA\\), el tamaño efecto de esta relación es distinta. Incluso, \\(hsGPA\\) que no había sido considerada en nuestro modelo inicial, tiene una asociación más grande con nuestra variable dependiente.\n\rComo es de esperar, existe una relación entre las calificaciones en la enseñanza media (\\(hsGPA\\)) y el puntaje en la prueba de admisión (\\(ACT\\)). Específicamente, ambas variables tienen una asociación positiva de 0.35.\n\r\rEn la práctica 5 nos preguntamos ¿cómo incide \\(ACT\\) y \\(hsGPA\\) en conjunto sobre \\(colGPA\\)?, sin profundizar en qué implica que nuestros predictores de \\(colGPA\\) estén correlacionados. Retomemos nuevamente nuestro modelo\n\rModelo de regresión multiple\rPara estimar el modelo de regresión multiple se debe realizar el mismo procedimiento de la regresión simple, solo que ahora deben señalar un (+) y el segundo predictor\nRegresión múltiple \rmodelo \u0026lt;- lm(y ~ x1 + x2 , data = data)\n\rPor fines de comparación, se estimaran primero dos regresiones simples con cada predictor, y luego la regresión múltiple en el Modelo 3:\ncol_actmodel\u0026lt;-lm(colGPA ~ACT, data=gpa1)\rcol_hsmodel\u0026lt;-lm(colGPA ~hsGPA, data=gpa1)\rcol_model \u0026lt;-lm(colGPA ~ACT +hsGPA, data = gpa1)\rsjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;),string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)\r\r\rModelo 1\r\rModelo 2\r\rModelo 3\r\r\r\rPredictores\r\rβ\r\rβ\r\rβ\r\r\r\r(Intercept)\r\r2.40 ***\r\r1.42 ***\r\r1.29 ***\r\r\r\rACT\r\r0.03 *\r\r\r0.01 \r\r\r\rhsGPA\r\r\r0.48 ***\r\r0.45 ***\r\r\r\rObservations\r\r141\r\r141\r\r141\r\r\r\rR2 / R2 adjusted\r\r0.043 / 0.036\r\r0.172 / 0.166\r\r0.176 / 0.164\r\r\r\r\rp\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001\r\r\r\r\r\\[\\widehat{colGPA} = 1.29 +0.01 \\dot\\ ACT + 0.453\\dot\\ hsGPA \\]\n\rInterpretación\r¿Cómo se interpreta este cuadro con los 3 modelos de regresión?\nEl modelo 1 estima que por cada punto que aumenta el examen de admisión \\(ACT\\), \\(colGPA\\) aumentaráen 0.03 puntos.\nEl modelo 2 estima que por cada punto que aumenta las notas en enseñanza media \\(hsGPA\\), \\(colGPA\\) aumentará en 0.48 puntos.\nEl modelo 3 estima \\(colGPA\\) considerando en conjunto ambas variables. Por un lado, por cada punto que aumenta el examen de admisión \\(ACT\\), \\(colGPA\\) aumentaráen 0.01 puntos, manteniendo \\(hsGPA\\) constante\rPor otro, por cada punto que aumenta las notas en enseñanza media \\(hsGPA\\), \\(colGPA\\) aumentará en 0.45 puntos, manteniendo \\(ACT\\) constante.\n¿Porqué se alteran los coeficientes de regresión?\rComo vimos en los gráficos de dispersión, existe una correlación entre nuestros predictores: el puntaje en \\(ACT\\) está asociado con las notas de enseñanza media \\(hsGPA\\).\nCuando se incorporan más variables en el modelo se descuenta este elemento en común que tienen las variables independientes. Por ello no solo los coefientes de regresión se ajustan en presencia de otras variables (\\(hsGPA\\) disminuyó de 0.48 a 0.45 y \\(ACT\\) de 0.03 a 0.01), sino que también el ajuste del modelo cambia (\\(R^2ajustado\\) es el estadístico más óptimo para identificar ello, pues como vimos en la práctica 5 \\(R^2\\) sobreestima la bondad de ajuste).\n\r\rParcialización\rLa forma de hacer este procedimiento de “mantener constante” el efecto de la otra variable se llama parcialización. Este procedimiento implica sacar la covarianza común entre mis variables independientes, es decir, lo que tienen en compun \\(hsGPA\\) y \\(ACT\\)\nSe habla de efectos parciales porque se estiman las regresiones solo con una de las variables independientes. Por ejemplo, ¿Cómo se predice \\(colGPA\\) en función \\(ACT\\), despejando el efecto de \\(hsGPA\\)?\nEn fórmula podemos ver que las estimaciones de $ b_{1}$ y $ b_{2}$ se interpretan como efectos parciales, de manera que dados los cambios en \\(ACT\\) y \\(hsGPA\\) se puede obtener un cambio predicho para \\(colGPA\\).\n\\[\\triangle{colGPA} = b_{1}\\triangle{ACT} + b_{2}\\triangle{hsGPA} \\]\nPero cuando \\(hsGPA\\) se mantiene constante, de manera que \\(\\triangle{hsGPA}\\) = 0, se obtiene entonces:\n\\[\\triangle{colGPA} = b_{1}\\triangle{ACT} \\]\nPero cuando \\(ACT\\) se mantiene constante, de manera que \\(\\triangle{ACT}\\) = 0, se obtiene entonces:\n\\[\\triangle{colGPA} = b_{2}\\triangle{hsGPA} \\]\nParcializar \\(ACT\\) de \\(hsGPA\\)\r¿Cómo determinar cuál es el (a) elemento común entre ambas variables y (b) extraer solamente aquello que no comparten?\nPara ello se realiza (a) una regresión simple donde los predictores son las variables del modelo (\\(ACT\\) dependiente y \\(hsGPA\\) independiente) y (b) en donde a la predicción de \\(ACT\\) hay asociado un residuo.\nEn otras palabras, el \\(b\\) de esta regresión es todo lo que comparte \\(ACT\\) y \\(hsGPA\\). Mientras que el residuo es todo lo de \\(ACT\\) que no es explicado po \\(hsGPA\\). En síntesis, es con lo que nos deberíamos quedar en nuestros modelos de regresión múltiple al estimar el \\(b_{1}\\) de \\(ACT\\).\nPaso 1: Estimar modelo\rmodel_act_hs =lm(ACT ~hsGPA, data = gpa1) #Crear regresion con predictores\rcoef(model_act_hs)\r## (Intercept) hsGPA ## 13.696763 3.074331\rEn consecuencia tenemos que\r\\[\\widehat{ACT} = 13.69 + 3.07{hsGPA} \\]\n\rPaso 2: calcular valores predichos y residuos\rSabemos que si tenemos un modelo de regresión podemos también obtener los residuos. Recordemos ¿qué es un residuo? Un residuo es la diferencia entre el valor observado y el valor predicho\nfit_act_hs=fitted.values(model_act_hs) # Calcular valores predichos\rres_act_hs=residuals(model_act_hs) #Calcular residuos\rgpa1=cbind(gpa1, fit_act_hs,res_act_hs) # Unir columna de residuos y valores predichos a base de datos\rhead(gpa1) #Mostrar los primeros elementos de la base de datos\r## colGPA hsGPA ACT fit_act_hs res_act_hs\r## 1 3.0 3.0 21 22.91975 -1.9197550\r## 2 3.4 3.2 24 23.53462 0.4653787\r## 3 3.0 3.6 26 24.76435 1.2356469\r## 4 3.5 3.5 27 24.45692 2.5430797\r## 5 3.6 3.9 28 25.68665 2.3133472\r## 6 3.0 3.4 25 24.14949 0.8505125\rPodemos ver en res_act_hs la varianza no explicada de \\(hsGPA\\) sobre \\(ACT\\).\n\rPaso 3: Crear regresión con variable parcializada\rAhora si hacemos la regresión con la variable res_act_hs notaremos que obtendremos el mismo \\(b_{1}\\) de la regresión del modelo múltiple (modelo 3) pero por medio de una regresión simple (modelo 4).\nact_hs_model \u0026lt;-lm(colGPA ~res_act_hs, data = gpa1) # Estimar regresión simple con parcialización de ACT\rsjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model, act_hs_model), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;, \u0026quot;Modelo 4\u0026quot;),string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)\r\r\rModelo 1\r\rModelo 2\r\rModelo 3\r\rModelo 4\r\r\r\rPredictores\r\rβ\r\rβ\r\rβ\r\rβ\r\r\r\r(Intercept)\r\r2.40 ***\r\r1.42 ***\r\r1.29 ***\r\r3.06 ***\r\r\r\rACT\r\r0.03 *\r\r\r0.01 \r\r\r\r\rhsGPA\r\r\r0.48 ***\r\r0.45 ***\r\r\r\r\rres_act_hs\r\r\r\r\r0.01 \r\r\r\rObservations\r\r141\r\r141\r\r141\r\r141\r\r\r\rR2 / R2 adjusted\r\r0.043 / 0.036\r\r0.172 / 0.166\r\r0.176 / 0.164\r\r0.005 / -0.003\r\r\r\r\rp\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001\r\r\r\r\rLo que tengo en ese modelo es la variable puntaje en el examen de admisión \\(ACT\\) sin las notas de enseñanza media \\(hsGPA\\). Lo mismo se podría realizar con la parcialización de \\(hsGPA\\).\nEste procedimiento de extraer el elemento común entre las variables es el que hace “tras bambalinas” la regresión múltiple. Lo importante es notar que en la regresión múltiple todos los predictores están parcializados del resto de los predictores. Se han “limpiado” de los efectos de las otras variables el resto de las variables del modelo.\n\r\r\rControl estadístico\r¿En cuál variable me fijo para la interpretación? Podemos graficar los coeficientes de la regresión de modo de ver el impacto que tienen cada una de las variables sobre \\(colGPA\\)\nplot_model(col_model, show.values = TRUE)+theme_sjplot()\rComo podemos ver el efecto que tiene \\(hsGPA\\) sobre \\(colGPA\\), controlando por \\(ACT\\), es mucho mayor que el que tiene \\(ACT\\) parcializado por \\(colGPA\\). Sin embargo, esto nada nos dice de qué variable enfatizar: esto dependen de las hipótesis que queremos probar con nuestros modelos.\n\r¿Qué significa mantener todos los demás factores constantes?\rEn la interpretación del modelo vimos que los coeficientes de regresión nos permiten entender el efecto de \\(ACT\\) sobre \\(colGPA\\), manteniendo \\(hsGPA\\) constante. También, \\(hsGPA\\) sobre \\(colGPA\\), manteniendo \\(ACT\\) constante.\nLa regresión múltiple nos proporciona esta interpretación “manteniendo constante las variables”, incluso cuando en nuestros mismos datos no hayan sido recoltados de manera constante. Esto es lo que hemos llamado una interpretación de efecto parcial de los coeficientes de regresión. Esto no implica que se haya encuestado personas con el mismo \\(hsGPA\\) pero con puntuaciones en \\(ACT\\). Para obtener los datos no se pusieron restricciones sobre los valores muestrales de \\(hsGPA\\) o de \\(ACT\\).\rMás bien, la regresión múltiple permite imitar esta situación “constante” sin restringir los valores de ninguna de las variables independientes.\n\r\rResumen Práctica 6:\rEn esta práctica revisamos los siguientes contenidos\r- Repaso de regresión lineal múltiple\r- Parcialización\r- Control estadístico\n\rReporte de progreso\rCompletar el reporte de progreso correspondiente a esta práctica [https://forms.gle/mMmR8qZxVJ1uYeUw8]\n\rForo práctica 6\r\r","date":1592524800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1598019297,"objectID":"c721292a113c2490ec6624b75af80b46","permalink":"/assignment/06-code/","publishdate":"2020-06-19T00:00:00Z","relpermalink":"/assignment/06-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 6. Regresión múltiple 2","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de la clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\rLecturas\rMoore: Residuos (144-154)\n\r","date":1591920000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1592524913,"objectID":"0ddf3e2b3a9f5347c88f83033fb01ff2","permalink":"/class/05-class/","publishdate":"2020-06-12T00:00:00Z","relpermalink":"/class/05-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de la clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\rLecturas\rMoore: Residuos (144-154)\n\r","tags":null,"title":"Regresión múltiple 1","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de la clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\rLecturas\rMoore: Residuos (144-154)\n\r","date":1590710400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1590861193,"objectID":"ac7533426a3114e90edf09c0635b197a","permalink":"/class/04-class/","publishdate":"2020-05-29T00:00:00Z","relpermalink":"/class/04-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de la clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\rLecturas\rMoore: Residuos (144-154)\n\r","tags":null,"title":"Regresión simple 2","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo de la práctica\rLibrerías\rDatos\rResiduos\rModelo y cálculo de parámetros\rBondad de Ajuste: Residuos y \\(R^{2}\\)\rSuma de cuadrados y \\(R^{2}\\)\rVisualización\rEl coeficiente de Regresión versus el coeficiente de correlación\rReporte de progreso\rForo\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo de la práctica\rBasados en el cálculo de parámetros del modelo de regresión en la práctica anterior (intercepto y coeficiente de regresión o pendiente), en esta práctica nos abocamos a temas de ajuste, residuos y relación entre correlación y regresión. La práctica está basada en el ejemplo de Darlington \u0026amp; Hayes cap. 2 (The simple regression model), que utilizamos en clases.\n\rLibrerías\rpacman::p_load(stargazer, ggplot2, dplyr,webshot)\r\rDatos\rLos datos a utilizar son los mismos que los de la práctica 3, corresponden a un ejemplo ficticio de 23 casos (individuos) y sus datos en dos variables relacionadas con un juego: el número de veces que se ha jugado antes (X) y el número de puntos ganados (Y).\ndatos \u0026lt;-read.csv(\u0026quot;https://multivariada.netlify.app/slides/03-regsimple1/tacataca.txt\u0026quot;, sep=\u0026quot;\u0026quot;)\rdatos\r## id juegos_x puntos_y\r## 1 1 0 2\r## 2 2 0 3\r## 3 3 1 2\r## 4 4 1 3\r## 5 5 1 4\r## 6 6 2 2\r## 7 7 2 3\r## 8 8 2 4\r## 9 9 2 5\r## 10 10 3 2\r## 11 11 3 3\r## 12 12 3 4\r## 13 13 3 5\r## 14 14 3 6\r## 15 15 4 3\r## 16 16 4 4\r## 17 17 4 5\r## 18 18 4 6\r## 19 19 5 4\r## 20 20 5 5\r## 21 21 5 6\r## 22 22 6 5\r## 23 23 6 6\rTambién desde esta misma dirección web se pueden bajar los datos y llamarlos localmente\nDirectorio de trabajo :Directorio de trabajo \nPara el trabajo de análisis de datos se recomienda establecer claramente el directorio de trabajo, es decir, la carpeta que contiene los archivos de datos, los códigos y los resultados. Esta carpeta es el lugar donde uno se posiciona para hacer los análisis, llamar otros archivos y exportar archivos.\nPara esto, varias opciones:\n\ren RStudio, Session \u0026gt; Set Working Directory \u0026gt; Choose Directory\ro también vía consola con el comando setwd(ruta-hacia-la-carpeta-local)\r\rSi se quiere verificar en qué carpeta se está trabajando, comando getwd()\nCon esto entonces, si los datos están guardados en la misma carpeta, entonces se llaman simplemente datos \u0026lt;- read.csv(\"tacataca.txt\", sep=\"\"). No se requiere dar la ruta completa justamente porque el programa ya sabe dónde uno está posicionado. Asimísmo, al momento de guardar/exportar algún resultado, automáticamente quedará en la carpeta de trabajo.\n\rRecordando la distribución de los datos y la recta de regresión:\ng2=ggplot(datos, aes(x=juegos_x, y=puntos_y)) +\rgeom_point() +\rgeom_smooth(method=lm, se=FALSE)\rg2\rGrabar / exportar gráficos :Exportar gráficos \rSi se quiere grabar un gráfico para luego utilizarlo en algún documento fuera del entorno R, algunas alternativas:\n\rutilizar la función ggsave (para gráficos ggplot)\r\rggsave(\u0026quot;g2.png\u0026quot;, g2)\r\rmás genéricamente, para guardar como imagen cualquier cosa que aparece en el visor de RStudio:\r\rpng(file = \u0026quot;g2.png\u0026quot;) # se abre un archivo vacío\rg2 # se genera el gráfico a guardar en el archivo\rdev.off() # se cierra el archivo\r\rEl gráfico quedará grabado en el directorio de trabajo (ver arriba). Si se desea que se grabe en otra parte, dar la ruta completa hacia la carpeta correspondiente (“C:/[ruta-hacia-carpeta]/g2.png”)\n\r\rResiduos\rEn el gráfico anterior vemos que la línea resume la relación entre X e Y que se denomina recta de regresión, caracterizada por un intercepto y una pendiente.\nClaramente, esta recta es una simplificación que no abarca toda la variabilidad de los datos. Por ejemplo, para el sujeto cuya experiencia es haber jugado 1 vez y luego gana 3 puntos, esta línea predice exactamente su puntaje basado en su experiencia. Sin embargo, el sujeto que ha jugado 3 veces y saca 6 puntos se encuentra más lejos de la línea y por lo tanto esta línea o “modelo predictivo” no representa tan bien su puntaje.\nLo anterior tiene que ver con el concepto de residuos, que es la diferencia entre el valor predicho (o \\(\\widehat{Y}\\)) y el observado \\(Y\\). Por lo tanto, la mejor recta será aquella que minimice al máximo los residuos.\nEl sentido de la recta que resume de mejor manera la relación entre dos variables es que minimice la suma de todos los residuos. Para realizar la suma de los residuos estos se elevan al cuadrado, lo que se denomina suma de residuos al cuadrado o \\(SS_{residual}\\) ya que como hay residuos positivos y negativos unos se cancelan a otros y la suma es 0. De la infinita cantidad de rectas que se pueden trazar, siempre hay una que tiene un valor menor de \\(SS_{residual}\\). Este procedimiento es el que da nombre al proceso de estimación: residuos cuadrados ordinarios, o OLS (Ordinary Least Squares).\n\rModelo y cálculo de parámetros\rComo vimos la práctica anterior, el modelo de regresión entonces se relaciona con una ecuación de la recta, o recta de regresión, que se puede definir en términos simples de la siguiente manera:\n\\[\\widehat{Y}=b_{0} +b_{1}X \\]\nreg1 \u0026lt;-lm(puntos_y ~juegos_x, data = datos)\rreg1\r## ## Call:\r## lm(formula = puntos_y ~ juegos_x, data = datos)\r## ## Coefficients:\r## (Intercept) juegos_x ## 2.5 0.5\rPodemos generar una tabla en un formato más publicable:\nstargazer(reg1, type=\u0026quot;text\u0026quot;)\r## ## ===============================================\r## Dependent variable: ## ---------------------------\r## puntos_y ## -----------------------------------------------\r## juegos_x 0.500*** ## (0.132) ## ## Constant 2.500*** ## (0.458) ## ## -----------------------------------------------\r## Observations 23 ## R2 0.405 ## Adjusted R2 0.376 ## Residual Std. Error 1.091 (df = 21) ## F Statistic 14.280*** (df = 1; 21) ## ===============================================\r## Note: *p\u0026lt;0.1; **p\u0026lt;0.05; ***p\u0026lt;0.01\rTambién es posible generar una tabla más resumida en formato publicable y visible en RStudio:\nsjPlot::tab_model(reg1, show.ci=FALSE)\r\r\rpuntos y\r\r\r\rPredictors\r\rEstimates\r\rp\r\r\r\r(Intercept)\r\r2.50\r\r\u0026lt;0.001\r\r\r\rjuegos_x\r\r0.50\r\r0.001\r\r\r\rObservations\r\r23\r\r\r\rR2 / R2 adjusted\r\r0.405 / 0.376\r\r\r\rGrabar / exportar tablas :Exportar tablas \nMuchas de las tablas producidas con R son en formato html, es decir, archivos para ser publicados en formato web. Por lo tanto, en general las tablas se graban primero como html, y luego se convierten a formato imagen con la librería webshot.\nPara tablas generadas con stargazer\nstargazer(reg1, type=\u0026quot;html\u0026quot;, out = \u0026quot;reg1.html\u0026quot;)\rwebshot(\u0026quot;reg1.html\u0026quot;,\u0026quot;reg1.png\u0026quot;)\rAlternativamente, para tablas de regresión con sjPlot:\nsjPlot::tab_model(reg1, show.ci=FALSE, file = \u0026quot;reg1_tab.html\u0026quot;)\rwebshot(\u0026quot;reg1_tab.html\u0026quot;,\u0026quot;reg1_tab.png\u0026quot;)\r\r\r\rBondad de Ajuste: Residuos y \\(R^{2}\\)\rA partir del método de Mínimos Cuadrados Ordinarios obtenemos una recta que describe un conjunto de datos minimizando las diferencias entre el modelo y la distribución de los datos mismos.\nNo obstante, incluso cuando se ajusta el mejor modelo siempre existirá un grado de imprecisión, representado por las diferencias entre los datos observados y los valores predichos por la recta de regresión.\nLa precisión de nuestro modelo se relaciona con el concepto de Bondad de Ajuste, y se evalúa a partir del estadístico \\(R^2\\).\nEn el siguiente apartado se puede observar la manera de calcular la predicción de Y (puntos_y) en base a X (juegos_x), y almacenarlos en la base de datos, con los respectivos residuos.\n#summary(lm(puntos_y~juegos_x, data=datos))\r#beta=0.5 intercepto=2.5\r\r#Variable de valores predichos\rdatos$estimado\u0026lt;-(2.5 +datos$juegos_x*0.5)\r\r# Alternativa por comando\r#datos$estimado \u0026lt;- predict(reg1)\r\r#Estimamos el residuo\rdatos$residuo \u0026lt;-datos$puntos_y -datos$estimado\r\r# Alternativa por comando\r#datos$residuo \u0026lt;- residuals(reg1)\r\rdatos %\u0026gt;%select(id, estimado, residuo)\r## id estimado residuo\r## 1 1 2.5 -0.5\r## 2 2 2.5 0.5\r## 3 3 3.0 -1.0\r## 4 4 3.0 0.0\r## 5 5 3.0 1.0\r## 6 6 3.5 -1.5\r## 7 7 3.5 -0.5\r## 8 8 3.5 0.5\r## 9 9 3.5 1.5\r## 10 10 4.0 -2.0\r## 11 11 4.0 -1.0\r## 12 12 4.0 0.0\r## 13 13 4.0 1.0\r## 14 14 4.0 2.0\r## 15 15 4.5 -1.5\r## 16 16 4.5 -0.5\r## 17 17 4.5 0.5\r## 18 18 4.5 1.5\r## 19 19 5.0 -1.0\r## 20 20 5.0 0.0\r## 21 21 5.0 1.0\r## 22 22 5.5 -0.5\r## 23 23 5.5 0.5\r\rSuma de cuadrados y \\(R^{2}\\)\rUsando la media como modelo podemos calcular las diferencias entre los valores observados y los valores predichos por la media.\n\rSuma Total de Cuadrados: La suma de las diferencias del promedio de Y al cuadrado (asociado al concepto de varianza de Y)\r\r\\[SS_{tot} = \\sum(y-\\bar{y})^2 \\]\rY calculamos\nss_tot\u0026lt;-sum((datos$puntos_y-mean(datos$puntos_y))^2); ss_tot\r## [1] 42\r\rSuma de cuadrados de la regresión: se refiere a la suma de diferencias (al cuadrado) entre el valor estimado por el modelo de regresión y la media. Expresa cuanto de la varianza de Y alcanzamos a predecir con X\r\r\\[SS_{reg} = \\sum(\\hat{y}-\\bar{y})^2\\]\nss_reg\u0026lt;-sum((datos$estimado-mean(datos$puntos_y))^2) ; ss_reg\r## [1] 17\r\rSuma de residuos al cuadrado: al contrario de el cálculo anterior, los residuos representan la parte de la varianza de Y que no alcanzamos a abarcar con nuestro modelo de regresión. Es decir, reprsentan el error en la predicción (diferencia entre lo estimado por el modelo y el valor observado)\r\r\\[SS_{error} = \\sum(y-\\hat{y})^2\\]\nss_err\u0026lt;-sum((datos$puntos_y -datos$estimado)^2);ss_err\r## [1] 25\rA partir de las sumas de cuadrados anteriores es posible calcular el estadístico \\(R^{2}\\)\n\\[R^2=\\frac{SS_{reg}}{SS_{tot}}= 1- \\frac{SS_{error}}{SS_{tot}}\\]\n#Opción 1\rss_reg/ss_tot\r## [1] 0.4047619\r#Opción 2\r1-ss_err/ss_tot\r## [1] 0.4047619\r#por comando\rsummary(lm(puntos_y~juegos_x, data=datos))$r.squared\r## [1] 0.4047619\r\rVisualización\rEn la siguiente sección se presentan distintas formas de visualizar los residuos a partir del paquete ggplot2.\n#Visualizacion\rlibrary(ggplot2)\r\rggplot(datos, aes(x=juegos_x, y=puntos_y))+\rgeom_smooth(method=\u0026quot;lm\u0026quot;, se=FALSE, color=\u0026quot;lightgrey\u0026quot;) +#Pendiente de regresion\rgeom_segment(aes(xend=juegos_x, yend=estimado), alpha = .2) +#Distancia entre estimados y datos en lineas\rgeom_point() +#Capa 1\rgeom_point(aes(y=estimado), shape =1) +\rtheme_bw()\rEn esta segunda opción, se agrega tamaño y color a los residuos mayores:\nggplot(datos, aes(x=juegos_x, y=puntos_y))+\rgeom_smooth(method=\u0026quot;lm\u0026quot;, se=FALSE, color=\u0026quot;lightgrey\u0026quot;) +#Pendiente de regresion\rgeom_segment(aes(xend=juegos_x, yend=estimado), alpha = .2) +#Distancia entre estimados y datos en lineas\rgeom_point(aes(color = abs(residuo), size = abs(residuo))) +\rscale_color_continuous(low = \u0026quot;black\u0026quot;, high = \u0026quot;red\u0026quot;) +\rguides(color = FALSE, size = FALSE) +\rgeom_point(aes(y=estimado), shape =1) +\rtheme_bw()\r\rEl coeficiente de Regresión versus el coeficiente de correlación\rTanto \\(r_{xy}\\) y \\(\\beta_1\\) son medidas de la relación entre X e Y. Ellas estan relacionadas con la formula de:\n\\[\\beta_1= r_{xy}(S_y/S_x)\\]\nEs decir:\nbeta\u0026lt;-cor(datos$juegos_x,datos$puntos_y)*(sd(datos$puntos_y)/sd(datos$juegos_x));beta\r## [1] 0.5\rreg1$coefficients[2] #llamamos al coeficiente beta (en posición 2) en el objeto reg1\r## juegos_x ## 0.5\rDel mismo modo existe una relación entre \\(r_{xy}\\) y \\(R^2\\)\n#Correlación (Pearson) entre juegos_x y puntos_y (r)\rcor(datos$juegos_x,datos$puntos_y)\r## [1] 0.636209\r#Correlación entre juegos_x y puntos_y al cuadrado.\r(cor(datos$juegos_x,datos$puntos_y))^2\r## [1] 0.4047619\rLa correlación entre X e Y es la misma que entre Y e X,\ncor(datos$juegos_x,datos$puntos_y)\r## [1] 0.636209\rcor(datos$puntos_y,datos$juegos_x)\r## [1] 0.636209\r… mientras la regresión entre X e Y no es la misma que entre Y e X\nlm(datos$puntos_y~datos$juegos_x)$coefficients\r## (Intercept) datos$juegos_x ## 2.5 0.5\rlm(datos$juegos_x~datos$puntos_y)$coefficients\r## (Intercept) datos$puntos_y ## -0.2380952 0.8095238\r\rReporte de progreso\rCompletar el reporte de progreso aquí.\n\rForo\r\r","date":1590710400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1590853802,"objectID":"0b905da0b361a42246b0f7d03e970a84","permalink":"/assignment/04-code/","publishdate":"2020-05-29T00:00:00Z","relpermalink":"/assignment/04-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 4. Regresión simple 2","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo de la práctica\rSobre hoja de código\rLibrerías\rDatos\rVerificación y descriptivos\rExperiencia en juegos y puntuación\rMedias condicionales\rResiduos\rModelo de regresión y cálculo de parámetros\rCálculo de los parámetros del modelo de regresión\r\rEstimación del modelo de regresión simple en R\rReporte de progreso\rArchivo de código\rForo práctica 3\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo de la práctica\rEn esta práctica se desarrollan ejercicios iniciales de regresión simple, que fueron presentados en la clase respectiva. El ejemplo a utilizar es del libro de Darlington \u0026amp; Hayes cap. 2 (The simple regression model).\n\rSobre hoja de código\rComo vimos en la práctica anterior, al momento de analizar los datos separamos el trabajo en dos hojas de código distintas: preparacion.R (práctica 1) y analisis.R (práctica 2). Recordar nombres de archivos y directorios sin tildes, espacios ni ñEn este caso, los datos son simples y como es un ejemplo no realizaremos código de preparación, solo el correspondiente a análisis. Antes de comenzar, sugerimos crear un archivo de código en R con el nombre analisis: R: File-\u0026gt; New File -\u0026gt; RScript, o simplemente Ctrl + Shift + N.\n\rLibrerías\rpacman::p_load(stargazer, ggplot2, dplyr)\r\rDatos\rLos datos a utilizar corresponden a un ejemplo ficticio de 23 casos (individuos) y sus datos en dos variables relacionadas con un juego (originalmente de mini-golf en el texto de referencia … pero pensemos en un ejemplo más cercano, de taca-taca). Las dos variables de esta base de datos son el número de veces que se ha jugado antes (juegos_x) y el número de goles o puntos ganados (puntos_y). El archivo de datos es tacataca.txt.\nVamos a cargar estos datos en nuestro espacio de trabajo en R dándole el nombre simple de datos Dos opciones de cargar los datos en R:\n\rbajarlos al computador local desde este link y luego llamarlos desde el directorio respectivo donde se guardaron:\r\rdatos \u0026lt;-read.csv(\u0026quot;( ...ruta hacia el archivo ...)\\tacataca.txt\u0026quot;, sep=\u0026quot;\u0026quot;)\r\rllamarlos directamente desde su ubicación en la web:\r\rdatos \u0026lt;-read.csv(\u0026quot;https://multivariada.netlify.app/slides/03-regsimple1/tacataca.txt\u0026quot;, sep=\u0026quot;\u0026quot;)\rComo es un archivo de texto simple (txt), los cargamos con la función read.csv, para datos guardados en texto simple separados por coma. Como en el caso de nuestros datos la separación es por espacios en lugar de comas, agregamos esta información con la instrucción sep=\"\"\rPara abrirlos datos recordemos que en la lógica de R se debe generar un objeto donde se guardan los datos. Este objeto puede tener cualquier nombre, en este caso lo llamaremos simplemente “datos”.\nRutas: ¿Cómo identifico la ruta hacia mi archivo? Dos maneras:\n\rBotón derecho sobre el archivo -\u0026gt; propiedades, ahí aparece la ruta completa. Copiar y pegar donde corresponde en el archivo de R, no olvidar agregar al final el nombre completo del archivo.\r\rMás fácil: mouse sobre archivo, boton derecho, copiar (o ctrl+c); luego, en el archivo de R, en el lugar que corresponde dar la ruta pegar (o ctrl+v)\r\r\r\rVerificación y descriptivos\rVerificamos si los datos fueron correctamente cargados:\nView(datos)\rTenemos entonces tres columnas:}\n\rid: número único que identifica a cada sujeto\n\rjuegos_x: número de veces que ha jugado previamente\n\rpuntos_y: numero de puntos que obtuvo en el juego actual\n\r\rGeneramos una tabla de descriptivos básicos con lo aprendido en la práctica de descripción de datos:\nY para publicar, usando la librería stargazer\nstargazer(datos, type = \u0026quot;text\u0026quot;)\r## ## ======================================================\r## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max\r## ------------------------------------------------------\r## id 23 12.000 6.782 1 6.5 17.5 23 ## juegos_x 23 3.000 1.758 0 2 4 6 ## puntos_y 23 4.000 1.382 2 3 5 6 ## ------------------------------------------------------\rEn la tabla vemos los estadísticos básicos de las variables juegos y puntos, y además aparece la variable id, que es el identificador y por lo tanto no tiene sentido que salga en la tabla. Para corregir, seleccionamos las variables de interés de datos con el operador pipa %\u0026gt;% operador pipa %\u0026gt;%. Este operador permite unir distintas funciones en una misma línea de código, y es muy utilizado por librerías de manejo de datos como dplyr. Por ejemplo, ahora la instrucción es “de la base de datos datos” %\u0026gt;% “selecciona solo las columnas juegos y puntos”:\nstargazer(datos %\u0026gt;%select(juegos_x,puntos_y) , type = \u0026quot;text\u0026quot;)\r## ## =====================================================\r## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max\r## -----------------------------------------------------\r## juegos_x 23 3.000 1.758 0 2 4 6 ## puntos_y 23 4.000 1.382 2 3 5 6 ## -----------------------------------------------------\r\rExperiencia en juegos y puntuación\rLa pregunta que nos hacemos para este ejercicio de demostración es: ¿tiene relación la experiencia previa (juegos jugados previamente) con el desempeño actual (puntos obtenidos)?\nVeamos un gráfico de nube de puntos / scatter de ambas variables. Para eso, primero cargamos la librería ggplotde R. Recordar que hay que instalarla primero si es que no se ha hecho previamente con install.packages(\"ggplot\")ggplot.\ng=ggplot(datos, aes(x=juegos_x, y=puntos_y)) +\rgeom_point()\rg\rPrimero, sobre librerías y visualización: lo que hicimos fue crear un objeto gráfico scatterplot g con la librería ggplot..\nEn términos de correlación se observa una posible asociación positiva, que podemos corroborar con la función cor:\ncor(datos$juegos_x,datos$puntos_y)\r## [1] 0.636209\rTenemos una correlación positiva (dirección de la relación) y de un tamaño de efecto grande (magnitud de la relación), para ciencias sociales. Es decir, existe una asociación positiva entre ambas variables: a medida que aumenta la experiencia en juegos, aumentan también los puntos obtenidos en el partido de taca taca. Ahora bien, ¿cómo se relaciona más específcamente la experiencia en juegos con los puntos obtenidos posteriormente?\n\rMedias condicionales\rAntes de avanzar desde la correlación al método de regresión es importante conocer el concepto de media condicional.\nComo sabemos el promedio de Y (puntos) es 4. Es decir, si conocemos a algún individuo que pertence al grupo de “datos”, sabemos que su puntaje se encuentra probablemente cercano a 4. ¿Podemos mejorar nuestra estimación utilizando el puntaje de X? Como lo conocemos, si el sujeto nos dice que ha jugado antes 6 veces, dada la información que conocemos probablemente vamos a estimar un puntaje superior de puntos, tal vez más cercano a 6.\nLo que estamos haciendo es utilizar la información que conocemos de X para dar una estimación de Y, que sea más precisa que el promedio bruto.\nMirando el gráfico de nube de puntos, sabemos que tres personas han jugado antes una vez, pero una de ellas tuvo 2 puntos, otra 3 y otra 4. Con estos datos podemos calcular la media de Y para X=1, que sería igual a 3. En otras palabras, la media condicional de Y cuando X=1 es 3. Con esto, uno podría calcular la media condicional para cada punto de X y hacer una estimación más precisa de Y. Sin embargo, este proceso todavía no nos permite generalizar más eficientemte la relación entre X e Y.\n¿Cuántos puntos (Y) se obtienen según la experiencia previa de juego (X)? Esta pregunta nos conduce al cálculo de una recta que atraviese los puntos y que generalice la relación entre X e Y:\ng2=ggplot(datos, aes(x=juegos_x, y=puntos_y)) +\rgeom_point() +\rgeom_smooth(method=lm, se=FALSE)\rg2\r\rResiduos\rEn el gráfico anterior vemos que la línea resume la relación entre X e Y, pero claramente es una simplificación que no abarca toda la variabilidad de los datos.\nPor ejemplo, para el sujeto cuya experiencia es haber jugado 1 vez y luego gana 3 puntos, esta línea predice exáctamente su puntaje basada en su experiencia. Sin embargo, el sujeto que ha jugado 3 veces y saca 6 puntos se encuentra más lejos de la línea y por lo tanto esta línea o “modelo predictivo” no representa tan bien su puntaje. A esto se refieren los residuos, que es la diferencia entre el valor predicho (o \\(\\widehat{Y}\\)) y el observado \\(Y\\), siendo los valores predichos de Y los que pasan por la recta a la altura de cada valor de X. Por lo tanto, la mejor recta será aquella que minimice al máximo los residuos.\nEl sentido de la recta que resume de mejor manera la relación entre dos variables es que minimice la suma de todos los residuos. ¿Cómo realizar este procedimiento?\n\rPara realizar la suma de los residuos estos se elevan al cuadrado, lo que se denomina Suma de residuos al cuadrado o \\(SS_{residual}\\). Se eleva al cuadrado ya que como hay residuos positivos y negativos, unos cancelarían a otros y la suma seía 0, tal como sucede en la formula de la varianza.\n\rDe la infinita cantidad de rectas que se pueden trazar, siempre hay una que tiene un valor menor de \\(SS_{residual}\\). Este procedimiento es el que da nombre al proceso de estimación: mínimos (residuos) cuadrados ordinarios, o OLS (Ordinary Least Squares).\n\r\r\rModelo de regresión y cálculo de parámetros\rEl nombre regresión hace alusión a investigaciones sobre estaturas de padres e hij_s en el S.XIX. La estatura de hij_s de padres muy altos es en promedio menor, y si sus padres son baj_s, es mayor (en comparación con sus padres). Este fenómeno se conoce como “regresión hacia el promedio” \nEl modelo de regresión se representa con una ecuación de la recta, o recta de regresión. Esta recta representa los valores predichos para Y según los distintos valores de X:\n\\[\\widehat{Y}=b_{0} +b_{1}X \\]\nDonde\n\r\\(\\widehat{Y}\\) es el valor estimado/predicho de \\(Y\\)\r\\(b_{0}\\) es el intercepto de la recta (el valor de Y cuando X es 0)\r\\(b_{1}\\) es el coeficiente de regresión, que nos dice cuánto aumenta Y por cada punto que aumenta X (pendiente)\r\r\rCálculo de los parámetros del modelo de regresión\r\\(b_{1}\\), o comunmente llamado “beta de regresión” se obtiene de la siguiente manera:\n\\[b_{1}=\\frac{Cov(XY)}{VarX}\\]\rEn términos más suntantivos se puede entender como qué parte de la covariación que hay entre X e Y se relaciona con (la varianza de) X. Especificando la fórmula:\n\\[b_{1}=\\frac{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {n-1}}{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})} {n-1}}\\]\rY simplificando\n\\[b_{1}=\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})}\\]\nComo sabemos, la base para todos estos cálculos es el valor de cada variable menos su promedio. Vamos a crear un vector en nuestra base de datos difx=\\(x-\\bar{x}\\) y dify=\\(y-\\bar{y}\\)\ndatos$difx=datos$juegos_x-mean(datos$juegos_x)\rdatos$dify=datos$puntos_y-mean(datos$puntos_y)\rY ahora con esto podemos obtener la diferencia de productos cruzados dif_cru=\\((x-\\bar{x})*(y-\\bar{y})\\), así como la diferencia de X de su promedio al cuadrado SSx=\\((x-\\bar{x})^2\\)\ndatos$difcru=datos$difx*datos$dify\rdatos$difx2=datos$difx^2\rdatos\r## id juegos_x puntos_y difx dify difcru difx2\r## 1 1 0 2 -3 -2 6 9\r## 2 2 0 3 -3 -1 3 9\r## 3 3 1 2 -2 -2 4 4\r## 4 4 1 3 -2 -1 2 4\r## 5 5 1 4 -2 0 0 4\r## 6 6 2 2 -1 -2 2 1\r## 7 7 2 3 -1 -1 1 1\r## 8 8 2 4 -1 0 0 1\r## 9 9 2 5 -1 1 -1 1\r## 10 10 3 2 0 -2 0 0\r## 11 11 3 3 0 -1 0 0\r## 12 12 3 4 0 0 0 0\r## 13 13 3 5 0 1 0 0\r## 14 14 3 6 0 2 0 0\r## 15 15 4 3 1 -1 -1 1\r## 16 16 4 4 1 0 0 1\r## 17 17 4 5 1 1 1 1\r## 18 18 4 6 1 2 2 1\r## 19 19 5 4 2 0 0 4\r## 20 20 5 5 2 1 2 4\r## 21 21 5 6 2 2 4 4\r## 22 22 6 5 3 1 3 9\r## 23 23 6 6 3 2 6 9\rY con esto podemos obtener la suma de productos cruzados y la suma de cuadrados de X\nsum(datos$difcru)\r## [1] 34\rsum(datos$difx2)\r## [1] 68\rReemplazando en la fórmula\n\\[b_{1}=\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})}=\\frac{34}{68}=0.5\\]\nY con esto podemos obtener el valor de \\(b_{0}\\)\n\\[b_{0}=\\bar{Y}-b_{1}\\bar{X}\\]\r\\[b_{0}=4-(3 * 0.5)=2.5\\]\nCompletando la ecuación:\n\\[\\bar{Y}=2.5+0.5X\\]\nEsto nos permite estimar el valor de \\(Y\\) (o su media condicional) basado en el puntaje \\(X\\).\rPor ejemplo, cuál es el valor estimado de \\(Y\\) dado \\(X=5\\)?\n\r\rEstimación del modelo de regresión simple en R\rLa función para estimar regresión en R es lm (linear model). Su forma general es:\nobjeto=lm(dependiente ~ independiente, data=datos)\rDonde\n\robjeto: el nombre (cualquiera) que le damos al objeto donde se guardan los resultados de la estimación\rdependiente / independiente: los nombres de las variables en los datos\rdata = el nombre del objeto de nuestros datos en R\r\rEjemplo con los datos de taca taca:\nreg1 \u0026lt;-lm(puntos_y ~juegos_x, data = datos)\rCon esta operación ya estimamos nuestra primera regresión simple. Para ver la estimación de los parámetros principales (intercepto y pendiente) simplemente ejecutamos el nombre del objeto:\nreg1\r## ## Call:\r## lm(formula = puntos_y ~ juegos_x, data = datos)\r## ## Coefficients:\r## (Intercept) juegos_x ## 2.5 0.5\rY obtenemos los valores que calculamos previamente.\nPodemos tener un output en un formato más apropiado utilizando la librería stargazer\nstargazer(reg1, type = \u0026quot;text\u0026quot;)\r## ## ===============================================\r## Dependent variable: ## ---------------------------\r## puntos_y ## -----------------------------------------------\r## juegos_x 0.500*** ## (0.132) ## ## Constant 2.500*** ## (0.458) ## ## -----------------------------------------------\r## Observations 23 ## R2 0.405 ## Adjusted R2 0.376 ## Residual Std. Error 1.091 (df = 21) ## F Statistic 14.280*** (df = 1; 21) ## ===============================================\r## Note: *p\u0026lt;0.1; **p\u0026lt;0.05; ***p\u0026lt;0.01\rVemos que en la tabla aparecen una serie de elementos adicionales, además de \\(b_{1}\\) (juegos) y el intercepto o constante (“Constant”). Esto será tema de la siguiente sesión.\n\rReporte de progreso\rCompletar el reporte de progreso correspondiente a esta práctica aquí\n\rArchivo de código\rEl archivo de código R de esta práctica se puede descargar aquí\n\rForo práctica 3\r\r","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1591276264,"objectID":"0c86205acf7811fbfe8648206a8418ff","permalink":"/assignment/03-code/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/assignment/03-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 3. Regresión simple 1","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de clase\rEste video es una edición de la clase efectuada vía Zoom el día viernes 3 de Abril \n\r\r\rLecturas\r\rLinares (2018) La explicación en sociología\r\r\r","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1586906392,"objectID":"ac47977a15b3902ca3402f61e5bf9df2","permalink":"/class/01-class/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/class/01-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de clase\rEste video es una edición de la clase efectuada vía Zoom el día viernes 3 de Abril \n\r\r\rLecturas\r\rLinares (2018) La explicación en sociología\r\r\r","tags":null,"title":"Presentación","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de clase\rPróximamente aquí \r---\r\r\r\rLecturas\r\rMoore: 1.Comprensión de los datos (1-54)\r\r\r","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1589647555,"objectID":"9ae245330f59c57e6f62568d635c26e4","permalink":"/class/02-class/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/class/02-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de clase\rPróximamente aquí \r---\r\r\r\rLecturas\r\rMoore: 1.Comprensión de los datos (1-54)\r\r\r","tags":null,"title":"Bases","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de clase\r\r\r\rLecturas\r\rMoore: 2. Análisis de relaciones (97-131)\r\r\r","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1590425049,"objectID":"a0c01f3889200201f6df018341b3db8f","permalink":"/class/03-class/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/class/03-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de clase\r\r\r\rLecturas\r\rMoore: 2. Análisis de relaciones (97-131)\r\r\r","tags":null,"title":"Regresión simple 1","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rPresentación\rObjetivo de la práctica\rAntecedentes de los datos a utilizar\rVideo - Tutoriales\r\rPreparación de datos ELSOC 2016\r1. Librerías principales (de R) a utilizar en el análisis\r2. Cargar base de datos\r3. Selección de variables a utilizar\r4. Procesamiento de variables\r4.1 Percepción de meritocracia\r4.3. Estatus subjetivo\r4.4. Sexo\r4.5 Edad\r\r5. Generación de base de datos procesada para el análisis\r\rArchivo de código\rForo\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rPresentación\rObjetivo de la práctica\rEl desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso.\nEn este curso vamos a distinguir dos momentos del trabajo con datos: procesamiento y análisis.\n\rPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos procesados.\n\rAnálisis: se relaciona principalmente con análisis descriptivos asociados a las preguntas de investigación y también modelamiento de datos para contrastar hipótesis de investigación.\n\r\rLos procesos de preparación y análisis vinculados a datos y resultados se presentan en el siguiente esquema:\rTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados en un documento de código, en este caso de código RArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: menú File \u0026gt; Save, y darle nombre (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\rLibrerías: cargar librerías a utilizar\rDatos: carga de datos\rSelección de variables a utilizar\rProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\rDescriptivo\rRecodificación: (datos perdidos y valores (en caso de ser necesario)\rEtiquetamiento: de variable y valores (en caso de ser necesario)\rOtros ajustes\r\rGeneración de base de datos procesada para el análisis.\r\rAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de meritocracia y estatus (objetivo y subjetivo) utilizando los datos de la encuesta ELSOC .\n\r\rAntecedentes de los datos a utilizar\rEl Estudio Longitudinal Social de Chile (ELSOC) es una encuesta desarrollada para analizar longitudinalmente la evolución del conflicto y cohesión en la sociedad chilena.\nUno de los módulos de ELSOC es “Desigualdad y Legitimidad”. Este módulo busca estudiar las percepciones y atribuciones asociadas a las desigualdades sociales. Se ve motivado por el interés de comprender cómo las personas perciben, legitiman y reproducen las diferencias de ingresos, estatus y poder presentes en el Chile contemporáneo.\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Percepción de Meritocracia, entendida como el grado en que los individuos consideran que su sociedad cumple con los principios de una meritocracia, es decir, que funciona como un sistema que asigna recompensas en función del esfuerzo y las habilidades. Para ello, junto con variables de meritocracia, consideraremos también variables de estatus (educación y estatus subjetivo), y variables de caracterización sociodemográfica (sexo y edad).\n\rVideo - Tutoriales\r\rSi se requiere instalar R, ir al siguiente tutorial en la página de descripción del uso de R en las prácticas haciendo click aquí.\n\rTambién se agrega un segundo tutorial con instrucciones paso a paso para poder comenzar a realizar esta Práctica 1 usando RStudio:\n\r\r\r\r\r\rPreparación de datos ELSOC 2016\r1. Librerías principales (de R) a utilizar en el análisis\rComo sabemos, la lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\ninstall.packages(\u0026quot;pacman\u0026quot;)\rY en adelante, las librerías se cargan así:\npacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer)\rPara esta sesión vamos a utilizar Las librerías que vamos a utilizar son:\n\rdplyr: ajuste general de datos\rsjmisc: descripción y exploración de base de datos\rcar: principalmente la función recode para recodificar/agrupar valores de variable\rstargazer: para tabla descriptiva\r\r\r2. Cargar base de datos\rAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\nrm(list=ls()) # borrar todos los objetos en el espacio de trabajo\roptions(scipen=999) # valores sin notación científica\rLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nLas bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo en línea que viene en formato RData: ELSOC_W01_v3.10.RData.\n#cargamos la base de datos desde internet\rload(url(\u0026quot;https://multivariada.netlify.com/assignment/data/original/ELSOC_W01_v3.10.RData\u0026quot;))\rLa base de datos aparece como un objeto en nuestro espacio de trabajo, con el nombre original con la que fue guardada (elsoc_2016):\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 2927 casos y 383 variables).\ndim(elsoc_2016) # dimension de la base\r## [1] 2927 383\rY si se quiere revisar en formato de planilla de datos:\nView(elsoc_2016)\r\r3. Selección de variables a utilizar\rEste paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello:\nSe identifica el nombre de las variables que registran la información de preguntas o items del instrumento: esto aparece en el libro de códigos y/o en el cuestionario, o también se puede hacer buscando en la base de datos mediante alguna palabra clave asociada a la pregunta. Por ejemplo, si queremos buscar variables asociadas a educación, utilizamos la función find_var (de sjmisc, librería que cargamos en el paso 1), que nos entrega nombre de la variable en columna var.name. Por ejemplo, si buscamos alguna variable asociada al concepto esfuerzo:\r\rfind_var(data = elsoc_2016,\u0026quot;esfuerzo\u0026quot;)\r## col.nr var.name\r## 1 158 c18_09\r## var.label\r## 1 Grado de acuerdo: Las personas son recompensadas por sus esfuerzos\rNos informa que esta variable es la c18_09.\nMediante la función select de dplyr, seleccionamos cada una de nuestras variables de interés y creamos una nueva base con el nombre proc_elsoc, donde “proc” hace referencia a base procesada:\nproc_elsoc \u0026lt;-elsoc_2016 %\u0026gt;%select(c18_09, # percepción meritocracia esfuerzo\rc18_10, # percepción meritocracia talento\rd01_01, # estatus social subjetivo\rm01, # nivel educacional\rm0_sexo,# sexo\rm0_edad)# edad\r\r# Comprobar\rnames(proc_elsoc)\r## [1] \u0026quot;c18_09\u0026quot; \u0026quot;c18_10\u0026quot; \u0026quot;d01_01\u0026quot; \u0026quot;m01\u0026quot; \u0026quot;m0_sexo\u0026quot; \u0026quot;m0_edad\u0026quot;\rMediante el comando get_label obtenemos el atributo label de las variables.\nsjlabelled::get_label(proc_elsoc)\r## c18_09 ## \u0026quot;Grado de acuerdo: Las personas son recompensadas por sus esfuerzos\u0026quot; ## c18_10 ## \u0026quot;Grado de acuerdo: Las personas son recompensada por su inteligencia\u0026quot; ## d01_01 ## \u0026quot;Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena\u0026quot; ## m01 ## \u0026quot;Nivel educacional\u0026quot; ## m0_sexo ## \u0026quot;Sexo del entrevistado\u0026quot; ## m0_edad ## \u0026quot;Edad del entrevistado\u0026quot;\rPodemos ver que son muy largas, por lo tanto, es necesario cambiarlas por etiquetas más cortas.\n\r4. Procesamiento de variables\rPara el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\nDescriptivo general\rRecodificación: de casos perdidos y otros valores (en caso necesario)\rEtiquetado: cambio de nombres de variables y valores (en caso necesario)\rOtros ajustes\r\rY se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n4.1 Percepción de meritocracia\rEn ELSOC, las variables que permiten medir la percepción de las personas con respecto al funcionamiento de la meritocracia en Chile son las siguientes:\n\r[c18_09]: “Grado de acuerdo: Las personas son recompensadas por sus esfuerzos” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo)\r[c18_10]: “Grado de acuerdo: Las personas son recompensadas por su inteligencia” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo)\r\ra. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\nfrq(proc_elsoc$c18_09)\r## ## Grado de acuerdo: Las personas son recompensadas por sus esfuerzos (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=-3.06 sd=71.66\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 4 0.14 0.14 0.14\r## -888 No Sabe (no leer) 14 0.48 0.48 0.61\r## 1 Totalmente en desacuerdo 357 12.20 12.20 12.81\r## 2 En desacuerdo 1331 45.47 45.47 58.28\r## 3 Ni de acuerdo ni en desacuerdo 497 16.98 16.98 75.26\r## 4 De acuerdo 646 22.07 22.07 97.34\r## 5 Totalmente de acuerdo 78 2.66 2.66 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\rfrq(proc_elsoc$c18_10)\r## ## Grado de acuerdo: Las personas son recompensada por su inteligencia (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=-3.42 sd=74.36\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 2 0.07 0.07 0.07\r## -888 No Sabe (no leer) 18 0.61 0.61 0.68\r## 1 Totalmente en desacuerdo 288 9.84 9.84 10.52\r## 2 En desacuerdo 1163 39.73 39.73 50.26\r## 3 Ni de acuerdo ni en desacuerdo 559 19.10 19.10 69.35\r## 4 De acuerdo 814 27.81 27.81 97.16\r## 5 Totalmente de acuerdo 83 2.84 2.84 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\rEn ambas variables vemos valores asociados a la opción “No responde” (-999) y “No sabe” (-888), que corresponde definirlos como casos perdidos (en el caso de R, como casos NA). El resto de los valores y etiquetas se encuentran en orden, así que en la recodificiación solo nos haremos cargo de los casos perdidos.\nb. Recodificación\nPara recodificar utilizamos la función recode, de la librería car\nproc_elsoc$c18_09 \u0026lt;-recode(proc_elsoc$c18_09, \u0026quot;c(-888,-999)=NA\u0026quot;)\rproc_elsoc$c18_10 \u0026lt;-recode(proc_elsoc$c18_10, \u0026quot;c(-888,-999)=NA\u0026quot;)\rc - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\nproc_elsoc \u0026lt;-proc_elsoc %\u0026gt;%rename(\u0026quot;mesfuerzo\u0026quot;=c18_09, # meritocracia esfuerzo\r\u0026quot;mtalento\u0026quot; =c18_10) # meritocracia talento\rAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$mesfuerzo)\r## [1] \u0026quot;Grado de acuerdo: Las personas son recompensadas por sus esfuerzos\u0026quot;\rproc_elsoc$mesfuerzo \u0026lt;-set_label(x = proc_elsoc$mesfuerzo,label = \u0026quot;Recompensa: esfuerzo\u0026quot;)\r\rget_label(proc_elsoc$mtalento)\r## [1] \u0026quot;Grado de acuerdo: Las personas son recompensada por su inteligencia\u0026quot;\rproc_elsoc$mtalento \u0026lt;-set_label(x = proc_elsoc$mtalento, label = \u0026quot;Recompensa: talento\u0026quot;)\rd. Otros ajustes\nPara este caso vamos a crear una variable que sea el promedio de los dos items de meritocracia.\nproc_elsoc$pmerit \u0026lt;-(proc_elsoc$mesfuerzo+proc_elsoc$mtalento)/2\rsummary(proc_elsoc$pmerit)\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 1.000 2.000 2.500 2.654 3.500 5.000 29\rget_label(proc_elsoc$pmerit)\r## [1] \u0026quot;Recompensa: esfuerzo\u0026quot;\rVemos que todavía tiene la etiqueta de la variable “Recompensa: esfuerzo”\nproc_elsoc$pmerit \u0026lt;-set_label(x = proc_elsoc$pmerit, label = \u0026quot;Meritocracia promedio\u0026quot;)\rRevisión final\nNuevamente un descriptivo de cada variable para confirmar que el procesamiento está ok:\nfrq(proc_elsoc$mesfuerzo)\r## ## Recompensa: esfuerzo (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2909 mean=2.57 sd=1.05\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 0 0.00 0.00 0.00\r## -888 No Sabe (no leer) 0 0.00 0.00 0.00\r## 1 Totalmente en desacuerdo 357 12.20 12.27 12.27\r## 2 En desacuerdo 1331 45.47 45.75 58.03\r## 3 Ni de acuerdo ni en desacuerdo 497 16.98 17.08 75.11\r## 4 De acuerdo 646 22.07 22.21 97.32\r## 5 Totalmente de acuerdo 78 2.66 2.68 100.00\r## NA \u0026lt;NA\u0026gt; 18 0.61 NA NA\rfrq(proc_elsoc$mtalento)\r## ## Recompensa: talento (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2907 mean=2.74 sd=1.06\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 0 0.00 0.00 0.00\r## -888 No Sabe (no leer) 0 0.00 0.00 0.00\r## 1 Totalmente en desacuerdo 288 9.84 9.91 9.91\r## 2 En desacuerdo 1163 39.73 40.01 49.91\r## 3 Ni de acuerdo ni en desacuerdo 559 19.10 19.23 69.14\r## 4 De acuerdo 814 27.81 28.00 97.14\r## 5 Totalmente de acuerdo 83 2.84 2.86 100.00\r## NA \u0026lt;NA\u0026gt; 20 0.68 NA NA\rfrq(proc_elsoc$pmerit)\r## ## Meritocracia promedio (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2898 mean=2.65 sd=0.97\r## ## val label frq raw.prc valid.prc cum.prc\r## -999.0 No Responde (no leer) 0 0.00 0.00 0.00\r## -888.0 No Sabe (no leer) 0 0.00 0.00 0.00\r## 1.0 Totalmente en desacuerdo 243 8.30 8.39 8.39\r## 1.5 1.5 79 2.70 2.73 11.11\r## 2.0 En desacuerdo 1041 35.57 35.92 47.03\r## 2.5 2.5 222 7.58 7.66 54.69\r## 3.0 Ni de acuerdo ni en desacuerdo 536 18.31 18.50 73.19\r## 3.5 3.5 169 5.77 5.83 79.02\r## 4.0 De acuerdo 528 18.04 18.22 97.24\r## 4.5 4.5 38 1.30 1.31 98.55\r## 5.0 Totalmente de acuerdo 42 1.43 1.45 100.00\r## NA \u0026lt;NA\u0026gt; 29 0.99 NA NA\r4.2. Educación\r\r[m01] = ¿Cuál es su nivel educacional? Indique el tipo de estudio actual (si estudia actualmente) o el último tipo aprobado (si no estudia actualmente).\r\ra. Descriptivo\nfrq(proc_elsoc$m01)\r## ## Nivel educacional (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=4.57 sd=26.34\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 2 0.07 0.07 0.07\r## -888 No Sabe (no leer) 0 0.00 0.00 0.07\r## 1 Sin estudios 37 1.26 1.26 1.33\r## 2 Educacion Basica o Preparatoria incompleta 322 11.00 11.00 12.33\r## 3 Educacion Basica o Preparatoria completa 297 10.15 10.15 22.48\r## 4 Educacion Media o Humanidades incompleta 394 13.46 13.46 35.94\r## 5 Educacion Media o Humanidades completa 857 29.28 29.28 65.22\r## 6 Tecnica Superior incompleta 102 3.48 3.48 68.71\r## 7 Tecnica Superior completa 381 13.02 13.02 81.72\r## 8 Universitaria incompleta 186 6.35 6.35 88.08\r## 9 Universitaria completa 303 10.35 10.35 98.43\r## 10 Estudios de posgrado (magister o doctorado) 46 1.57 1.57 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\rb. Recodificación\n\rDatos perdidos:\r\rproc_elsoc$m01 \u0026lt;-recode(proc_elsoc$m01, \u0026quot;c(-888,-999)=NA\u0026quot;)\r\rValores\r\rRecodificación de acuerdo a las categorías CINE 2011 (UNESCO)\n1. Sin estudios = [CINE 0 ] = 1\r2. Educacion Basica o Preparatoria incompleta = [CINE 0 ] = 1\r3. Educacion Basica o Preparatoria completa = [CINE 1,2 ] = 2\r4. Educacion Media o Humanidades incompleta = [CINE 3 ] = 3\r5. Educacion Media o Humanidades completa = [CINE 3 ] = 3\r6. Tecnico Superior incompleta = [CINE 5 ] = 4\r7. Tecnico Superior completa = [CINE 5 ] = 4\r8. Universitaria incompleta = [CINE 6 ] = 5\r9. Universitaria completa = [CINE 6 ] = 6\r10. Estudios de posgrado (magister o doctorado) = [CINE 7, 8] = 6\r# recodificacion usando funcion \u0026#39;recode\u0026#39; de la libreria car\rproc_elsoc$m01 \u0026lt;-car::recode(proc_elsoc$m01, \u0026quot;c(1,2)=1; c(3)=2;c(4,5)=3;c(6,7)=4;c(8,9,10)=5\u0026quot;)\rComprobar con un nuevo descriptivo:\nfrq(proc_elsoc$m01)\r## ## Nivel educacional (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2925 mean=3.18 sd=1.21\r## ## val label frq raw.prc valid.prc\r## -999 No Responde (no leer) 0 0.00 0.00\r## -888 No Sabe (no leer) 0 0.00 0.00\r## 1 Sin estudios 359 12.27 12.27\r## 2 Educacion Basica o Preparatoria incompleta 297 10.15 10.15\r## 3 Educacion Basica o Preparatoria completa 1251 42.74 42.77\r## 4 Educacion Media o Humanidades incompleta 483 16.50 16.51\r## 5 Educacion Media o Humanidades completa 535 18.28 18.29\r## 6 Tecnica Superior incompleta 0 0.00 0.00\r## 7 Tecnica Superior completa 0 0.00 0.00\r## 8 Universitaria incompleta 0 0.00 0.00\r## 9 Universitaria completa 0 0.00 0.00\r## 10 Estudios de posgrado (magister o doctorado) 0 0.00 0.00\r## NA \u0026lt;NA\u0026gt; 2 0.07 NA\r## cum.prc\r## 0.00\r## 0.00\r## 12.27\r## 22.43\r## 65.20\r## 81.71\r## 100.00\r## 100.00\r## 100.00\r## 100.00\r## 100.00\r## 100.00\r## NA\rSe observa que los valores coinciden con la recodificación (los casos se acumulan entre las categorías 1 y 5), pero las etiquetas ahora no coinciden; se soluciona en el siguiente paso.\nc. Etiquetado\nPara re-etiquetar valores usamos la función set_labels, de la librería sjlabelled\nproc_elsoc$m01 \u0026lt;-set_labels(proc_elsoc$m01,\rlabels=c( \u0026quot;Primaria incompleta menos\u0026quot;=1,\r\u0026quot;Primaria y secundaria baja\u0026quot;=2,\r\u0026quot;Secundaria alta\u0026quot;=3,\r\u0026quot;Terciaria ciclo corto\u0026quot;=4,\r\u0026quot;Terciaria y Postgrado\u0026quot;=5))\rLuego renombramos la variable con un nombre más sustantivo\nproc_elsoc \u0026lt;-rename(proc_elsoc,\u0026quot;edcine\u0026quot;=m01)\rAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$edcine)\r## [1] \u0026quot;Nivel educacional\u0026quot;\rproc_elsoc$edcine \u0026lt;-set_label(x = proc_elsoc$edcine,label = \u0026quot;Educación\u0026quot;)\r\r\r4.3. Estatus subjetivo\ra. Descriptivo\n\r[d01_01]: “Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena” (0 = el nivel mas bajo; 10 = el nivel mas alto)\r\rfrq(proc_elsoc$d01_01)\rsummary(proc_elsoc$d01_01)\r## ## Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=0.63 sd=57.67\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 1 0.03 0.03 0.03\r## -888 No Sabe (no leer) 11 0.38 0.38 0.41\r## 0 0 El nivel mas bajo 44 1.50 1.50 1.91\r## 1 1 84 2.87 2.87 4.78\r## 2 2 207 7.07 7.07 11.86\r## 3 3 439 15.00 15.00 26.85\r## 4 4 677 23.13 23.13 49.98\r## 5 5 975 33.31 33.31 83.29\r## 6 6 310 10.59 10.59 93.88\r## 7 7 116 3.96 3.96 97.85\r## 8 8 37 1.26 1.26 99.11\r## 9 9 4 0.14 0.14 99.25\r## 10 10 El nivel mas alto 22 0.75 0.75 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\r## ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -999.0000 3.0000 5.0000 0.6338 5.0000 10.0000\rb. Recodificación\nproc_elsoc$d01_01 \u0026lt;-recode(proc_elsoc$d01_01, \u0026quot;c(-888,-999)=NA\u0026quot;)\rc. Etiquetado\n\rCambio de nombre de variable a etiqueta más sustantiva ess (estatus social subjetivo)\r\rproc_elsoc \u0026lt;-proc_elsoc %\u0026gt;%rename(\u0026quot;ess\u0026quot;=d01_01) # estatus social subjetivo\rAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$ess)\r## [1] \u0026quot;Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena\u0026quot;\rproc_elsoc$ess \u0026lt;-set_label(x = proc_elsoc$ess,label = \u0026quot;Estatus Social Subjetivo\u0026quot;)\r\r4.4. Sexo\r\r[m0_sexo] = Indicar el sexo del entrevistado.\r\ra. Descriptivo\nfrq(proc_elsoc$m0_sexo)\r## ## Sexo del entrevistado (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=1.60 sd=0.49\r## ## val label frq raw.prc valid.prc cum.prc\r## 1 Hombre 1163 39.73 39.73 39.73\r## 2 Mujer 1764 60.27 60.27 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\rb. Recodificación\nEn general esta variable no tiene problemas de casos perdidos ni de etiquetas, pero de todas maneras vamos a hacer un cambio de acuerdo a convenciones en análisis de datos, donde por lo general hombres tienen valor 0 y mujeres 1:\nproc_elsoc$m0_sexo \u0026lt;-car::recode(proc_elsoc$m0_sexo, \u0026quot;1=0;2=1\u0026quot;)\rc. Etiquetado\nY ahora cambiamos las etiquetas de acuerdo a la recodificación anterior:\nproc_elsoc$m0_sexo \u0026lt;-set_labels(proc_elsoc$m0_sexo,\rlabels=c( \u0026quot;Hombre\u0026quot;=0,\r\u0026quot;Mujer\u0026quot;=1))\rTambién el nombre de la variable a algo más simple:\nproc_elsoc \u0026lt;-rename(proc_elsoc,\u0026quot;sexo\u0026quot;=m0_sexo)\rAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$sexo)\r## [1] \u0026quot;Sexo del entrevistado\u0026quot;\rproc_elsoc$sexo \u0026lt;-set_label(x = proc_elsoc$sexo,label = \u0026quot;Sexo\u0026quot;)\rRevisar con un nuevo descriptivo:\nfrq(proc_elsoc$sexo)\r## ## Sexo (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=0.60 sd=0.49\r## ## val label frq raw.prc valid.prc cum.prc\r## 0 Hombre 1163 39.73 39.73 39.73\r## 1 Mujer 1764 60.27 60.27 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\r\r4.5 Edad\r\r[m0_edad] = ¿Cuáles su edad? (años cumplidos).\r\ra. Descriptivo\nfrq(proc_elsoc$m0_edad)\r## ## Edad del entrevistado (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=46.09 sd=15.29\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 0 0.00 0.00 0.00\r## -888 No Sabe (no leer) 0 0.00 0.00 0.00\r## 18 18 19 0.65 0.65 0.65\r## 19 19 32 1.09 1.09 1.74\r## 20 20 26 0.89 0.89 2.63\r## 21 21 39 1.33 1.33 3.96\r## 22 22 49 1.67 1.67 5.64\r## 23 23 44 1.50 1.50 7.14\r## 24 24 51 1.74 1.74 8.88\r## 25 25 46 1.57 1.57 10.45\r## 26 26 44 1.50 1.50 11.96\r## 27 27 51 1.74 1.74 13.70\r## 28 28 58 1.98 1.98 15.68\r## 29 29 47 1.61 1.61 17.29\r## 30 30 66 2.25 2.25 19.54\r## 31 31 48 1.64 1.64 21.18\r## 32 32 64 2.19 2.19 23.37\r## 33 33 55 1.88 1.88 25.25\r## 34 34 55 1.88 1.88 27.13\r## 35 35 67 2.29 2.29 29.42\r## 36 36 70 2.39 2.39 31.81\r## 37 37 46 1.57 1.57 33.38\r## 38 38 57 1.95 1.95 35.33\r## 39 39 37 1.26 1.26 36.59\r## 40 40 57 1.95 1.95 38.54\r## 41 41 58 1.98 1.98 40.52\r## 42 42 67 2.29 2.29 42.81\r## 43 43 54 1.84 1.84 44.65\r## 44 44 45 1.54 1.54 46.19\r## 45 45 53 1.81 1.81 48.00\r## 46 46 77 2.63 2.63 50.63\r## 47 47 56 1.91 1.91 52.55\r## 48 48 72 2.46 2.46 55.01\r## 49 49 53 1.81 1.81 56.82\r## 50 50 69 2.36 2.36 59.17\r## 51 51 55 1.88 1.88 61.05\r## 52 52 69 2.36 2.36 63.41\r## 53 53 57 1.95 1.95 65.36\r## 54 54 76 2.60 2.60 67.95\r## 55 55 72 2.46 2.46 70.41\r## 56 56 76 2.60 2.60 73.01\r## 57 57 53 1.81 1.81 74.82\r## 58 58 57 1.95 1.95 76.77\r## 59 59 44 1.50 1.50 78.27\r## 60 60 57 1.95 1.95 80.22\r## 61 61 33 1.13 1.13 81.35\r## 62 62 33 1.13 1.13 82.47\r## 63 63 49 1.67 1.67 84.15\r## 64 64 39 1.33 1.33 85.48\r## 65 65 60 2.05 2.05 87.53\r## 66 66 39 1.33 1.33 88.86\r## 67 67 39 1.33 1.33 90.19\r## 68 68 35 1.20 1.20 91.39\r## 69 69 32 1.09 1.09 92.48\r## 70 70 37 1.26 1.26 93.75\r## 71 71 29 0.99 0.99 94.74\r## 72 72 28 0.96 0.96 95.70\r## 73 73 42 1.43 1.43 97.13\r## 74 74 39 1.33 1.33 98.46\r## 75 75 37 1.26 1.26 99.73\r## 77 77 1 0.03 0.03 99.76\r## 78 78 3 0.10 0.10 99.86\r## 80 80 1 0.03 0.03 99.90\r## 81 81 1 0.03 0.03 99.93\r## 88 88 2 0.07 0.07 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\rb. Recodificación: no es necesario en este caso\nc. Etiquetado\nCambio del nombre de la variable a algo más simple:\nproc_elsoc \u0026lt;-rename(proc_elsoc,\u0026quot;edad\u0026quot;=m0_edad)\rAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$edad)\r## [1] \u0026quot;Edad del entrevistado\u0026quot;\rproc_elsoc$edad \u0026lt;-set_label(x = proc_elsoc$edad,label = \u0026quot;Edad\u0026quot;)\r\r\r5. Generación de base de datos procesada para el análisis\rAntes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función stargazer (de la librería homónima)\nstargazer(proc_elsoc, type=\u0026quot;text\u0026quot;)\r## ## ==============================================================\r## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max ## --------------------------------------------------------------\r## mesfuerzo 2,909 2.573 1.047 1.000 2.000 3.000 5.000 ## mtalento 2,907 2.739 1.060 1.000 2.000 4.000 5.000 ## ess 2,915 4.330 1.567 0.000 3.000 5.000 10.000\r## edcine 2,925 3.184 1.207 1.000 3.000 4.000 5.000 ## sexo 2,927 0.603 0.489 0 0 1 1 ## edad 2,927 46.091 15.287 18 33 58 88 ## pmerit 2,898 2.654 0.969 1.000 2.000 3.500 5.000 ## --------------------------------------------------------------\r\rGuardar base de datos procesada: en carpeta local La ruta hacia su carpeta local si está trabajando en windows debería ser algo como \"C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar\r\rsave(proc_elsoc,file = \u0026quot;[ruta hacia carpeta local en su computador]/ELSOC_ess_merit2016.RData\u0026quot;)\rEn este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:\nsave(proc_elsoc,file = \u0026quot;content/assignment/data/proc/ELSOC_ess_merit2016.RData\u0026quot;)\r\r\rArchivo de código\rEl archivo de código R de esta práctica se puede descargar aquí\n\rForo\r\r","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1591276264,"objectID":"9f719bf107561ff88768da3264c94b73","permalink":"/assignment/01-code/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/assignment/01-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 1. Preparación de datos en R","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo de la práctica\rCódigo de análisis\r1. Librerías\r2. Cargar base de datos\r3. Descripción de variables\r3.1 Tabla descriptiva de variables para sección metodológica\r3.2 Exploración de asociación entre variables\r\rNota final: Información de la sesión de R\r\rResumen Práctica 2: Descripción de variables\rReporte de progreso\rArchivo de código\rForo práctica 2\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo de la práctica\rEsta segunda práctica tiene por objetivo repasar algunos conceptos básicos de los cursos anteriores de Estadística Descriptiva y Estadística Correlacional. Asume como base el desarrollo de la Práctica 1, a la cual se hará referencia permanente.\nEn la Práctica 1 se desarrolló un código de preparación de datos que generó una base de datos procesada para el análisis. En esta Práctica 2 comenzamos con el segundo momento de procesamiento de datos, que es el análisis propiamente tal. El análisis se divide en descripción de variables y contraste de hipótesis. En esta práctica nos enfocaremos en la primera fase, que llega hasta el punto 3 del código de análisis:\nAl igual que el Código de Preparación, el Código de Análisis posee una estructura definida. En este caso son 4 partes, donde las primeras son similares al código de preparación:\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\rLibrerías principales (de R) a utilizar en el análisis\rDatos (que provienen de los preparados en la fase anterior)\rDescripción de variables\r\rTabla general de variables para la sección metodológica del reporte\rExploración descriptiva de relaciones entre variables\r\rContraste de hipótesis / inferencia estadística según la técnica que corresponda\r\rAl final de esta práctica la idea es que cada un_ pueda avanzar hasta el punto 3 del Código de Análisis. El punto 4 (contraste de hipótesis) se desarrollará más adelante en este curso con énfasis en la técnica de regresión.\n\rCódigo de análisis\r1. Librerías\rLa explicación de esta parte del código se encuentra en la sección correspondiente de la práctica 1.pacman::p_load\npacman::p_load(dplyr, #Manipulacion de datos\rstargazer, #Tablas\rsjmisc, # Tablas\rsummarytools, # Tablas\rkableExtra, #Tablas\rsjPlot, #Tablas y gráficos\rcorrplot, # Correlaciones\rsessioninfo) # Información de la sesión de trabajo\r\r2. Cargar base de datos\rVamos a cargar la base de datos ELSOC_ess_merit2016.Rproc_elsoc, que generamos durante la práctica 1. Se puede llamar desde el directorio en que la guardaron dando la ruta completa, o también para esta práctica la podemos llamar directamente desde nuestro sitio web:\nload(url(\u0026quot;https://multivariada.netlify.app/assignment/data/proc/ELSOC_ess_merit2016.RData\u0026quot;)) #Cargar base de datos\r\rExploración inicial general de la base de datos\r\rnames(proc_elsoc) # Muestra los nombres de las variables de la base de datos\r## [1] \u0026quot;mesfuerzo\u0026quot; \u0026quot;mtalento\u0026quot; \u0026quot;ess\u0026quot; \u0026quot;edcine\u0026quot; \u0026quot;sexo\u0026quot; \u0026quot;edad\u0026quot; ## [7] \u0026quot;pmerit\u0026quot;\rdim(proc_elsoc) # Dimensiones\r## [1] 2927 7\rEn el caso de esta base, 2927 casos y 7 variables\nRecordando el contenido de cada variable preparada en la práctica 1:\n\r[merit] = Indice promedio de percepción de meritocracia.\n\r[ess] = Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena\" (0 = el nivel mas bajo; 10 = el nivel mas alto)\n\r[edcine] = Nivel educacional(1 = Primaria incompleta menos, 2 = Primaria y secundaria baja, 3 = Secundaria alta, 4 = Terciaria ciclo corto, 5 = Terciaria y Postgrado)\n\r[sexo] = Sexo (O = Hombre; 1 = Mujer)\n\r[edad] = ¿Cuáles su edad? (años cumplidos)\n\r\r\r3. Descripción de variables\rLos resultados referidos a descripción de variables se presentan en dos momentos del reporte de investigación:\n\ren la sección de metodología, cuando se presentan las variables del estudio en una tabla descriptiva de variables.\n\ren la sección de análisis, que en general comienza con una exploración de asociaciones entre variables, también conocido como análisis descriptivo.\n\r\r3.1 Tabla descriptiva de variables para sección metodológica\rA continuación se presentan dos opciones de generar esta tabla descriptiva de variables con distintas librerías de R.\na. Tabla descriptiva con stargazerstargazer\nLa función stargazer (de la librería del mismo nombre) permitirá mostrar los principales estadísticos descriptivos univariados de las variables: medidas de tendencia central (media), de dispersión (desviación estándar) y posición (mínimo, máximo, percentiles).\nstargazer(proc_elsoc,type = \u0026quot;text\u0026quot;)\r## ## ==============================================================\r## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max ## --------------------------------------------------------------\r## mesfuerzo 2,909 2.573 1.047 1.000 2.000 3.000 5.000 ## mtalento 2,907 2.739 1.060 1.000 2.000 4.000 5.000 ## ess 2,915 4.330 1.567 0.000 3.000 5.000 10.000\r## edcine 2,925 3.184 1.207 1.000 3.000 4.000 5.000 ## sexo 2,927 0.603 0.489 0 0 1 1 ## edad 2,927 46.091 15.287 18 33 58 88 ## pmerit 2,898 2.654 0.969 1.000 2.000 3.500 5.000 ## --------------------------------------------------------------\rAlgunas observaciones sobre esta tabla:\n\rLa opción type=\"text\" permite que podamos ver los resultados directamente en la consola, de manera bastante rudimentaria. Con otras opciones que veremos más adelante se puede estilizar para su publicación.\n\rUna distinción relevante a considerar cuando se describen variables es si estas son categóricas o continuas. La definición de si una variables es tratada como categórica o continua es algo que hace el/la autor/a del reporte, sin embargo hay variables nominales como sexo que claramente corresponden a categóricas, y por lo tanto no corresponde hacer un promedio entre ambas. Sin embargo, como esta variable está codificada 0 (hombre) y 1 (mujer), en este caso lo que indica el valor de la columna promedio (Mean=0.60) es la proporción de mujeres vs hombres. En otras palabras, hay un 60% de mujeres y 40% de hombres en la muestra.\n\r\rb. Tablas descriptivas con descr, librería sjmiscsjmisc::descr\nLa opción básica de descr es la siguiente:\nsjmisc::descr(proc_elsoc)\r## ## ## Basic descriptive statistics\r## ## var type label n NA.prc mean sd se md\r## mesfuerzo numeric Recompensa: esfuerzo 2909 0.61 2.57 1.05 0.02 2.0\r## mtalento numeric Recompensa: talento 2907 0.68 2.74 1.06 0.02 3.0\r## ess numeric Estatus Social Subjetivo 2915 0.41 4.33 1.57 0.03 5.0\r## edcine numeric Educación 2925 0.07 3.18 1.21 0.02 3.0\r## sexo numeric Sexo 2927 0.00 0.60 0.49 0.01 1.0\r## edad numeric Edad 2927 0.00 46.09 15.29 0.28 46.0\r## pmerit numeric Meritocracia promedio 2898 0.99 2.65 0.97 0.02 2.5\r## trimmed range skew\r## 2.56 4 (1-5) 0.42\r## 2.76 4 (1-5) 0.18\r## 4.36 10 (0-10) -0.01\r## 3.23 4 (1-5) -0.15\r## 0.63 1 (0-1) -0.42\r## 45.90 70 (18-88) 0.07\r## 2.66 4 (1-5) 0.26\rEn este caso utilizamos la forma librería::función (sjmisc::descr), ya que la función descr también existe en otras librerías y así nos aseguramos que la función utilizada es de esa librería específica.\nSeleccionamos algunas columnas específicas con información más relevante con la opción show. Además, agregamos la función kable para obtener una tabla que luego sea fácilmente publicable en distintos formatos (a profundizar en una práctica posterior):\nsjmisc::descr(proc_elsoc,\rshow = c(\u0026quot;label\u0026quot;,\u0026quot;range\u0026quot;, \u0026quot;mean\u0026quot;, \u0026quot;sd\u0026quot;, \u0026quot;NA.prc\u0026quot;, \u0026quot;n\u0026quot;))%\u0026gt;%\rkable(.,\u0026quot;markdown\u0026quot;)\r\r\r\rvar\rlabel\rn\rNA.prc\rmean\rsd\rrange\r\r\r\r4\rmesfuerzo\rRecompensa: esfuerzo\r2909\r0.6149641\r2.5727054\r1.0466874\r4 (1-5)\r\r5\rmtalento\rRecompensa: talento\r2907\r0.6832935\r2.7389061\r1.0596182\r4 (1-5)\r\r3\ress\rEstatus Social Subjetivo\r2915\r0.4099761\r4.3300172\r1.5666965\r10 (0-10)\r\r2\redcine\rEducación\r2925\r0.0683293\r3.1839316\r1.2066058\r4 (1-5)\r\r7\rsexo\rSexo\r2927\r0.0000000\r0.6026648\r0.4894300\r1 (0-1)\r\r1\redad\rEdad\r2927\r0.0000000\r46.0908780\r15.2867983\r70 (18-88)\r\r6\rpmerit\rMeritocracia promedio\r2898\r0.9907755\r2.6538992\r0.9694792\r4 (1-5)\r\r\r\rc. Tabla descriptiva con summarytools::dfSummarysummarytools::dfSummary\nEsta tercera opción nos ofrece una tabla aún más detallada, con gráficos para cada variable, las frecuencias para cada valor, y las etiquetas de las variables, por lo que es muy recomendable.\nSe específica de la siguiente manera:\ndfSummary(proc_elsoc, plain.ascii = FALSE)\r## ### Data Frame Summary ## #### proc_elsoc ## **Dimensions:** 2927 x 7 ## **Duplicates:** 396 ## ## ----------------------------------------------------------------------------------------------------------------------------------------\r## No Variable Label Stats / Values Freqs (% of Valid) Graph Valid Missing ## ---- ------------ -------------------------- -------------------------- ---------------------- -------------------- ---------- ---------\r## 1 mesfuerzo\\ Recompensa: esfuerzo Mean (sd) : 2.6 (1)\\ 1 : 357 (12.3%)\\ II \\ 2909\\ 18\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 2 : 1331 (45.8%)\\ IIIIIIIII \\ (99.39%) (0.61%) ## 1 \u0026lt; 2 \u0026lt; 5\\ 3 : 497 (17.1%)\\ III \\ ## IQR (CV) : 1 (0.4) 4 : 646 (22.2%)\\ IIII \\ ## 5 : 78 ( 2.7%) ## ## 2 mtalento\\ Recompensa: talento Mean (sd) : 2.7 (1.1)\\ 1 : 288 ( 9.9%)\\ I \\ 2907\\ 20\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 2 : 1163 (40.0%)\\ IIIIIIII \\ (99.32%) (0.68%) ## 1 \u0026lt; 3 \u0026lt; 5\\ 3 : 559 (19.2%)\\ III \\ ## IQR (CV) : 2 (0.4) 4 : 814 (28.0%)\\ IIIII \\ ## 5 : 83 ( 2.9%) ## ## 3 ess\\ Estatus Social Subjetivo Mean (sd) : 4.3 (1.6)\\ 11 distinct values \\ 2915\\ 12\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ \\ \\ \\ \\ \\ \\ \\ \\ :\\ (99.59%) (0.41%) ## 0 \u0026lt; 5 \u0026lt; 10\\ \\ \\ \\ \\ \\ \\ . :\\ ## IQR (CV) : 2 (0.4) \\ \\ \\ \\ . : :\\ ## \\ \\ \\ \\ : : : .\\ ## . : : : : : . ## ## 4 edcine\\ Educación Mean (sd) : 3.2 (1.2)\\ 1 : 359 (12.3%)\\ II \\ 2925\\ 2\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 2 : 297 (10.2%)\\ II \\ (99.93%) (0.07%) ## 1 \u0026lt; 3 \u0026lt; 5\\ 3 : 1251 (42.8%)\\ IIIIIIII \\ ## IQR (CV) : 1 (0.4) 4 : 483 (16.5%)\\ III \\ ## 5 : 535 (18.3%) III ## ## 5 sexo\\ Sexo Min : 0\\ 0 : 1163 (39.7%)\\ IIIIIII \\ 2927\\ 0\\ ## [numeric] Mean : 0.6\\ 1 : 1764 (60.3%) IIIIIIIIIIII (100%) (0%) ## Max : 1 ## ## 6 edad\\ Edad Mean (sd) : 46.1 (15.3)\\ 63 distinct values \\ 2927\\ 0\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ \\ \\ . . . : :\\ (100%) (0%) ## 18 \u0026lt; 46 \u0026lt; 88\\ . : : : : : .\\ ## IQR (CV) : 25 (0.3) : : : : : : : :\\ ## : : : : : : : :\\ ## : : : : : : : : . ## ## 7 pmerit\\ Meritocracia promedio Mean (sd) : 2.7 (1)\\ 1.00 : 243 ( 8.4%)\\ I \\ 2898\\ 29\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 1.50 : 79 ( 2.7%)\\ \\ (99.01%) (0.99%) ## 1 \u0026lt; 2.5 \u0026lt; 5\\ 2.00 : 1041 (35.9%)\\ IIIIIII \\ ## IQR (CV) : 1.5 (0.4) 2.50 : 222 ( 7.7%)\\ I \\ ## 3.00 : 536 (18.5%)\\ III \\ ## 3.50 : 169 ( 5.8%)\\ I \\ ## 4.00 : 528 (18.2%)\\ III \\ ## 4.50 : 38 ( 1.3%)\\ \\ ## 5.00 : 42 ( 1.5%) ## ----------------------------------------------------------------------------------------------------------------------------------------\rEs muy ancha para visualizar bien en la consola de R, pero en su versión más definitiva de publicación se verá así:\nview(dfSummary(proc_elsoc, headings=FALSE))\r\r\rNo\rVariable\rLabel\rStats / Values\rFreqs (% of Valid)\rGraph\rValid\rMissing\r\r\r\r\r1\rmesfuerzo\r[numeric]\rRecompensa: esfuerzo\rMean (sd) : 2.6 (1)\rmin 1:357(12.3%)2:1331(45.8%)3:497(17.1%)4:646(22.2%)5:78(2.7%)\r\r2909\r(99.39%)\r18\r(0.61%)\r\r\r2\rmtalento\r[numeric]\rRecompensa: talento\rMean (sd) : 2.7 (1.1)\rmin 1:288(9.9%)2:1163(40.0%)3:559(19.2%)4:814(28.0%)5:83(2.9%)\r\r2907\r(99.32%)\r20\r(0.68%)\r\r\r3\ress\r[numeric]\rEstatus Social Subjetivo\rMean (sd) : 4.3 (1.6)\rmin 11 distinct values\r\r2915\r(99.59%)\r12\r(0.41%)\r\r\r4\redcine\r[numeric]\rEducaci\u0026#0243;n\rMean (sd) : 3.2 (1.2)\rmin 1:359(12.3%)2:297(10.2%)3:1251(42.8%)4:483(16.5%)5:535(18.3%)\r\r2925\r(99.93%)\r2\r(0.07%)\r\r\r5\rsexo\r[numeric]\rSexo\rMin : 0\rMean : 0.6\rMax : 1\r0:1163(39.7%)1:1764(60.3%)\r\r2927\r(100%)\r0\r(0%)\r\r\r6\redad\r[numeric]\rEdad\rMean (sd) : 46.1 (15.3)\rmin 63 distinct values\r\r2927\r(100%)\r0\r(0%)\r\r\r7\rpmerit\r[numeric]\rMeritocracia promedio\rMean (sd) : 2.7 (1)\rmin 1.00:243(8.4%)1.50:79(2.7%)2.00:1041(35.9%)2.50:222(7.7%)3.00:536(18.5%)3.50:169(5.8%)4.00:528(18.2%)4.50:38(1.3%)5.00:42(1.5%)\r\r2898\r(99.01%)\r29\r(0.99%)\r\r\r\rGenerated by summarytools 0.9.6 (R version 3.6.0)2020-04-23\n\rNota sobre casos perdidos (NAs) na.omit(data)\rHasta ahora hemos mantenido los casos perdidos en la base de datos, ya que son importantes de reportar en la tabla general de variables. Sin embargo, de aquí en adelante se recomienda trabajar solo con casos completos, es decir, sacar los casos perdidos. El quitar los casos perdidos de una base de datos es muy simple con la función na.omit, pero para tomar precauciones y asegurarse que funciona se recomienda el siguiente procedimiento:\n\rrespaldar la base de datos original en el espacio de trabajo (por si queremos en adelante realizar algún análisis referido a casos perdidos), la dejaremos con el nombre proc_elsoc_original.\rcontamos el número de casos con el comando dim\rcontamos el número de casos perdidos con sum(is.na(proc_elsoc))\rborramos los casos perdidos con proc_elsoc \u0026lt;-na.omit(proc_elsoc)\rcontamos nuevamente con dim para asegurarnos que se borraron\ry por temas de funcionamiento de R, al realizar la operación de sacar casos perdidos, se borra toda la información de las etiquetas (labels), así que las recuperamos de la base original con el comando copy_labels, de la librería sjlabelled.\r\rproc_elsoc_original \u0026lt;-proc_elsoc\rdim(proc_elsoc)\r## [1] 2927 7\rsum(is.na(proc_elsoc))\r## [1] 81\rproc_elsoc \u0026lt;-na.omit(proc_elsoc)\rdim(proc_elsoc)\r## [1] 2887 7\rproc_elsoc \u0026lt;-sjlabelled::copy_labels(proc_elsoc,proc_elsoc_original)\r\r\r3.2 Exploración de asociación entre variables\rDado que las hipótesis de investigación corresponden a asociación entre variables, antes de realizar el contraste de hipótesis se suele presentar un análisis descriptivio que explora las asociaciones entre variables.\nLa forma de explorar las asociaciones entre variables dependen de la naturaleza de las variables que se asocian:\n\rVariables categóricas: tabla de contingencia\rVariable categórica y continua: tabla de promedios por cada categoría\rVariables continuas: correlaciones.\r\rEn esta sección también es muy relevante la visualización de datos mediante gráficos, por lo que incluiremos algunos.\nEl uso tanto de tablas como de gráficos en el reporte queda a discreción del/a autor/a. La pregunta que orienta esta decisión es: ¿Me permite enriquecer la discusión de los resultados en relación a las hipótesis planteadas?\nTablas de contingencia para variables categóricas\rPara tablas de contingencia categóricas utilizaremos la función sjt.xtab, de la librería sjPlot. Veamos primero una especificación simple: sjPlot::sjt.xtab\nsjt.xtab(proc_elsoc$edcine, proc_elsoc$sexo)\r\rEducación\r\rSexo\r\rTotal\r\r\r\rHombre\r\rMujer\r\r\r\rPrimaria incompleta\nmenos\r\r102\r\r247\r\r349\r\r\r\rPrimaria y\nsecundaria baja\r\r105\r\r186\r\r291\r\r\r\rSecundaria alta\r\r511\r\r727\r\r1238\r\r\r\rTerciaria ciclo\ncorto\r\r186\r\r292\r\r478\r\r\r\rTerciaria y\nPostgrado\r\r245\r\r286\r\r531\r\r\r\rTotal\r\r1149\r\r1738\r\r2887\r\r\rχ2=28.154 · df=4 · Cramer’s V=0.099 · p=0.000\r\r\r\rAl ejecutar el comando, el resultado aparece automáticamente en el visor de RStudio. A esta tabla podemos también agregar porcentajes de filas y/o columnas, según sea lo más relevante analizar. En general se recomienda agregar solo un porcentaje, de otra manera la tabla se satura de información. Además, vamos a quitar el pie de la tabla (conviene dejarlo solo si hay hipótesis asociadas al cruce simple entre las dos variables).\nsjt.xtab(proc_elsoc$edcine, proc_elsoc$sexo,\rshow.col.prc=TRUE,\rshow.summary=FALSE\r)\r\rEducación\r\rSexo\r\rTotal\r\r\r\rHombre\r\rMujer\r\r\r\rPrimaria incompleta\nmenos\r\r102\n8.9 %\r\r247\n14.2 %\r\r349\n12.1 %\r\r\r\rPrimaria y\nsecundaria baja\r\r105\n9.1 %\r\r186\n10.7 %\r\r291\n10.1 %\r\r\r\rSecundaria alta\r\r511\n44.5 %\r\r727\n41.8 %\r\r1238\n42.9 %\r\r\r\rTerciaria ciclo\ncorto\r\r186\n16.2 %\r\r292\n16.8 %\r\r478\n16.6 %\r\r\r\rTerciaria y\nPostgrado\r\r245\n21.3 %\r\r286\n16.5 %\r\r531\n18.4 %\r\r\r\rTotal\r\r1149\n100 %\r\r1738\n100 %\r\r2887\n100 %\r\r\r\r\rTablas de promedio de variable continua por una categóricas\rEn ejemplo vamos a explorar datos de nuestra variable de percepción de meritocracia pmerit por los niveles educacionales edcine.\nUna forma rápida de explorar esto es mediante la función tapply, que nos entrega de manera simple el promedio de una variable por otra:\ntapply(proc_elsoc$pmerit, proc_elsoc$edcine, mean)\r## 1 2 3 4 5 ## 2.968481 2.697595 2.662763 2.479079 2.559322\rAquí vemos en promedio de pmerit para cada uno de los 5 niveles de la variable educación edcine. Si se estima conveniente este tipo de cruces se puede representar también en una tabla con más opciones de información y también de publicación. Para esto utilizaremos una función algo más compleja de la librería dplyr.dplyr Esta librería permite aplicar una serie de funciones concatenadas y enlazadas mediante el operador %\u0026gt;%. El sentido de cada función aparece comentado abajo:\nproc_elsoc %\u0026gt;%# se especifica la base de datos\rselect(pmerit,edcine) %\u0026gt;%# se seleccionan las variables\rdplyr::group_by(Educación=sjlabelled::as_label(edcine)) %\u0026gt;%# se agrupan por la variable categórica y se usan sus etiquetas con as_label\rdplyr::summarise(Obs.=n(),Promedio=mean(pmerit),SD=sd(pmerit)) %\u0026gt;%# se agregan las operaciones a presentar en la tabla\rkable(, format = \u0026quot;markdown\u0026quot;) # se genera la tabla\r\r\rEducación\rObs.\rPromedio\rSD\r\r\r\rPrimaria incompleta menos\r349\r2.968481\r0.9828315\r\rPrimaria y secundaria baja\r291\r2.697595\r1.0041093\r\rSecundaria alta\r1238\r2.662762\r0.9685655\r\rTerciaria ciclo corto\r478\r2.479080\r0.9431323\r\rTerciaria y Postgrado\r531\r2.559322\r0.9223446\r\r\r\rEsta asocación también se puede representar de manera más simple con un gráfico, en este caso de cajas o boxplot mediante la función plot_grpfrq de sjPlot:sjPlot::plot_grpfrq\nplot_grpfrq(proc_elsoc$pmerit,proc_elsoc$edcine,\rtype = \u0026quot;box\u0026quot;)\r\rCorrelaciones (variables continuas)\rAlgunas notas sobre correlación:\n\rEl coeficiente de correlación mide la fuerza de la relación lineal entre dos variable continuas. Esta puede ser:\n\rpositiva: a medida que aumenta una, aumenta la otra (ej: estatura y edad)\rnegativa: a medida que una aumenta, disminuye la otra (ej: tiempo dedicado al estudio y probabilidad de reprobar)\rneutra: no hay asociación entre variables.\r\rEl rango de variación del coeficiente de correlación va desde -1 (correlación negativa perfecta) y 1 (correlación positiva perfecta).\n\rExisten diferentes formas de cálculo del coeficiente de correlación (Spearman, Kendall, Pearson).\n\rEn el coeficiente de correlación se analiza tanto su tamaño como su significación estadística.\n\r\rEn lo que sigue nos concentraremos en el coeficiente de correlación más utilizado que es el de Pearson, que se aplica cuando las variables son de naturaleza continua.\nTablas/matrices de correlación\nLas correlaciones entre variables se presentan en general en modo de matrices, es decir, las variables se presentan en las filas y las columnas y en las celdas donde se cruzan los pares de variables se muestra su coeficiente de correlación.\nEn su forma simple en R se aplica la función cor a lacor base de datos, y la guardamos en un objeto que le damos el nombre M para futuras operaciones:\nM \u0026lt;-cor(proc_elsoc)\rM\r## mesfuerzo mtalento ess edcine sexo\r## mesfuerzo 1.000000000 0.69768811 -0.004312135 -0.12167659 -0.04480502\r## mtalento 0.697688106 1.00000000 0.018447696 -0.10582754 -0.03759340\r## ess -0.004312135 0.01844770 1.000000000 0.28959248 -0.03745546\r## edcine -0.121676591 -0.10582754 0.289592479 1.00000000 -0.08682644\r## sexo -0.044805024 -0.03759340 -0.037455462 -0.08682644 1.00000000\r## edad 0.096495547 0.07383771 -0.066031873 -0.37660283 0.06121699\r## pmerit 0.920404032 0.92224547 0.007740598 -0.12341680 -0.04469515\r## edad pmerit\r## mesfuerzo 0.09649555 0.920404032\r## mtalento 0.07383771 0.922245465\r## ess -0.06603187 0.007740598\r## edcine -0.37660283 -0.123416804\r## sexo 0.06121699 -0.044695146\r## edad 1.00000000 0.092369792\r## pmerit 0.09236979 1.000000000\rEste es el reporte simple, pero no muy amigable a la vista. Para una versión más amable utilizamos la función sjt.corrsjPlot::sjt.corr:NOTA: sjPlot actualizó su librería a fines de Mayo (versión 2.8.4); para quienes hayan actualizado a esta versión, la función para tabla de correlaciones ahora es tab_corr\nsjt.corr(proc_elsoc)\r\r\rRecompensa: esfuerzo\r\rRecompensa: talento\r\rEstatus Social Subjetivo\r\rEducación\r\rSexo\r\rEdad\r\rMeritocracia promedio\r\r\r\rRecompensa: esfuerzo\r\r\r0.698***\r\r-0.004\r\r-0.122***\r\r-0.045*\r\r0.096***\r\r0.920***\r\r\r\rRecompensa: talento\r\r0.698***\r\r\r0.018\r\r-0.106***\r\r-0.038*\r\r0.074***\r\r0.922***\r\r\r\rEstatus Social Subjetivo\r\r-0.004\r\r0.018\r\r\r0.290***\r\r-0.037*\r\r-0.066***\r\r0.008\r\r\r\rEducación\r\r-0.122***\r\r-0.106***\r\r0.290***\r\r\r-0.087***\r\r-0.377***\r\r-0.123***\r\r\r\rSexo\r\r-0.045*\r\r-0.038*\r\r-0.037*\r\r-0.087***\r\r\r0.061**\r\r-0.045*\r\r\r\rEdad\r\r0.096***\r\r0.074***\r\r-0.066***\r\r-0.377***\r\r0.061**\r\r\r0.092***\r\r\r\rMeritocracia promedio\r\r0.920***\r\r0.922***\r\r0.008\r\r-0.123***\r\r-0.045*\r\r0.092***\r\r\r\r\rComputed correlation used pearson-method with listwise-deletion.\r\r\r\rCon esta mejor visualización, algunas observaciones sobre la matriz de correlaciones:\n\rEn esta matriz las variables están representadas en las filas y en las columnas.\rCada coeficiente expresa la correlación de una variable con otra. Por ejemplo, la correlación entre la variable de recompensa por esfuerzo y recompensa por inteligencia es 0.698.\rLa información de cada coeficiente se repite sobre y bajo la diagonal, ya que es el mismo par de variables pero en el orden alterno.\rEn la diagonal corresponde que todos los coeficientes sean 1, ya que la correlación de una variable consigo misma es perfectamente positiva. En esta tabla se omiten y aparece la diagonal vacía, ya que es información redundante. Por lo mismo, también se recomienda eliminar el triangulo superior de la tabla (redundante) de la siguiente manera:\r\rsjt.corr(proc_elsoc,\rtriangle = \u0026quot;lower\u0026quot;)\r\r\rRecompensa: esfuerzo\r\rRecompensa: talento\r\rEstatus Social Subjetivo\r\rEducación\r\rSexo\r\rEdad\r\rMeritocracia promedio\r\r\r\rRecompensa: esfuerzo\r\r\r\r\r\r\r\r\r\r\rRecompensa: talento\r\r0.698***\r\r\r\r\r\r\r\r\r\rEstatus Social Subjetivo\r\r-0.004\r\r0.018\r\r\r\r\r\r\r\r\rEducación\r\r-0.122***\r\r-0.106***\r\r0.290***\r\r\r\r\r\r\r\rSexo\r\r-0.045*\r\r-0.038*\r\r-0.037*\r\r-0.087***\r\r\r\r\r\r\rEdad\r\r0.096***\r\r0.074***\r\r-0.066***\r\r-0.377***\r\r0.061**\r\r\r\r\r\rMeritocracia promedio\r\r0.920***\r\r0.922***\r\r0.008\r\r-0.123***\r\r-0.045*\r\r0.092***\r\r\r\r\rComputed correlation used pearson-method with listwise-deletion.\r\r\r\rUna segunda forma de presentar matrices de correlaciones es de manera gráfica con la librería corrplot, cuya función corrplot.mixed corrplot::corrplot.mixedse aplica al objeto que generamos con la función cor (M):\ncorrplot.mixed(M)\rEste gráfico/matriz representa el grado de asociación entre variables mediante el tamaño de los círculos e intensidad de colores, y el signo de la asociación se representa con una gradiente de colores que va del azul (positivo) al rojo (negativo). Bajo la diagonal aparecen los indices de correlación entre pares de variables.\nFinalmente, también se puede representar la correlación entre dos variables en un gráfico de nube de puntos o scatterplot:sjPlot::plot_scatter\nnames(proc_elsoc)\r## [1] \u0026quot;mesfuerzo\u0026quot; \u0026quot;mtalento\u0026quot; \u0026quot;ess\u0026quot; \u0026quot;edcine\u0026quot; \u0026quot;sexo\u0026quot; \u0026quot;edad\u0026quot; ## [7] \u0026quot;pmerit\u0026quot;\rplot_scatter(proc_elsoc, edad, ess)\rDonde:\n\rcada punto representa un caso\rla forma de la nube indica si la asociación es positiva, negativa o neutra:\r\rEn el caso de nuestra nube de puntos entre edad y estatus social subjetivo, observamos que no hay asociación (lo que ya era indicado por su correlación de -0.07 observada en la matriz de correlaciones).\n\r\r\rNota final: Información de la sesión de R\rR y sus librerías tienen distintas versiones. Esto puede representar algunos problemas de compatibilidad entre usuarios, por ejemplo, dos personas que trabajan en el mismo proyecto pero con distintas versiones (librerías y/o de R), pueden tener ocasionalmente complicaciones. Por eso, una buena práctica es registrar al final del código la información de la sesión. Y como siempre en R, varias maneras de hacer esto. Vamos con la más genérica que es muy simple: sessionInfo() sessionInfo()\nsessionInfo()\r## R version 4.0.0 (2020-04-24)\r## Platform: x86_64-pc-linux-gnu (64-bit)\r## Running under: Ubuntu 16.04.6 LTS\r## ## Matrix products: default\r## BLAS: /usr/lib/libblas/libblas.so.3.6.0\r## LAPACK: /usr/lib/lapack/liblapack.so.3.6.0\r## ## locale:\r## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=es_CL.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=es_CL.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=es_CL.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=es_CL.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] sessioninfo_1.1.1 corrplot_0.84 sjmisc_2.8.4 summarytools_0.9.6\r## [5] sjstats_0.18.0 psych_1.9.12.31 Publish_2019.12.04 prodlim_2019.11.13\r## [9] ggpubr_0.3.0 magrittr_1.5 car_3.0-7 carData_3.0-3 ## [13] scales_1.1.1 gridExtra_2.3 ggplot2_3.3.0 stargazer_5.2.2 ## [17] sjPlot_2.8.3 kableExtra_1.1.0 Rmisc_1.5 plyr_1.8.6 ## [21] lattice_0.20-41 dplyr_0.8.5 knitr_1.28 pacman_0.5.1 ## ## loaded via a namespace (and not attached):\r## [1] TH.data_1.0-10 minqa_1.2.4 colorspace_1.4-1 pryr_0.1.4 ## [5] ggsignif_0.6.0 ellipsis_0.3.0 rio_0.5.16 sjlabelled_1.1.4 ## [9] estimability_1.3 parameters_0.6.1 base64enc_0.1-3 rstudioapi_0.11 ## [13] fansi_0.4.1 mvtnorm_1.1-0 lubridate_1.7.8 xml2_1.3.2 ## [17] codetools_0.2-16 splines_4.0.0 mnormt_1.5-7 nloptr_1.2.2.1 ## [21] ggeffects_0.14.3 broom_0.5.6 effectsize_0.3.0 readr_1.3.1 ## [25] compiler_4.0.0 httr_1.4.1 emmeans_1.4.6 backports_1.1.7 ## [29] assertthat_0.2.1 Matrix_1.2-18 cli_2.0.2 htmltools_0.4.0 ## [33] tools_4.0.0 coda_0.19-3 gtable_0.3.0 glue_1.4.1 ## [37] Rcpp_1.0.4.6 cellranger_1.1.0 vctrs_0.3.0 nlme_3.1-147 ## [41] blogdown_0.18 insight_0.8.4 xfun_0.13 stringr_1.4.0 ## [45] openxlsx_4.1.5 lme4_1.1-23 rvest_0.3.5 lifecycle_0.2.0 ## [49] statmod_1.4.34 rstatix_0.5.0 MASS_7.3-51.6 zoo_1.8-8 ## [53] hms_0.5.3 parallel_4.0.0 sandwich_2.5-1 yaml_2.2.1 ## [57] curl_4.3 pander_0.6.3 stringi_1.4.6 bayestestR_0.6.0 ## [61] checkmate_2.0.0 boot_1.3-25 zip_2.0.4 lava_1.6.7 ## [65] rlang_0.4.6 pkgconfig_2.0.3 matrixStats_0.56.0 evaluate_0.14 ## [69] purrr_0.3.4 rapportools_1.0 tidyselect_1.1.0 bookdown_0.18 ## [73] R6_2.4.1 magick_2.3 generics_0.0.2 multcomp_1.4-13 ## [77] pillar_1.4.4 haven_2.2.0 foreign_0.8-79 withr_2.2.0 ## [81] survival_3.1-12 abind_1.4-5 tibble_3.0.1 performance_0.4.6 ## [85] modelr_0.1.7 crayon_1.3.4 rmarkdown_2.1 grid_4.0.0 ## [89] readxl_1.3.1 data.table_1.12.8 forcats_0.5.0 digest_0.6.25 ## [93] webshot_0.5.2 xtable_1.8-4 tidyr_1.0.3 munsell_0.5.0 ## [97] viridisLite_0.3.0 tcltk_4.0.0\rAcá vemos un listado de información muy completo, desde versión de R, sistema operativo, opciones de idioma local (LOCALE), y muchas librerías. Si optamos por esta versión de la información de la sesión, lo importante es fijarse en (a) version de R, y (b) de las librerías cargadas al principio, que aquí aparecen bajo “other attached packages”.\nLa segunda opción permite obtener información más precisa, con sessioninfo sessioninfo()(la única diferencia con la anterior en el nombre es que info es con minúscula sessioninfo). Con un poco más de especificaciones de sintaxis se pueden obtener directamente los puntos (a) y (b) mencionados anteriormente:\nsession_info(\u0026quot;sessioninfo\u0026quot;)$platform\r## setting value ## version R version 4.0.0 (2020-04-24)\r## os Ubuntu 16.04.6 LTS ## system x86_64, linux-gnu ## ui X11 ## language en_US ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz America/Santiago ## date 2020-05-16\rpackage_info(pkgs = (.packages()), dependencies = FALSE)\r## package * version date lib source ## car * 3.0-7 2020-03-11 [1] CRAN (R 4.0.0)\r## carData * 3.0-3 2019-11-16 [1] CRAN (R 4.0.0)\r## corrplot * 0.84 2017-10-16 [1] CRAN (R 4.0.0)\r## dplyr * 0.8.5 2020-03-07 [1] CRAN (R 4.0.0)\r## ggplot2 * 3.3.0 2020-03-05 [1] CRAN (R 4.0.0)\r## ggpubr * 0.3.0 2020-05-04 [1] CRAN (R 4.0.0)\r## gridExtra * 2.3 2017-09-09 [1] CRAN (R 4.0.0)\r## kableExtra * 1.1.0 2019-03-16 [1] CRAN (R 4.0.0)\r## knitr * 1.28 2020-02-06 [1] CRAN (R 4.0.0)\r## lattice * 0.20-41 2020-04-02 [1] CRAN (R 4.0.0)\r## magrittr * 1.5 2014-11-22 [1] CRAN (R 4.0.0)\r## pacman * 0.5.1 2019-03-11 [1] CRAN (R 4.0.0)\r## plyr * 1.8.6 2020-03-03 [1] CRAN (R 4.0.0)\r## prodlim * 2019.11.13 2019-11-17 [1] CRAN (R 4.0.0)\r## psych * 1.9.12.31 2020-01-08 [1] CRAN (R 4.0.0)\r## Publish * 2019.12.04 2019-12-04 [1] CRAN (R 4.0.0)\r## Rmisc * 1.5 2013-10-22 [1] CRAN (R 4.0.0)\r## scales * 1.1.1 2020-05-11 [1] CRAN (R 4.0.0)\r## sessioninfo * 1.1.1 2018-11-05 [1] CRAN (R 4.0.0)\r## sjmisc * 2.8.4 2020-04-03 [1] CRAN (R 4.0.0)\r## sjPlot * 2.8.3 2020-03-09 [1] CRAN (R 4.0.0)\r## sjstats * 0.18.0 2020-05-06 [1] CRAN (R 4.0.0)\r## stargazer * 5.2.2 2018-05-30 [1] CRAN (R 4.0.0)\r## summarytools * 0.9.6 2020-03-02 [1] CRAN (R 4.0.0)\r## ## [1] /home/juank/Dropbox/Rlibrary\r## [2] /usr/local/lib/R/site-library\r## [3] /usr/lib/R/site-library\r## [4] /usr/lib/R/library\r\r\rResumen Práctica 2: Descripción de variables\rEn esta práctica revisamos los siguientes contenidos:\n\rtabla descriptiva general de variables\rtabla de asociación (o contingencia) entre dos variables categóricas\rtabla y gráfico de asociación entre variables categóricas y contínuas\rasociaciones entre pares de variables continuas mediante el índice de correlación.\r\r\rReporte de progreso\rCompletar el reporte de progreso correspondiente a esta práctica aquí\n\rArchivo de código\rEl archivo de código R de esta práctica se puede descargar aquí\n\rForo práctica 2\r\r","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1598019297,"objectID":"112494b1f3727cfe1df8f164d59d3152","permalink":"/assignment/02-code/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/assignment/02-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 2. Descripción de variables","type":"docs"},{"authors":null,"categories":null,"content":"\rPresentación\rEl Estudio Longitudinal Social de Chile (ELSOC) es una encuesta desarrollada para analizar intertemporalmente la evolución del conflicto y cohesión en la sociedad chilena.\nUno de los módulos de ELSOC es “Desigualdad y Legitimidad”. Este módulo busca estudiar las percepciones y atribuciones asociadas a las desigualdades sociales. Se ve motivado por el interés de comprender cómo las personas perciben, legitiman y reproducen las diferencias de ingresos, estatus y poder presentes en el Chile contemporáneo.\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevante para el estudio de la Percepción de Meritocracia, entendida como el grado en que los individuos consideran que su sociedad cumple con los principios de una meritocracia, es decir, que funciona como un sistema que asigna recompensas en función del esfuerzo y las habilidades.\n\rPreparacion de datos con ELSOC 2016\rLibrerías y configuración\rlibrary(dplyr)\r## ## Attaching package: \u0026#39;dplyr\u0026#39;\r## The following objects are masked from \u0026#39;package:stats\u0026#39;:\r## ## filter, lag\r## The following objects are masked from \u0026#39;package:base\u0026#39;:\r## ## intersect, setdiff, setequal, union\rrm(list=ls()) # borrar todos los objetos en el enviorment\roptions(scipen=999) #sin notacion cientifica\rCargar base de datos\r\rEjemplo de ruta, debe remplazarla por la de su computador.\r\rsetwd(\u0026quot;C:/usuario/usted/multivariada/materiales/01material\u0026quot;) \r# buscammos la sub carpeta ... datos/original/ELSOC_W01_v3.10.RData\rload(\u0026quot;data/original/ELSOC_W01_v3.10.RData\u0026quot;)\relsoc \u0026lt;- elsoc_2016; remove(elsoc_2016)\r# load(\u0026quot;link/ELSOC_W01_v3.10.RData\u0026quot;)\r\rDatos perdidos\r\rEn ELSOC todos los valores -888 y -999 corresponden a valores para las categorias “No sabe” y “No responde”, respectivamente.\rDecidimos dejarlas como valores perdidos (NA)\r\rfor (i in 1:ncol(elsoc)) {\relsoc[,i][elsoc[,i] == c(-888)] \u0026lt;- NA #Missing elsoc[,i][elsoc[,i] == c(-999)] \u0026lt;- NA #Missing }\r\r\rRecodificacion Variables percepcion de meritocracia\r\r[c18_09]: “Grado de acuerdo: Las personas son recompensadas por sus esfuerzos” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo)\r[c18_10]: “Grado de acuerdo: Las personas son recompensada por su inteligencia” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo)\r\relsoc$c18_09 \u0026lt;- as.numeric(elsoc$c18_09) elsoc$c18_10 \u0026lt;- as.numeric(elsoc$c18_10) # Variables meritocracia promedio -----------------------------------------\relsoc \u0026lt;- rename(elsoc,meffort=c18_09) # cambio de nombre de la variable c18_09 a uno mas sustantivo elsoc \u0026lt;- rename(elsoc,mtalent=c18_10) # cambio de nombre de la variable c18_10 a uno mas sustantivo # creamos un indice promedio de percepcion de meritocracia usando ambas preguntas\relsoc$merit \u0026lt;- (elsoc$meffort+elsoc$mtalent)/2 # re escalamos la variable de 1-5 a una de 0 a 100 (para facilitar interpretacion) elsoc$merit \u0026lt;- (elsoc$merit-min(elsoc$merit,na.rm=T))/(max(elsoc$merit,na.rm=T)-min(elsoc$merit,na.rm=T))*100\r\rRecodificacion variable Estatus subjetivo\r\r[d01_01]: “Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena” (0 = el nivel mas bajo; 10 = el nivel mas alto)\r\relsoc$ess \u0026lt;- as.numeric(elsoc$d01_01) # Estatus Social Subjetivo\rtable(elsoc$ess)\rsummary(elsoc$ess)\r## ## 0 1 2 3 4 5 6 7 8 9 10 ## 44 84 207 439 677 975 310 116 37 4 22 ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 0.00 3.00 5.00 4.33 5.00 10.00 12\r\rRecodificacion variables Estatus objetivo\rIngresos del hogar\rsummary(elsoc$m29) # ingresos total ; NA == 587\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 0 267500 420000 2477852 700000 4000000000 587\rsummary(elsoc$m30) # ingresos tramos \r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 1.000 3.000 6.000 7.415 11.000 20.000 2479\rsummary(elsoc$nhogar1) # tamannio del hogar\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 2.000 3.000 3.077 4.000 14.000\relsoc$m29[elsoc$m29==0] \u0026lt;- NA\r# Remplazar NA por media de categorias Ingreso -------------------------------#\relsoc$mean_tramos \u0026lt;- NA # creamos una variable vacia\r# remplazamos ...\relsoc$mean_tramos[elsoc$m30==1] \u0026lt;-110000\relsoc$mean_tramos[elsoc$m30==2] \u0026lt;-250000.5\relsoc$mean_tramos[elsoc$m30==3] \u0026lt;-305000.5\relsoc$mean_tramos[elsoc$m30==4] \u0026lt;-355000.5\relsoc$mean_tramos[elsoc$m30==5] \u0026lt;-400000.5\relsoc$mean_tramos[elsoc$m30==6] \u0026lt;-445000.5\relsoc$mean_tramos[elsoc$m30==7] \u0026lt;-490000.5\relsoc$mean_tramos[elsoc$m30==8] \u0026lt;-535000.5\relsoc$mean_tramos[elsoc$m30==9] \u0026lt;-585000.5\relsoc$mean_tramos[elsoc$m30==10]\u0026lt;-640000.5\relsoc$mean_tramos[elsoc$m30==11]\u0026lt;-700000.5\relsoc$mean_tramos[elsoc$m30==12]\u0026lt;-765000.5\relsoc$mean_tramos[elsoc$m30==13]\u0026lt;-845000.5\relsoc$mean_tramos[elsoc$m30==14]\u0026lt;-935000.5\relsoc$mean_tramos[elsoc$m30==15]\u0026lt;-1040000.5\relsoc$mean_tramos[elsoc$m30==16]\u0026lt;-1180000.5\relsoc$mean_tramos[elsoc$m30==17]\u0026lt;-1375000.5\relsoc$mean_tramos[elsoc$m30==18]\u0026lt;-1670000.5\relsoc$mean_tramos[elsoc$m30==19]\u0026lt;-2275000.5\relsoc$mean_tramos[elsoc$m30==20]\u0026lt;-3726106\rtable(elsoc$mean_tramos) # chequeamos\r## ## 110000 250000.5 305000.5 355000.5 400000.5 445000.5 490000.5 535000.5 ## 49 42 36 35 33 33 38 21 ## 585000.5 640000.5 700000.5 765000.5 845000.5 935000.5 1040000.5 1180000.5 ## 26 16 18 15 11 14 19 13 ## 1375000.5 1670000.5 2275000.5 3726106 ## 4 10 8 7\relsoc$m29 \u0026lt;- ifelse(test = (is.na(elsoc$m29)),#¿es el valor un NA? yes = elsoc$mean_tramos, #Si es verdadero, remplazar por el valor de mean_tramos\rno = elsoc$m29)# Si es falso, remplazar por el valor del m29\rsummary(elsoc$m29) # NA = 147\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 20000 280000 445000 2182986 700000 4000000000 147\r# cambiamos el nombre de las variables inghogar = m29; nhogar=nhogar1\relsoc \u0026lt;- rename(elsoc, inghogar=m29, nhogar=nhogar1) # ingreso neto = ingreso del hogar / numero de personas en el hogar\relsoc$ingneto \u0026lt;- as.numeric(elsoc$inghogar/elsoc$nhogar) # logaritmo natural del ingreso neto (para normalizar la distribucion sesgada del ingreso)\relsoc$lningneto \u0026lt;- log(elsoc$ingneto) summary(elsoc$ingneto)\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 7500 95000 150000 1028152 267500 2000000000 147\rsummary(elsoc$lningneto)\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 8.923 11.462 11.918 12.006 12.497 21.416 147\r#---Deciles (ingreso per capita hogar)------------------------------------------------\relsoc \u0026lt;- elsoc %\u0026gt;% mutate(inc10h = ntile(inghogar, 10)) # Crear Deciles de ingreso\relsoc$D10h \u0026lt;- factor(elsoc$inc10h, levels = c(1,2,3,4,5,6,7,8,9,10), labels = c(\u0026quot;D01\u0026quot;,\u0026quot;D02\u0026quot;,\u0026quot;D03\u0026quot;,\u0026quot;D04\u0026quot;,\u0026quot;D05\u0026quot;,\r\u0026quot;D06\u0026quot;,\u0026quot;D07\u0026quot;,\u0026quot;D08\u0026quot;,\u0026quot;D09\u0026quot;,\u0026quot;D10\u0026quot;));table(elsoc$D10h)\r## ## D01 D02 D03 D04 D05 D06 D07 D08 D09 D10 ## 278 278 278 278 278 278 278 278 278 278\r\rEducación\rtable(elsoc$m01) # Educacion en ELSOC\r## ## 1 2 3 4 5 6 7 8 9 10 ## 37 322 297 394 857 102 381 186 303 46\rRecodificación CINE 2011 (UNESCO)\n1. Sin estudios = [CINE 0 ] = 1\r2. Educacion Basica o Preparatoria incompleta = [CINE 0 ] = 1\r3. Educacion Basica o Preparatoria completa = [CINE 1,2 ] = 2\r4. Educacion Media o Humanidades incompleta = [CINE 3 ] = 3\r5. Educacion Media o Humanidades completa = [CINE 3 ] = 3\r6. Tecnico Superior incompleta = [CINE 5 ] = 4\r7. Tecnico Superior completa = [CINE 5 ] = 4\r8. Universitaria incompleta = [CINE 6 ] = 5\r9. Universitaria completa = [CINE 6 ] = 6\r10. Estudios de posgrado (magister o doctorado) = [CINE 7, 8] = 6\r# recodificacion usando funcion \u0026#39;recode\u0026#39; de la libreria car elsoc$edcine \u0026lt;- car::recode(elsoc$m01, \u0026quot;c(1,2)=1; c(3)=2;c(4,5)=3;c(6,7)=4;c(8,9,10)=5\u0026quot;) round(prop.table(table(elsoc$edcine)), 3)\r## ## 1 2 3 4 5 ## 0.123 0.102 0.428 0.165 0.183\relsoc$edcine \u0026lt;- factor(elsoc$edcine,\rlevels = c(1,2,3,4,5),\rlabels=c(\u0026quot;Primaria incompleta menos\u0026quot;,\r\u0026quot;Primaria y secundaria baja\u0026quot;,\r\u0026quot;Secundaria alta\u0026quot;,\r\u0026quot;Terciaria ciclo corto\u0026quot;,\r\u0026quot;Terciaria y Postgrado\u0026quot;))\rtable(elsoc$edcine) #chequeamos\r## ## Primaria incompleta menos Primaria y secundaria baja ## 359 297 ## Secundaria alta Terciaria ciclo corto ## 1251 483 ## Terciaria y Postgrado ## 535\r\r\rVariables control\r#---Sexo----\relsoc$sexo \u0026lt;- car::recode(elsoc$m0_sexo, \u0026quot;1=1;2=0\u0026quot;)\relsoc$sexo \u0026lt;- factor(elsoc$sexo, levels = c(0,1), labels = c(\u0026quot;Hombre\u0026quot;,\u0026quot;Mujer\u0026quot;)) # Sexo\r#Hombre=0\r#Mujer=1\r#---Edad----\relsoc$edad \u0026lt;- as.numeric(elsoc$m0_edad) #Edad\r#---Posicion Politica----\r# PREGUNTA: \u0026quot;Autoubicacion escala izquierda-derecha\u0026quot; # (0 = izquierda; 10 = Derecha; 11 = Independiente; 12 =Ninguno)\relsoc$ppolcat \u0026lt;- car::recode(elsoc$c15, \u0026quot;c(0,1,2,3,4)=1;5=2;c(6,7,8,9,10)=3;11=4;12=5\u0026quot;) elsoc$ppolcat \u0026lt;- factor(elsoc$ppolcat, levels = c(1,2,3,4,5), labels = c(\u0026quot;Izquierda/Centro Izquierda\u0026quot;,\r\u0026quot;Centro\u0026quot;,\r\u0026quot;Derecha/Centro Derecha\u0026quot;,\r\u0026quot;Independiente\u0026quot;,\r\u0026quot;Ninguno\u0026quot;))\r\r\rMantener variables relevantes\r# selecccionamos las variables relevantes\relsoc_16 \u0026lt;- elsoc %\u0026gt;% dplyr::select(merit,ess,edcine,lningneto,D10h, sexo, edad,ppolcat) # dejamos solamente los casos con informacion completa (listwise deletion)\relsoc_16 \u0026lt;- na.omit(elsoc_16)\rnames(elsoc_16) # comprobamos los nombres de variables\r## [1] \u0026quot;merit\u0026quot; \u0026quot;ess\u0026quot; \u0026quot;edcine\u0026quot; \u0026quot;lningneto\u0026quot; \u0026quot;D10h\u0026quot; \u0026quot;sexo\u0026quot; ## [7] \u0026quot;edad\u0026quot; \u0026quot;ppolcat\u0026quot;\rhead(elsoc_16) #chequear\r## merit ess edcine lningneto D10h sexo edad ppolcat\r## 1 75.0 5 Primaria incompleta menos 11.22524 D03 Hombre 64 Independiente\r## 2 75.0 5 Secundaria alta 12.42922 D06 Hombre 60 Ninguno\r## 3 50.0 3 Secundaria alta 11.31040 D06 Hombre 26 Ninguno\r## 4 75.0 6 Terciaria y Postgrado 13.54763 D08 Mujer 51 Ninguno\r## 5 62.5 4 Secundaria alta 13.10216 D06 Mujer 69 Ninguno\r## 6 75.0 5 Secundaria alta 13.10216 D06 Mujer 62 Independiente\r# Guardar base de datos procesada ---------------------------------------------------------------\rsave(elsoc_16,file = \u0026quot;data/proc/ELSOC_ess_merit2016.RData\u0026quot;)\r\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1585881306,"objectID":"96782a7dad874126bc6358fdb483b41e","permalink":"/assignment/01material/prep-datos/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/01material/prep-datos/","section":"assignment","summary":"Presentación\rEl Estudio Longitudinal Social de Chile (ELSOC) es una encuesta desarrollada para analizar intertemporalmente la evolución del conflicto y cohesión en la sociedad chilena.\nUno de los módulos de ELSOC es “Desigualdad y Legitimidad”. Este módulo busca estudiar las percepciones y atribuciones asociadas a las desigualdades sociales. Se ve motivado por el interés de comprender cómo las personas perciben, legitiman y reproducen las diferencias de ingresos, estatus y poder presentes en el Chile contemporáneo.","tags":null,"title":"Material 1. Procesamiento de datos en R","type":"assignment"},{"authors":null,"categories":null,"content":"\r\r\r\r\r\r Contenidos y Presentaciones\r Prácticas y evaluaciones\r Lecturas y material adicional\r\r\r\rABRIL \r\r\r\r\r3\r1. Presentación - Programa y forma de trabajo  - Modelos y explicación en ciencias sociales\rPráctica 1: Preparación de datos\r- *Linares (2018) Sociología y teoría social analíticas, cap. 2: La explicación en ciencias sociales - Salgado (2009) Construyendo explicaciones en sociología\r\rMAYO \r\r\r\r\r15\r2. Bases/Repaso - Datos y variables - Preparación y descripción - Varianza y covarianza - Correlación (descriptiva)\rPráctica 2: Descripción de variables\r- Moore: 1.Comprensión de los datos (1-54)\r\r22\r3. Regresión simple I Distribución condicional\nMínimos cuadrados y recta de regresión\rPráctica 3: Correlación y regresión\r- Moore: 2. Análisis de relaciones (97-131) \r\r29\r4. Regresión simple II Regresión vs correlación Residuos y ajuste general (R2) Presentación pauta de Trabajo del curso\rPractica 4: Residuos y ajuste\r- Moore: Residuos (144-154)\r\rJUNIO \r\r\r\r\r5\rSemana preparación Informe 1\rInforme 1: Regresión simple (individual) 20%, entrega MIERCOLES 10\rEjemplo de informe aquí\r\r12\rSemana de receso\r\r\r\r19\r5. Regresión múltiple 1 - Introducción\rPráctica 5: Tabla de regresión múltiple\r- * Wooldridge (2010) Cap 3 (parcial): Análisis de regresión múltiple: estimación (68-80)\r\r26\r6. Regresión múltiple 2 - Coeficientes de regresión parcial - Correlación parcial y semiparcial \rPráctica 6: Parcialización y control estadístico\r- * Wooldridge (2010) Cap 3 (parcial): Análisis de regresión múltiple: estimación (68-80)\r\rJULIO \r\r\r\r\r03\r7. Regresión e inferencia - Conceptos y supuestos - Tabla ANOVA - Inferencia sobre coeficientes\rPráctica 7: Inferencia\r- Moore 7: Inferencia para medias (482-543)\r\r10\r8. Regresión e inferencia (2) - Práctica 8: Inferencia 2 - Selección de predictores, setwise \u0026amp; stepwise\rPráctica 8: Predictores\r- Wooldridge (2010) Cap 7: Análisis de regresión múltiple con información cualitativa (225-246)\r\r17\rSemana preparación informe 2\rInforme 2: Regresión múltiple (grupal) 30%, entrega Miércoles 29\r- * Wooldridge (2010) Cap 19: Realización de un proyecto empírico (668-694)\r\r\r\r\r\r\r24\rSemana de Receso\r\r\r\r31\r9. Regresión logística I - Probabilidades - Odds ratios\rPráctica 9: Probabilidades y Odds\rCamarero et al (2017) Regresión logística (1-29) \r\rAGOSTO \r\r\r\r\r07\r10. Regresión logística II - Estimación de parámetros - Inferencia - Predicción\rPráctica 10: Estimación logística\r- Camarero et al (2017) Regresión logística (30-52)\r\r14\r11. Supuestos y chequeos de robustez - Relaciones no lineales -Transformaciones - Centrado\rPráctica 11: Transformación de variables y supuestos de regresión\r- Darlington \u0026amp; Hayes 2016 Cap16 Detecting and Managing Irregularities - Darlington \u0026amp; Hayes 2016 Cap12 Nonlinear relationships\r\r21\r12. Repaso, pendientes y cierre de los contenidos Preparación Informe 3\rEntrega Informe 3: Regresión logística, predictores categóricos y supuestos (grupal) 50%.\rWooldridge cap 6 Temas adicionales\r\r\r\rEntrega informe final: viernes 28 de Agosto\rExamen final: Semana del 7 de Septiembre\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1597721378,"objectID":"3e223d7ba58b0122b42458e4cf52e04c","permalink":"/schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/schedule/","section":"","summary":"Contenidos y Presentaciones\r Prácticas y evaluaciones\r Lecturas y material adicional\r\r\r\rABRIL \r\r\r\r\r3\r1. Presentación - Programa y forma de trabajo  - Modelos y explicación en ciencias sociales\rPráctica 1: Preparación de datos\r- *Linares (2018) Sociología y teoría social analíticas, cap. 2: La explicación en ciencias sociales - Salgado (2009) Construyendo explicaciones en sociología\r\rMAYO \r\r\r\r\r15\r2.","tags":null,"title":"Planificación","type":"page"},{"authors":null,"categories":null,"content":"\r\rPropósito general del curso\rCompetencias a las que contribuye el curso\rSub-Competencias\r\rResultados de Aprendizaje\rSaberes / contenidos\rUNIDAD 1: Introducción al modelamiento de datos sociales\rUNIDAD 2: Regresión Lineal Simple y Múltiple\rUNIDAD 3: Regresión múltiple para variables dependientes categóricas\r\rMetodología (actualizado)\rEvaluación (actualizado) (detalles en pestaña Trabajos)\rRequisitos de aprobación\rBibliografía\rTextos principales.\rMODELOS CIENTÍFICOS (Unidad 1)\rMODELOS DE REGRESIÓN LINEAL (Unidad 2)\rMODELOS DE REGRESIÓN PARA VARIABLES CATEGÓRICAS (Unidad 3)\rLinks \u0026amp; otras recomendaciones\r\rSoftware\rPlataformas de comunicación y discusión\rVARIOS\rProgramación de sesiones\r\r\rPropósito general del curso\rAl finalizar el curso los estudiantes conocerán los fundamentos del análisis estadístico multivariado.\rSe espera que los estudiantes sean capaces de:\n\ridentificar las principales técnicas de análisis estadístico multivariado utilizadas en la investigación sociológica\rdepurar y preparar datos para la aplicación de distintas técnicas de análisis estadístico multivariado; corroborar las condiciones de aplicación de distintas técnicas de análisis estadístico multivariado\rutilizar software de análisis estadístico\rcontrastar hipótesis de investigación\relaborar reportes de resultados y conclusiones a partir de la aplicación de diferentes técnicas de análisis estadístico multivariado.\r\rComplementariamente se espera que los estudiantes adquieran herramientas que les permitan comunicar resultados de investigación en contextos sociales, profesionales y académicos.\n\rCompetencias a las que contribuye el curso\r\rDiseñar y desarrollar estrategias de investigación social.\n\rComunicar los saberes disciplinares de manera pertinente a las características de distintos contextos y audiencias, utilizando diversas estrategias y formatos.\n\r\rSub-Competencias\r\rDiseñar y aplicar diversas técnicas de recolección y producción de información empírica, pertinentes al objeto de estudio.\n\rInterpretar información empírica aplicando diversas técnicas, en función de un plan de análisis.\n\rDiseñar estrategias para comunicar los saberes disciplinares considerando las características de distintos contextos y audiencias.\n\rComunicar en forma oral y escrita los saberes disciplinares considerando distintos contextos y audiencias, haciendo un uso creativo de distintas estrategias.\n\r\r\r\rResultados de Aprendizaje\rAl finalizar el curso, los estudiantes:\n\rSerán capaces de explicar los conceptos y fundamentos teóricos y estadísticos de la investigación social basada en modelos predictivos para variables observadas y serán capaces de explicar su utilidad para la sociología.\rSerán capaces de preparar y depurar bases de datos para su análisis utilizando técnicas multivariadas, evaluando la pertinencia y la presencia de condiciones para la aplicación de modelos predictivos para variables observadas.\rSerán capaces de manejar software especializado y reportar los resultados de modelos predictivos para variables observadas cuantitativas y no cuantitativas.\r\r\rSaberes / contenidos\rUNIDAD 1: Introducción al modelamiento de datos sociales\r\rTipos de investigación (descriptiva vs relacional y explicativa) y su materialización en el análisis estadístico.\rLa explicación en ciencias sociales: su relación con el concepto de covariación; la explicación como dependencia robusta y como cadena causal y el trabajo con modelos.\rEl trabajo con modelos: tipos de modelos (modelo teórico, modelo normativo, modelo científico, modelo estadístico); la vinculación entre los modelos científicos y los modelos teóricos; los modelos estadísticos como tipo de modelo científico.\rCiencia abierta y modelamiento: transparencia, reproducibilidad y replicación.\r\r\rUNIDAD 2: Regresión Lineal Simple y Múltiple\r\rBases: varianza, covarianza y correlación.\rUsos y aplicaciones en ciencias sociales de la regresión lineal.\rSupuestos y condiciones de aplicación de la regresión lineal.\rManejo de casos influyentes\rProcedimientos de estimación e interpretación de parámetros.\rIntroducción de variables de control estadístico.\rCriterios de validez, capacidad predictiva y evaluación del ajuste de la regresión lineal.\rTemas avanzados de regresión lineal: introducción de predictores categóricos, estimación de efectos de interacción y mediación, y uso de herramientas gráficas como apoyo a la interpretación y análisis de datos.\r\r\rUNIDAD 3: Regresión múltiple para variables dependientes categóricas\r\rLimitaciones de la regresión lineal y potencialidades de la introducción de variables dependientes categóricas.\rConcepto y sentido de la función logística y funciones afines.\rSupuestos y condiciones de aplicación de la regresión para variables categóricas.\rProcedimientos de estimación e interpretación de parámetros de regresión logística.\rCriterios de validez, capacidad predictiva y evaluación del ajuste de la regresión Logística.\rGeneralización de modelos de regresión logística: modelo de regresión logística multinomial y ordinal.\rEmpleo de otras matrices de correlación (tetracórica, biserial y policórica).\r\r\r\rMetodología (actualizado)\rEn las circunstancias excepcionales de este semestre dada la crisis santiaria, se han realizado una serie de ajustes metodológicos. De todas maneras estos se irán actualizando en el transcurso del semestre según varíe la contingencia y también atendiendio a necesidades y sugerencias de l_s participantes.\nTendremos tres espacios principales de aprendizaje:\nSesiones de clases: mientras dure la emergencia se realizaran online mediante la plataforma Zoom para las dos secciones; eventualmente algunas de las clases serán reemplazadas por videos explicativos. Todo el material de presentaciones se encontrará disponible en este sitio.\n\rPrácticas guiadas: cada tema de las sesiones se acompaña de una guía práctica de aplicación de contenidos. Estas guías están diseñadas para ser desarrolladas de manera autónoma por cada estudiante semana a semana. También serán desarrolladas y revisadas cada semana separados por secciones, para dar mayor oportunidad de participación y resolver las dudas respectivas. Estas prácticas serán supervisadas principalmente por los apoyos docentes.\n\rTrabajos: se desarrollarán trabajos de investigación durante el semestre (ver sección evaluación abajo) que permitirán a l_s participantes aplicar contenidos y recibir retroalimentación de su desempeño. Los trabajos serán asesorados principalmente por ayudantes que se asignarán a cada grupo.\n\r\r\rEvaluación (actualizado) (detalles en pestaña Trabajos)\rEl curso tendrá tres instancias de evaluación:\n\rTrabajo 1 (individual): Correlación y regresión simple (20%).\rTrabajo 2 (grupal): Regresión multiple e inferencia estadística (30%)\rTrabajo 3 (grupal): Regresión logística, predictores categóricos y supuestos (50%)\r\rLa nota ponderada de los trabajos equivaldrá al 60% de la nota del curso y el examen final al 40% restante.\n\rRequisitos de aprobación\rNota mínima de aprobación: 4,0 (en escala de 1 a 7).\nRequisitos de eximición de examen:\ncontar con un promedio ponderado igual o superior a 5.5.\rno tener nota bajo 4 en ninguno de los trabajos\r\rRequisitos para presentación a examen:\n\rPodrán presentarse al examen de primera oportunidad los estudiantes que hayan obtenido una calificación final igual o superior a 3.5.\rEl examen de segunda oportunidad será para aquellos estudiantes que presenten una nota igual o inferior a 3.5 o aquellos que en el examen de primera oportunidad no hubiesen logrado una nota igual o superior a 4.0.\r\r\rBibliografía\rLa bibliografía obligatoria para cada semana se presenta en la planificación del curso, desde donde se puede acceder directamente a los documentos. De todas maneras, abajo algunos textos comentados y referencias para cada unidad.\nTextos principales.\rHay cuatro referencias principales recomendadas para este curso:\n\rMoore (2010) Estadística aplicada básica. Barcelona: Antoni Bosch. No estaba en la bibliografía original, pero se incluye porque explica de manera bastante clara (y en español) una serie de análisis estadístico que sirven de base para este curso.\n\rDarlington, R. B., \u0026amp; Hayes, A. F. (2017). Regression analysis and linear models: concepts, applications, and implementation. Guilford Press. Este libro me parece un muy buen texto para acompañar un curso de regresión en ciencias sociales, lamentablemente está en inglés y por lo tanto solo es bibliografía sugerida. Los capítulos más relevantes estarán a disposición,\n\rWooldridge, J. M. (2008). Introducción a la econometría: un enfoque moderno. Paraninfo Cengage Learning. Libro clásico de regresión para economístas, la ventaja es que está en español, la desventaja (para nosotros) es que en ocasiones utiliza un lenguaje y ejemplos lejanos a la sociología.\n\rWickham, H., \u0026amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data (First edition). Sebastopol: O’Reilly. Libro con enfoque en el aprendizaje de R con técnicas que ciertamente van más allá del curso, pero muy util como referencia general. Además, está disponible también en español como “R para ciencia de datos”.\n\r\rAbajo bilbiografía recomendada para cada unidad\n\rMODELOS CIENTÍFICOS (Unidad 1)\r\rGarcía-Ferrando, M. (1985). Análisis y modelización causal en sociología. Reis, 29(1), 143-164.\rGoldthorpe, J. H. (2001). Causation, statistics, and sociology. European Sociological Review, 17(1), 1-20.\rRamón, L., \u0026amp; Ángeles, M. (2006). Estadística y causalidad en la sociología empírica del XX. Papers: revista de sociología, 80(1), 223-255.\rSalgado, M. (2009). Construyendo explicaciones: el uso de modelos en sociología. Persona y Sociedad, 30 (3), 29-60.\r\r\rMODELOS DE REGRESIÓN LINEAL (Unidad 2)\r\rEtxeberria, J. (1999). Regresión múltiple. Madrid: La Muralla.\rFox, J. \u0026amp; Weisberg, S. (2011) An R Companion to Applied Regression (149-183). London: Sage.\rPértega-Díaz, S., \u0026amp; Pita-Fernández, S. (2000). Técnicas de regresión: Regresión lineal múltiple. Cuadernos de atención primaria, 7(3), 173-176. En: https://dialnet.unirioja.es/servlet/articulo?codigo=2331162\rPértega-Díaz, S., \u0026amp; Pita-Fernández, S. (2000). Técnicas de regresión: Regresión lineal simple. Cuadernos de atención primaria, 7(2), 91-94. En: https://dialnet.unirioja.es/servlet/articulo?codigo=2331559\rGrolemund, G. \u0026amp; Wickam, H. (2017) R for Data Science. Disponible en: https://r4ds.had.co.nz/\r\r\rMODELOS DE REGRESIÓN PARA VARIABLES CATEGÓRICAS (Unidad 3)\r\rSilva LC, Barroso J. (2004). Regresión Logística. Cuaderno 27. Madrid: La Muralla.\rSilva LC. (1995). Excursión a la regresión logística en ciencias de la salud. Madrid: Díaz de Santos; 1995.\rJovell, A.J. (1995). Análisis de regresión logística, Cuadernos Metodológicos del CIS. Madrid.\r\r\rLinks \u0026amp; otras recomendaciones\r\rEconometrics with R\r\r\r\rSoftware\rUsaremos R 4.0 a través de la interfaz de RStudio. También realizaremos ejercicios y prácticas online en RCloud.\n\rPlataformas de comunicación y discusión\r\rForos Ucursos\rEn evaluación\r\rDisqus\r\r\r\rVARIOS\r\rLas clases en general se acompañan de documentos de presentación, que estarán disponibles antes de la sesión en la página de Materiales, y están desarrollados con base en Rmarkdown/XaringanRmarkdown/ Xaringan. Estos documentos no son:\n\r“la clase”\rautoexplicativos (ni aspiran a serlo)\r“el ppt” (ni mucho menos “la ppt”)\r\rPolíticas de participación y trato: se espera y enfatiza la participación por distintos canales disponibles. También se enfatiza un trato respetuoso y horizontal. Quienes están tomando este curso serán referidos como participantes y/o estudiantes, evitar el uso de “l_s cabr_s” o “l_s chiquill_s”. Quien no se sienta tratad_ apropiadamente o vea que otr_s no lo estan siendo, se solicita reportar para solucionar la situación.\n\r\r\rProgramación de sesiones\rVisitar la página de Planificación.\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1593784608,"objectID":"e4d5a4a79239f08c6ad0d7cbf1be756c","permalink":"/programa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/programa/","section":"","summary":"Propósito general del curso\rCompetencias a las que contribuye el curso\rSub-Competencias\r\rResultados de Aprendizaje\rSaberes / contenidos\rUNIDAD 1: Introducción al modelamiento de datos sociales\rUNIDAD 2: Regresión Lineal Simple y Múltiple\rUNIDAD 3: Regresión múltiple para variables dependientes categóricas\r\rMetodología (actualizado)\rEvaluación (actualizado) (detalles en pestaña Trabajos)\rRequisitos de aprobación\rBibliografía\rTextos principales.\rMODELOS CIENTÍFICOS (Unidad 1)\rMODELOS DE REGRESIÓN LINEAL (Unidad 2)\rMODELOS DE REGRESIÓN PARA VARIABLES CATEGÓRICAS (Unidad 3)\rLinks \u0026amp; otras recomendaciones\r\rSoftware\rPlataformas de comunicación y discusión\rVARIOS\rProgramación de sesiones\r\r\rPropósito general del curso\rAl finalizar el curso los estudiantes conocerán los fundamentos del análisis estadístico multivariado.","tags":null,"title":"Programa","type":"page"},{"authors":null,"categories":null,"content":"\rRequired\r\rChapter 1 in Kieran Healy, Data Visualization [@Healy:2019]\rChapters 2 and 3 in Alberto Cairo, The Truthful Art [@Cairo:2016] (skim the introduction and chapter 1)\r\r\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1585881306,"objectID":"57c6d6996ee98125a5375a3865ff4c4c","permalink":"/reading/01-reading/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/01-reading/","section":"reading","summary":"\rRequired\r\rChapter 1 in Kieran Healy, Data Visualization [@Healy:2019]\rChapters 2 and 3 in Alberto Cairo, The Truthful Art [@Cairo:2016] (skim the introduction and chapter 1)\r\r\r","tags":null,"title":"Truth, Beauty, and Data","type":"reading"}]